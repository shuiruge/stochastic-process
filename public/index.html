<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:x="https://www.texmacs.org/2002/extensions" xmlns:m="http://www.w3.org/1998/Math/MathML">
  <head>
    <title>A Brief Note about Information, Stochastic Process, and
    Least-Action Principle</title>
    <meta charset="utf-8" content="TeXmacs 2.1.4" name="generator"></meta>
    <style type="text/css">
      body { text-align: justify } h5 { display: inline; padding-right: 1em }
      h6 { display: inline; padding-right: 1em } table { border-collapse:
      collapse } td { padding: 0.2em; vertical-align: baseline } dt { float:
      left; min-width: 1.75em; text-align: right; padding-right: 0.75em;
      font-weight: bold; } dd { margin-left: 2.75em; padding-bottom: 0.25em; }
      dd p { padding-top: 0em; } .subsup { display: inline; vertical-align:
      -0.2em } .subsup td { padding: 0px; text-align: left} .fraction {
      display: inline; vertical-align: -0.8em } .fraction td { padding: 0px;
      text-align: center } .wide { position: relative; margin-left: -0.4em }
      .accent { position: relative; margin-left: -0.4em; top: -0.1em }
      .title-block { width: 100%; text-align: center } .title-block p {
      margin: 0px } .compact-block p { margin-top: 0px; margin-bottom: 0px }
      .left-tab { text-align: left } .center-tab { text-align: center }
      .balloon-anchor { border-bottom: 1px dotted #000000; outline: none;
      cursor: help; position: relative; } .balloon-anchor [hidden] {
      margin-left: -999em; position: absolute; display: none; }
      .balloon-anchor: hover [hidden] { position: absolute; left: 1em; top:
      2em; z-index: 99; margin-left: 0; width: 500px; display: inline-block; }
      .balloon-body { } .ornament { border-width: 1px; border-style: solid;
      border-color: black; display: inline-block; padding: 0.2em; } .right-tab
      { float: right; position: relative; top: -1em; } .no-breaks {
      white-space: nowrap; } .underline { text-decoration: underline; }
      .overline { text-decoration: overline; } .strike-through {
      text-decoration: line-through; } del { text-decoration: line-through
      wavy red; } .fill-out { text-decoration: underline dotted; } 
    </style>
    <link href="https://www.texmacs.org/css/web-article.css" type="text/css" rel="stylesheet"></link>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" language="javascript"></script>
  </head>
  <body>
    <table class="title-block" style="margin-bottom: 2em">
      <tr>
        <td><table class="title-block" style="margin-top: 0.5em; margin-bottom: 0.5em">
          <tr>
            <td><font style="font-size: 168.2%"><strong>A Brief Note about Information,
            Stochastic Process, and Least-Action
            Principle</strong></font></td>
          </tr>
        </table></td>
      </tr>
    </table>
    <h2>Table of contents<span style="margin-left: 1em"></span></h2>
    <div class="compact-block" style="text-indent: 0em">
      <p style="margin-top: 1em; margin-bottom: 0.5em">
        <b>1<span style="margin-left: 1em"></span>Relative Entropy</b> <span style="margin-left: 5mm"></span> <a
        href="#auto-1">1</a>
      </p>
      <p>
        1.1<span style="margin-left: 1em"></span>A Brief Review of Probability <span style="margin-left: 5mm"></span>
        <a href="#auto-2">1</a>
      </p>
      <p>
        1.2<span style="margin-left: 1em"></span>Shannon Entropy Is Plausible for Discrete
        Random Variable <span style="margin-left: 5mm"></span> <a href="#auto-3">2</a>
      </p>
      <p>
        1.3<span style="margin-left: 1em"></span>Shannon Entropy Fails for Continuous Random
        Variable <span style="margin-left: 5mm"></span> <a href="#auto-4">3</a>
      </p>
      <p>
        1.4<span style="margin-left: 1em"></span>Relative Entropy is the Unique Solution to the
        Axioms <span style="margin-left: 5mm"></span> <a href="#auto-5">3</a>
      </p>
      <p style="margin-top: 1em; margin-bottom: 0.5em">
        <b>2<span style="margin-left: 1em"></span>Master Equation, Detailed Balance, and
        Relative Entropy</b> <span style="margin-left: 5mm"></span> <a href="#auto-6">4</a>
      </p>
      <p>
        2.1<span style="margin-left: 1em"></span>Conventions in This Section <span style="margin-left: 5mm"></span>
        <a href="#auto-7">4</a>
      </p>
      <p>
        2.2<span style="margin-left: 1em"></span>Master Equation Describes the Evolution of
        Markov Process <span style="margin-left: 5mm"></span> <a href="#auto-8">4</a>
      </p>
      <p>
        2.3<span style="margin-left: 1em"></span>Transition Rate Determines Transition Density
        <span style="margin-left: 5mm"></span> <a href="#auto-9">6</a>
      </p>
      <p>
        2.4<span style="margin-left: 1em"></span>Detailed Balance Provides Stationary
        Distribution <span style="margin-left: 5mm"></span> <a href="#auto-10">8</a>
      </p>
      <p>
        2.5<span style="margin-left: 1em"></span>Detailed Balance with Connectivity
        Monotonically Reduces Relative Entropy <span style="margin-left: 5mm"></span> <a href="#auto-11">9</a>
      </p>
      <p>
        2.6<span style="margin-left: 1em"></span>Monte-Carlo Simulation and Guarantee of
        Relaxation <span style="margin-left: 5mm"></span> <a href="#auto-12">10</a>
      </p>
      <p>
        2.7<span style="margin-left: 1em"></span>Example: Metropolis-Hastings Algorithm <span
        style="margin-left: 5mm"></span> <a href="#auto-13">13</a>
      </p>
      <p>
        2.8<span style="margin-left: 1em"></span>* Existence of Stationary Density Function
        <span style="margin-left: 5mm"></span> <a href="#auto-14">14</a>
      </p>
      <p style="margin-top: 1em; margin-bottom: 0.5em">
        <b>3<span style="margin-left: 1em"></span>Kramers-Moyal Expansion and Langevin
        Process</b> <span style="margin-left: 5mm"></span> <a href="#auto-15">15</a>
      </p>
      <p>
        3.1<span style="margin-left: 1em"></span>Conventions in This Section <span style="margin-left: 5mm"></span>
        <a href="#auto-16">15</a>
      </p>
      <p>
        3.2<span style="margin-left: 1em"></span>Spatial Expansion of Master Equation Gives
        Kramers-Moyal Expansion <span style="margin-left: 5mm"></span> <a href="#auto-17">15</a>
      </p>
      <p>
        3.3<span style="margin-left: 1em"></span>From Brownian Motion to Central Limit Theorem
        <span style="margin-left: 5mm"></span> <a href="#auto-18">16</a>
      </p>
      <p>
        3.4<span style="margin-left: 1em"></span>Langevin Process Arises in the Difference of
        Scales <span style="margin-left: 5mm"></span> <a href="#auto-19">17</a>
      </p>
      <p>
        3.5<span style="margin-left: 1em"></span>Transition Rate of Langevin Process Is a
        Generalized Function <span style="margin-left: 5mm"></span> <a href="#auto-20">18</a>
      </p>
      <p>
        3.6<span style="margin-left: 1em"></span>Master Equation of Langevin Process Is
        Fokker-Planck Equation <span style="margin-left: 5mm"></span> <a href="#auto-21">20</a>
      </p>
      <p>
        3.7<span style="margin-left: 1em"></span>Stationary Solution of Langevin Process Has
        Source-Free Degree of Freedom <span style="margin-left: 5mm"></span> <a href="#auto-22">20</a>
      </p>
      <p>
        3.8<span style="margin-left: 1em"></span>Detailed Balance of Langevin Process Lacks
        Source-Free Degree of Freedom <span style="margin-left: 5mm"></span> <a href="#auto-23">21</a>
      </p>
      <p style="margin-top: 1em; margin-bottom: 0.5em">
        <b>4<span style="margin-left: 1em"></span>Least-Action Principle</b> <span style="margin-left: 5mm"></span>
        <a href="#auto-24">22</a>
      </p>
      <p>
        4.1<span style="margin-left: 1em"></span>Conventions in This Section <span style="margin-left: 5mm"></span>
        <a href="#auto-25">22</a>
      </p>
      <p>
        4.2<span style="margin-left: 1em"></span>A Brief Review of Least-Action Principle in
        Classical Mechanics <span style="margin-left: 5mm"></span> <a href="#auto-26">22</a>
      </p>
      <p>
        4.3<span style="margin-left: 1em"></span>Least-Action Principle of Distribution Has No
        Redundancy <span style="margin-left: 5mm"></span> <a href="#auto-27">23</a>
      </p>
      <p>
        4.4<span style="margin-left: 1em"></span>Data Fitting Is Equivalent to Least-Action
        Principle of Distribution <span style="margin-left: 5mm"></span> <a href="#auto-28">24</a>
      </p>
      <p>
        4.5<span style="margin-left: 1em"></span>The Action of Langevin Process Is Gaussian
        <span style="margin-left: 5mm"></span> <a href="#auto-30">26</a>
      </p>
      <p>
        4.6<span style="margin-left: 1em"></span>* The Action of Langevin Process: Another
        Derivation <span style="margin-left: 5mm"></span> <a href="#auto-31">26</a>
      </p>
      <p>
        4.7<span style="margin-left: 1em"></span>* Langevin Process Has Dissipation <span style="margin-left: 5mm"></span>
        <a href="#auto-32">27</a>
      </p>
      <p>
        4.8<span style="margin-left: 1em"></span>How Far Will Information Propagate in Langevin
        Process? <span style="margin-left: 5mm"></span> <a href="#auto-33">28</a>
      </p>
      <p>
        4.9<span style="margin-left: 1em"></span>Example: Action in Deep Learning (TODO) <span
        style="margin-left: 5mm"></span> <a href="#auto-34">31</a>
      </p>
      <p>
        4.10<span style="margin-left: 1em"></span>* History: Structures in Nature Arise from
        Least-Action Principle <span style="margin-left: 5mm"></span> <a href="#auto-35">31</a>
      </p>
      <p>
        4.10.1<span style="margin-left: 1em"></span>WBE Theory and Universality <span style="margin-left: 5mm"></span>
        <a href="#auto-36">31</a>
      </p>
      <p>
        4.10.2<span style="margin-left: 1em"></span>Renormalization Group and Criticality <span
        style="margin-left: 5mm"></span> <a href="#auto-37">32</a>
      </p>
    </div>
    <h2 id="auto-1"><a id="section: Relative Entropy"></a>1<span style="margin-left: 1em"></span>Relative Entropy<span style="margin-left: 1em"></span></h2>
    <h3 id="auto-2"><a id="section: A Brief Review of Probability"></a>1.1<span style="margin-left: 1em"></span>A Brief Review of
    Probability<span style="margin-left: 1em"></span></h3>
    <p>
      <em>Those that are not deterministic are denoted by capital
      letters.</em> But, a capital letter may also denote something that is
      determined. For example, a random variable has to be denoted by capital
      letter, like \(X\), while we can also use \(F\) to denote something
      determined, such as a functional.
    </p>
    <p>
      The set of all possible values of a random variable is called the
      <strong>alphabet</strong>
      .
      <div class="footnote">
        <font style="font-size: 77.1%"><div align="justify">
          <div style="margin-left: 0px">
            <div style="margin-right: 0px">
              <class style="font-style: normal"><p>
                1. Some textures call it <b>sample space</b>. But
                &ldquo;space&rdquo; usually hints for extra structures such as
                vector space or topological space. So, we use
                &ldquo;alphabet&rdquo; instead (following David Mackay, see
                his book <i>Information Theory, Inference, and Learning
                Algorithms</i>, section 2.1. Link to free PDF: <a href="https://www.inference.org.uk/itprnn/book.pdf">https://www.inference.org.uk/itprnn/book.pdf</a>).
              </p></class>
            </div>
          </div>
        </div></font>
      </div>
      <span style="margin-left: 0em"></span>
      <a id="footnr-1"></a>
      <sup><class style="font-style: normal"><a href="#footnote-1">1</a></class></sup>
      And for each value in the alphabet, we assign a
      <em>positive</em>
      value called
      <strong>density</strong>
      if the alphabet is of continuum (continuous random variable), or
      <strong>mass</strong>
      otherwise (discrete random variable).
      <div class="footnote">
        <font style="font-size: 77.1%"><div align="justify">
          <div style="margin-left: 0px">
            <div style="margin-right: 0px">
              <class style="font-style: normal"><p>
                2. In many textures, the density or mass function is
                non-negative (rather than being positive). Being positive is
                beneficial because, for example, we will discuss the logarithm
                of density or mass function, for which being zero is invalid.
                For any value on which density or mass function vanishes, we
                throw it out of \(\mathcal{X}\), which in turn guarantees the
                positivity.
              </p></class>
            </div>
          </div>
        </div></font>
      </div>
      <span style="margin-left: 0em"></span>
      <a id="footnr-2"></a>
      <sup><class style="font-style: normal"><a href="#footnote-2">2</a></class></sup>
      We use
      <strong>distribution</strong>
      for not only the mass or density on the alphabet, but also a sampler
      that can sample an ensemble of values of the random variable that
      converges to the mass or density when the number of sample tends to
      infinity. For example, we say \(X\) is a random variable with alphabet
      \(\mathcal{X}\) and distribution \(P\).
    </p>
    <p>
      The density of a value \(x\) is usually denoted by \(p (x)\), which, as
      a function, is called <strong>density function</strong>. Notice that \(p
      (x)\) is deterministic, thus not capital. The same for mass, where \(p
      (x)\) is called <strong>mass function</strong>. Thus, we can say the
      expectation of a function \(f\) on distribution \(P\), denoted by
      \(\mathbb{E}_P [f]\) or \(\mathbb{E}_{x \sim P} [f (x)]\). If the
      alphabet \(\mathcal{X}\) is of continuum, then it is
      \(\int_{\mathcal{X}} \mathrm{d} x p (x) f (x)\), otherwise \(\sum_{x \in
      \mathcal{X}} p (x) f (x)\).
    </p>
    <p>
      If there exists random variables \(Y\) and \(Z\), with alphabets
      \(\mathcal{Y}\) and \(\mathcal{Z}\) respectively, such that \(X = Y
      \oplus Z\) (for example, let \(X\) two-dimensional, \(Y\) and \(Z\) are
      the components), then we have <strong>marginal distribution</strong>s,
      denoted by \(P_Y\) and \(P_Z\), where \(p (y) := \int_{\mathcal{Z}}
      \mathrm{d} z p (y, z)\) and \(p (z) := \int_{\mathcal{Y}} \mathrm{d} y p
      (y, z)\) if \(X\) is of continuum, and the same for mass function.
      Notice that we have omitted the subscript \(Y\) in \(p_Y\) (and the same
      for \(p_Z\)) since the \(y\) in \(p (y)\) has clearly indicated this. We
      <strong>marginalize</strong> \(Z\) so as to get \(P_Y\).
    </p>
    <p>
      We further have the <strong>conditional distribution</strong> of \(Y\)
      given \(Z\), denoted by \(P_{Y|Z}\), where \(p (y|z) := p (y, z) / p
      (z)\) (we omit the subscript of \(p_{Y|Z}\) too). Suppose that we
      samples lots of \((Y, Z)\) values from \(P\), and then filters the pairs
      with \(Z = z\). The frequency of \(Y = y\) found in the filtered samples
      is approximated by \(p (y|z)\).
    </p>
    <h3 id="auto-3">1.2<span style="margin-left: 1em"></span>Shannon Entropy Is Plausible for Discrete
    Random Variable<span style="margin-left: 1em"></span></h3>
    <p>
      The Shannon entropy is well-defined for discrete random variable. Let
      \(X\) a discrete random variables with alphabet \(\{ 1, \ldots, n \}\)
      with \(p_i\) the mass of \(X = i\). The Shannon entropy is thus a
      function of \((p_1, \ldots, p_n)\) defined by
    </p>
    <center>
      \(\displaystyle H (P) := - k \sum_{i = 1}^n p_i \ln p_i,\)
    </center>
    <p>
      where \(k\) is a positive constant. Interestingly, this expression is
      unique given some plausible axioms, which can be qualitatively expressed
      as
    </p>
    <ol>
      <li>
        <p>
          \(H\) is a continuous function of \((p_1, \ldots, p_n)\);
        </p>
      </li>
      <li>
        <p>
          larger alphabet has higher uncertainty (information or entropy); and
        </p>
      </li>
      <li>
        <p>
          if we have known some information, and based on this knowledge we
          know further, the total information shall be the sum of all that we
          know.
        </p>
      </li>
    </ol>
    <p>
      Here, we use <b>uncertainty</b>, <b>surprise</b>, <b>information</b>,
      and <b>entropy</b> as interchangeable.
    </p>
    <p>
      The third axiom is also called the additivity of information. For two
      independent variables \(X\) and \(Y\) with distributions \(P\) and \(Q\)
      respectively, the third axiom indicates that the total information of
      \(H (P Q)\) is \(H (P) + H (Q)\). But, the third axiom indicates more
      than this. It also defines a &ldquo;conditional entropy&rdquo; for
      dealing with the situation where \(X\) and \(Y\) are dependent. Jaynes
      gives a detailed declaration to these axioms.
      <div class="footnote">
        <font style="font-size: 77.1%"><div align="justify">
          <div style="margin-left: 0px">
            <div style="margin-right: 0px">
              <class style="font-style: normal"><p>
                3. See the appendix A of <i>Information Theory and Statistical
                Mechanics</i> by E. T. Jaynes, 1957. A free PDF version can be
                found on Internet: <a href="https://bayes.wustl.edu/etj/articles/theory.1.pdf">https://bayes.wustl.edu/etj/articles/theory.1.pdf</a>.
              </p></class>
            </div>
          </div>
        </div></font>
      </div>
      <span style="margin-left: 0em"></span>
      <a id="footnr-3"></a>
      <sup><class style="font-style: normal"><a href="#footnote-3">3</a></class></sup>
      This conditional entropy is, argued by others, quite strong and not
      sufficiently natural. The problem is that this stronger axiom is
      essential for Shannon entropy to arise. Otherwise, there will be other
      entropy definitions that satisfy all the axioms, where the third
      involves only independent random variables, such as R&eacute;nyi
      entropy.
      <div class="footnote">
        <font style="font-size: 77.1%"><div align="justify">
          <div style="margin-left: 0px">
            <div style="margin-right: 0px">
              <class style="font-style: normal"><p>
                4. <i>On measures of information and entropy</i> by
                Alfr&eacute;d R&eacute;nyi, 1961. A free PDF version can be
                found on Internet: <a href="http://digitalassets.lib.berkeley.edu/math/ucb/text/math_s4_v1_article-27.pdf">http://digitalassets.lib.berkeley.edu/math/ucb/text/math_s4_v1_article-27.pdf</a>.
              </p></class>
            </div>
          </div>
        </div></font>
      </div>
      <span style="margin-left: 0em"></span>
      <a id="footnr-4"></a>
      <sup><class style="font-style: normal"><a href="#footnote-4">4</a></class></sup>
    </p>
    <p>
      As we will see, when extending the alphabet to continuum, this problem
      naturally ceases.
    </p>
    <h3 id="auto-4"><a id="section: Shannon Entropy Fails for Continuous Random Variable"></a>1.3<span style="margin-left: 1em"></span>Shannon Entropy Fails for
    Continuous Random Variable<span style="margin-left: 1em"></span></h3>
    <p>
      The Shannon entropy, however, cannot be directly generalized to
      continuous random variable. Usually, the entropy for continuous random
      variable \(X\) with alphabet \(\mathcal{X}\) and distribution \(P\) is
      given as a functional of the density function \(p (x)\),
    </p>
    <center>
      \(\displaystyle H (P) := - k \int_{\mathcal{X}} \mathrm{d} x p (x) \ln p
      (x)\)
    </center>
    <p>
      which, however, is not well-defined. The first issue is that the \(p\)
      has dimension, indicated by \(\int_{\mathcal{X}} \mathrm{d} x p (x) =
      1\). This means we put a dimensional quantity into logarithm which is
      invalid. The second issue is that the \(H\) is not invariant under
      coordinate transformation \(X \rightarrow Y := \varphi (X)\) where
      \(\varphi\) is a diffeomorphism. But as a &ldquo;physical&rdquo;
      quantity, \(H\) should be invariant under &ldquo;non-physical&rdquo;
      transformations.
    </p>
    <p>
      To eliminate the two issues, we shall extends the axiomatic description
      of entropy. The key to this extension is introducing another
      distribution, \(Q\), which has the same alphabet as \(P\); and instead
      considering <i>the uncertainty (surprise) caused by \(P\) when prior
      knowledge has been given by \(Q\)</i>. As we will see, this will solve
      the two issues altogether.
    </p>
    <p>
      Explicitly, we extends the axioms as
    </p>
    <ol>
      <li>
        <p>
          \(H\) is a smooth and local functional of \(p\) and \(q\);
        </p>
      </li>
      <li>
        <p>
          \(H (P, Q) > 0\) with \(P \neq Q\) and \(H (P, P) = 0\); and
        </p>
      </li>
      <li>
        <p>
          If \(X = Y \oplus Z\), and if \(Y\) and \(Z\) independent, then \(H
          (P, Q) = H (P_Y, Q_Y) + H (P_Z, Q_Z)\), where \(P_Y, \ldots, Q_Z\)
          are marginal distributions.
        </p>
      </li>
    </ol>
    <p>
      The first axiom employs the locality of \(H\), which is thought as
      natural since \(H\) has been a functional. The second axiom indicates
      that \(H\) vanishes only when there is no surprise caused by \(P\) (thus
      \(P = Q\)). It is a little like the second axiom for Shannon entropy.
      The third axiom, like the third in Shannon entropy, claims the
      additivity of surprise: if \(X\) has two independent parts, the total
      surprise shall be the sum of each.
    </p>
    <h3 id="auto-5">1.4<span style="margin-left: 1em"></span>Relative Entropy is the Unique Solution to
    the Axioms<span style="margin-left: 1em"></span></h3>
    <p>
      We are to derive the explicit expression of \(H\) based on the three
      axioms. The result is found to be unique.
    </p>
    <p>
      Based on the first axiom, there is a function \(h : (0, + \infty) \times
      (0, + \infty) \rightarrow [0, + \infty)\) such that \(H\) can be
      expressed as
    </p>
    <center>
      \(\displaystyle H (P, Q) = \int_{\mathcal{X}} \mathrm{d} x p (x) h (p
      (x), q (x)) .\)
    </center>
    <p>
      We are to determine the explicit form of \(h\). Thus, from second axiom,
    </p>
    <center>
      \(\displaystyle H (P, P) = \int_{\mathcal{X}} \mathrm{d} x p (x) h (p
      (x), p (x)) = 0\)
    </center>
    <p>
      holds for all distribution \(P\). Since \(p\) is positive and \(h\) is
      non-negative, then we have \(h (p (x), p (x)) = 0\) for all \(x \in
      \mathcal{X}\). The distribution \(P\) is arbitrary, thus we find \(h (x,
      x) = 0\) for any \(x \in (0, + \infty)\).
    </p>
    <p>
      Now come to the third axiom. Since \(Y\) and \(Z\) are independent, \(H
      (P, Q)\) can be written as \(\int_{\mathcal{X}} \mathrm{d} y \mathrm{d}
      z p_Y (y) p_Z (z) h (p_Y (y) p_Z
(z), q_Y (y) q_Z (z))\). Thus, the
      third axiom implies
    </p>
    <center>
      \(\displaystyle \int_{\mathcal{X}} \mathrm{d} y \mathrm{d} z p_Y (y) p_Z
      (z) \left[ h (p_Y (y)
p_Z (z), q_Y (y) q_Z (z)) - h (p_Y (y), q_Y (y)) -
      h (p_Z (z), q_Z (z))
\right] = 0.\)
    </center>
    <p>
      Following the previous argument, we find \(h (a x, b y) = h (a, b) + h
      (x, y)\) for any \(a, b, x, y \in (0, + \infty)\). Taking derivative on
      \(a\) and \(b\) results in \(\partial_1 h (a x, b y) x = \partial_1 h
      (a, b)\) and \(\partial_2 h (a x, b y) y = \partial_2 h (a, b)\). Since
      \(\partial_1 h (a, a) + \partial_2 h (a, a) = (\mathrm{d} / \mathrm{d}
      a) h (a,
a) = 0\), we get \(\partial_1 h (a x, a y) x + \partial_2 h (a
      x, a y) y = 0\). Letting \(a = 1\), it becomes a first order partial
      differential equation \(\partial_1 h (x, y) x + \partial_2 h (x, y) y =
      0\), which has a unique solution that \(h (x \mathrm{e}^t, y
      \mathrm{e}^t)\) is constant for all \(t\). Choosing \(t = - \ln y\), we
      find \(h (x, y) = h (x / y, 1)\). Now \(h\) reduces from two variables
      to one. So, plugging this result back to \(h (a x, b y) = h (a, b) + h
      (x, y)\), we have \(h (x y, 1) = h (x, 1) + h (y, 1)\). It looks like a
      logarithm. We are to show that it is indeed so. By taking derivative on
      \(x\) and then letting \(y = 1\), we get an first order ordinary
      differential equation \(\partial_1 h (x, 1) = \partial_1 h (1, 1) / x\),
      which has a unique solution that \(h (x, 1) = \partial_1 h (1, 1) \ln
      (x) + C\), where \(C\) is a constant. Combined with \(h (x, y) = h (x /
      y, 1)\), we finally arrive at \(h (x, y) = \partial_1 h (1, 1) \ln (x /
      y) + C\). To determine the \(\partial_1 h (1, 1)\) and \(C\), we use the
      second axiom \(\partial_1 h (1, 1)  \int \mathrm{d} x p (x) \ln (p (x) /
      q (x)) + C > 0\) when \(p \neq q\) and \(\partial_1 h (1, 1)  \int
      \mathrm{d} x p (x) \ln (p (x) / p (x)) + C = 0\). The second equation
      results in \(C = 0\). By <a href="https://en.wikipedia.org/wiki/Jensen%27s_inequality">Jensen's inequality</a>, the integral
      \(\int \mathrm{d} x p (x) \ln (p (x) / q (x))\) is non-negative, thus
      from the first equation, \(\partial_1 h (1, 1) > 0\). Up to now, all
      things about \(h\) have been settled. We conclude that there is a unique
      expression that satisfies all the three axioms, which is
    </p>
    <center>
      \(\displaystyle H (P, Q) = k \int_{\mathcal{X}} \mathrm{d} x p (x) \ln
      \frac{p (x)}{q (x)},\)
    </center>
    <p>
      where \(k > 0\). This was first derived by <a href="https://en.wikipedia.org/wiki/Solomon_Kullback">Solomon Kullback</a>
      and <a href="https://en.wikipedia.org/wiki/Richard_Leibler">Richard Leibler</a> in 1951, so it is called
      <b>Kullback&ndash;Leibler divergence</b> (<b>KL-divergence</b> for
      short), denoted by \(D_{\operatorname{KL}} (P\|Q)\). Since it
      characterizes the relative surprise, it is also called <b>relative
      entropy</b> (entropy for surprise).
    </p>
    <p>
      The locality is essential for relative entropy to arise. For example,
      Renyi divergence, defined by
    </p>
    <center>
      \(\displaystyle H_{\alpha} (P, Q) = \frac{1}{\alpha - 1} \ln \left(
      \int_{\mathcal{X}}
\mathrm{d} x \frac{p^{\alpha} (x)}{q^{\alpha - 1}
      (x)} \right),\)
    </center>
    <p>
      also satisfies the three axioms when locality is absent.
    </p>
    <p>
      In the end, we examine the two issues appeared in Shannon entropy
      (section <a href="#section: Shannon Entropy Fails for Continuous Random Variable">1.3</a>). In \(H (P, Q)\), the logarithm is \(\ln (p /
      q)\) which is dimensionless. And a coordinate transformation \(X
      \rightarrow Y := \varphi (X)\) makes \(\int \mathrm{d} x p (x) = \int
      \mathrm{d} y | \det (\partial \varphi^{- 1})
(y) | p (\varphi^{- 1} (y))
      =: \int \mathrm{d} y \tilde{p} (y)\), thus \(p \rightarrow \tilde{p} :=
      | \det (\partial \varphi^{- 1}) | p \circ
\varphi^{- 1}\). The same for
      \(q \rightarrow \tilde{q} := | \det (\partial \varphi^{- 1}) | q
      \circ
\varphi^{- 1}\). The common factor \(| \det (\partial \varphi^{-
      1}) |\) will be eliminated in \(\ln (p / q)\), leaving \(H (P, Q)\)
      invariant (since \(\int \mathrm{d} x p \ln (p / q) \rightarrow \int
      \mathrm{d} y \tilde{p} \ln
(\tilde{p} / \tilde{q})\), which equals to
      \(\int \mathrm{d} x p \ln (p / q)\)). So, the two issues of Shannon
      entropy cease in relative entropy.
    </p>
    <h2 id="auto-6"><a id="section: Master Equation, Detailed Balance, and Relative Entropy"></a>2<span style="margin-left: 1em"></span>Master Equation, Detailed Balance,
    and Relative Entropy<span style="margin-left: 1em"></span></h2>
    <h3 id="auto-7">2.1<span style="margin-left: 1em"></span>Conventions in This Section<span style="margin-left: 1em"></span></h3>
    <p>
      Let \(X\) a multi-dimensional random variables, being, discrete,
      continuous, or partially discrete and partially continuous, with
      alphabet \(\mathcal{X}\) and distribution \(P\). Even though the
      discussion in this section applies to both discrete and continuous
      random variables, we use the notation of the continuous. The reason is
      that converting from discrete to continuous may cause problems (section
      <a href="#section: Shannon Entropy Fails for Continuous Random Variable">1.3</a>), while the inverse will be safe and direct as long as
      any smooth structure of \(X\) is not employed throughout the discussion.
    </p>
    <h3 id="auto-8"><a id="section: Master Equation Describes the Evolution of Markov Process"></a>2.2<span style="margin-left: 1em"></span>Master Equation Describes the
    Evolution of Markov Process<span style="margin-left: 1em"></span></h3>
    <p>
      Without losing generality, consider a pile of sand on a desk. The desk
      has been fenced in so that the sands will not flow out of the desk.
      Imagine that these sands are magic, having free will to move on the
      desk. The distribution of sands changes with time. In the language of
      probability, the density of sands at position \(x\) of the desk is
      described by a time-dependent density function \(p (x, t)\), where the
      total mass of the sands on the desk is normalized to \(1\), and the
      position on the desk characterizes the alphabet \(\mathcal{X}\).
    </p>
    <p>
      Let \(q_{t \rightarrow t'} (y|x)\) denote the <em>portion</em> of
      density at position \(x\) that transits to position \(y\), from \(t\) to
      \(t'\). Then, the transited density will be \(q_{t \rightarrow t'} (y|x)
      p (x, t)\). There may be some portion of density at position \(x\) that
      does not transit during \(t \rightarrow t'\) (the lazy sands). In this
      case we imagine the sands transit from position \(x\) to \(x\) (stay on
      \(x\)), which is \(q_{t \rightarrow t'} (x|x)\). Now, every sand at
      position \(x\) has transited during \(t \rightarrow t'\), and the total
      portion shall be 100%, which means
    </p>
    <table width="100%">
      <tr>
        <td width="100%" align="center">\(\displaystyle \int_{\mathcal{X}} \mathrm{d} y q_{t
        \rightarrow t'} (y|x) = 1. \)</td>
        <td align="right">(1)</td>
      </tr>
    </table>
    <p>
      As portion, \(q_{t \rightarrow t'}\) cannot be negative, thus \(q_{t
      \rightarrow t'} (x|y) \geqslant 0\) for each \(x\) and \(y\) in
      \(\mathcal{X}\). We call \(q_{t \rightarrow t'}\) the <strong>transition
      density</strong>. Not like the density function of distribution,
      transition density can be zero in a subset of \(\mathcal{X}\).
    </p>
    <p>
      The transition makes a difference on density at position \(x\). The
      difference is caused by the density transited from \(x\), which is
      \(\int_{\mathcal{X}} \mathrm{d} y q_{t \rightarrow t'} (y|x) p (x, t)\),
      and that transited to \(x\), which is \(\)\(\int_{\mathcal{X}}
      \mathrm{d} y q_{t \rightarrow t'} (x|y) p (y, t)\). Thus, we have
    </p>
    <center>
      \(\displaystyle p (x, t') - p (x, t) = \int_{\mathcal{X}} \mathrm{d} y
      [q_{t \rightarrow t'}
(x|y) p (y, t) - q_{t \rightarrow t'} (y|x) p (x,
      t)] .\)
    </center>
    <p>
      By inserting equation (<a href="#equation:transition density normalization">1</a>), we find
    </p>
    <table width="100%">
      <tr>
        <td width="100%" align="center">\(\displaystyle p (x, t') = \int_{\mathcal{X}}
        \mathrm{d} y q_{t \rightarrow t'} (x|y) p (y,
t), \)</td>
        <td align="right">(2)</td>
      </tr>
    </table>
    <p>
      which is called the <strong>discrete time master equation</strong>. When
      \(t' = t\), we have \(p (x, t) = \int_{\mathcal{X}} \mathrm{d} y q_{t
      \rightarrow t} (x|y) p (y, t)\), indicating that
    </p>
    <center>
      \(\displaystyle q_{t \rightarrow t} (x|y) = \delta (x - y),\)
    </center>
    <p>
      where \(\delta (x - y)\) indicates Kronecker's delta function when
      \(\mathcal{X}\) is discrete, or Dirac's delta function when
      \(\mathcal{X}\) is continuous. Delta function has the property that
      \(\int_{\mathcal{X}} \mathrm{d} x \delta (x - y) f (x) = f (y)\) for any
      \(f\).
    </p>
    <p>
      
    </p>
    <p>
      In addition, if the change of the distribution of sands is smooth, that
      is, there is not a sand lump that jumping from one place to another in
      an arbitrarily short period of time, then \(q_{t \rightarrow t'}\) is
      smooth on \(t'\). Taking derivative on \(t'\) and then setting \(t'\) to
      \(t\), we have
    </p>
    <table width="100%">
      <tr>
        <td width="100%" align="center">\(\displaystyle \frac{\partial p}{\partial t} (x, t)
        = \int_{\mathcal{X}} \mathrm{d} y r_t (x,
y) p (y, t), \)</td>
        <td align="right">(3)</td>
      </tr>
    </table>
    <p>
      where \(r_t (x, y) := \lim_{t' \rightarrow t} (\partial q_{t \rightarrow
      t'} /
\partial t') (x|y)\), called <strong>transition rate</strong>. It
      is called the <strong>continuous time master equation</strong>, or
      simply <strong>master equation</strong>. The word &ldquo;master&rdquo;
      indicates that the transition rate has completely determined (mastered)
      the evolutionary behavior of distribution.
    </p>
    <p>
      Even though all these concepts are born of the pile of sand, they are
      applicable to any stochastic process where the distribution \(P (t)\) is
      time-dependent (but the alphabet \(\mathcal{X}\) is time-invariant), no
      matter whether the random variable is discrete or continuous.
    </p>
    <p>
      A stochastic process is <strong>Markovian</strong> if the transition
      density \(q_{t \rightarrow t'}\) depends only on the time interval
      \(\Delta t := t' - t\), thus \(q_{\Delta t}\). In this case, transition
      rate \(r\) is time-independent, so the master equation becomes
    </p>
    <table width="100%">
      <tr>
        <td width="100%" align="center">\(\displaystyle \frac{\partial p}{\partial t} (x, t)
        = \int_{\mathcal{X}} \mathrm{d} y r (x,
y) p (y, t) . \)</td>
        <td align="right">(4)</td>
      </tr>
    </table>
    <p>
      <em>Since we only deal with Markovian stochastic process throughout this
      note, when referring to master equation, we mean equation <a href="#equation:master equation">4</a>.
      And to discrete time master equation, equation <a href="#equation:discrete time master equation">5</a>:</em>
    </p>
    <table width="100%">
      <tr>
        <td width="100%" align="center">\(\displaystyle p (x, t + \Delta t) =
        \int_{\mathcal{X}} \mathrm{d} y q_{\Delta t} (x, y) p
(y, t) . \)</td>
        <td align="right">(5)</td>
      </tr>
    </table>
    <p>
      
    </p>
    <p>
      Before finishing this section, we discuss the demanded conditions for
      transition rate. The normalization of transition density <a href="#equation:transition density normalization">1</a>
      implies that \(\int_{\mathcal{X}} \mathrm{d} x r (x, y) = 0\). This can
      be seen by Taylor expanding \(q_{\Delta t}\) by \(\Delta t\), as
      \(q_{\Delta t} (x|y) = \delta (x - y) + r (x, y) \Delta t + \omicron
      (\Delta t)\), where we have inserted \(q_0 (x|y) = \delta (x - y)\) and
      the definition of \(r\). Also from this Taylor expansion, we see that
      the non-negativity of \(q_{\Delta t}\) implies \(r (x, y) \geqslant 0\)
      when \(x \neq y\). Since \(p\) is a density function of distribution,
      and density function is defined to be positive (see section <a href="#section: A Brief Review of Probability">1.1</a>),
      the equation <a href="#equation:discrete time master equation v0">2</a> must conserve this positivity. We are to
      show that this is guaranteed by the master equation itself, without any
      extra condition demanded for the transition rate. It is convenient to
      use discrete notations, thus replace \(x \rightarrow i\), \(y
      \rightarrow j\), and \(\int \rightarrow \sum\). The master equation
      turns to be \((\mathrm{d} p_i / \mathrm{d} t) (t) = \sum_j r_{i j} p_j
      (t)\). Notice that it becomes an ordinary differential equation. Recall
      that \(r_{i j} \geqslant 0\) when \(i \neq j\), and thus \(r_{i i}
      \leqslant 0\) (since \(\sum_j r_{j i} = 0\)). We separate the right hand
      side to \(r_{i i} p_i (t) + \sum_{j : j \neq i} r_{i j} p_j (t)\), and
      the worst situation is that \(r_{i j} = 0\) for each \(j \neq i\) and
      \(r_{i i} < 0\). In this case, the master equation reduces to
      \((\mathrm{d} p_i / \mathrm{d} t) (t) = r_{i i} p_i (t)\), which has the
      solution \(p_i (t) = p_i (0) \exp (r_{i i} t)\). It implies that \(p_i
      (t) > 0\) as long as \(p_i (0) > 0\), indicating that master equation
      conserves the positivity of density function. As a summary, we demand
      transition rate \(r\) to be \(r (x, y) \geqslant 0\) when \(x \neq y\)
      and \(\int_{\mathcal{X}} \mathrm{d} x r (x, y) = 0\).
    </p>
    <h3 id="auto-9"><a id="section: Transition Rate Determines Transition Density"></a>2.3<span style="margin-left: 1em"></span>Transition Rate Determines
    Transition Density<span style="margin-left: 1em"></span></h3>
    <p>
      We wonder, given a transition rate, can we obtain the corresponding
      transition density? Generally, we cannot get the global (finite) from
      the local (infinitesimal). For example, we cannot determine a function
      only by its first derivative at the origin. But, master equation has a
      group-like structure, by which the local accumulates to be global. We
      are to show how this happens.
    </p>
    <p>
      We can use the master equation <a href="#equation:master equation">4</a> to calculate \(\partial^n
      p / \partial t^n\) for any \(n\). For \(n = 2\), by inserting master
      equation <a href="#equation:master equation">4</a> (to the blue term), we have
    </p>
    <center>
      \(\displaystyle \frac{\partial^2 p}{\partial t^2} (z, t) =
      \frac{\partial}{\partial t}
{\color{blue}{\frac{\partial p}{\partial t}
      (z, t)}} =
\frac{\partial}{\partial t} {\color{blue}{\int_{\mathcal{X}}
      \mathrm{d} y r
(z, y) p (y, t)}} = \int_{\mathcal{X}} \mathrm{d} y r (z,
      y)  {\frac{\partial
p}{\partial t} (y, t)} .\)
    </center>
    <p>
      We then insert master equation <a href="#equation:master equation">4</a> again (to the green term),
      and find
    </p>
    <center>
      \(\displaystyle \frac{\partial^2 p}{\partial t^2} (z, t) =
      \int_{\mathcal{X}} \mathrm{d} y r
(z, y)  {\int_{\mathcal{X}} \mathrm{d}
      x r (y, x) p (x, t)} =
\int_{\mathcal{X}} \mathrm{d} x
      \int_{\mathcal{X}} \mathrm{d} y r (z, y) r (y,
x) p (x, t) .\)
    </center>
    <p>
      Following the same steps, it can be generalized to higher order
      derivatives, as
    </p>
    <center>
      \(\displaystyle \frac{\partial^{n + 1} p}{\partial t^{n + 1}} (z, t) =
      \int_{\mathcal{X}}
\mathrm{d} x \int_{\mathcal{X}} \mathrm{d} y_1 \cdots
      \int_{\mathcal{X}}
\mathrm{d} y_n r (z, y_n) r (y_n, y_{n - 1}) \cdots r
      (y_1, x) p (x, t) .\)
    </center>
    <p>
      Notice the pattern: a sequence of \(r\) and a rightmost \(p (x, t)\).
      The reason for this pattern to arise is that \(q_{\Delta t}\), thus
      \(r\), is independent of \(t\): a Markovian property.
    </p>
    <p>
      On the other hand, Taylor expand the both sides of equation <a href="#equation:discrete time master equation">5</a>
      by \(\Delta t\) gives, at \((\Delta t)^{n + 1}\) order,
    </p>
    <center>
      \(\displaystyle \frac{\partial^{n + 1} p}{\partial t^{n + 1}} (z, t) =
      \int_{\mathcal{X}}
\mathrm{d} x q^{(n + 1)}_0 (z|x) p (x, t),\)
    </center>
    <p>
      where, for simplifying notation, we have denoted the \(n\)th-order
      derivatives of \(q_{\Delta t}\) by
    </p>
    <center>
      \(\displaystyle q^{(n)}_{\Delta t} (x|y) := \lim_{s \rightarrow \Delta
      t} \frac{\mathrm{d}^n
q_s}{\mathrm{d} s^n} (x|y) .\)
    </center>
    <p>
      So,\(\) by equaling the two expressions of \((\partial^{n + 1} p /
      \partial t^{n + 1}) (z, t)\), we find
    </p>
    <center>
      \(\displaystyle \int_{\mathcal{X}} \mathrm{d} x \left[ q^{(n + 1)}_0
      (z|x) -
\int_{\mathcal{X}} \mathrm{d} y_1 \cdots \int_{\mathcal{X}}
      \mathrm{d} y_n r
(z, y_n) r (y_n, y_{n - 1}) \cdots r (y_1, x) \right] p
      (x, t) = 0\)
    </center>
    <p>
      For \(n = 1, 2, \ldots\). This holds for all \(p (x, t)\), thus
    </p>
    <center>
      \(\displaystyle q^{(n + 1)}_0 (z|x) = \int_{\mathcal{X}} \mathrm{d} y_1
      \cdots
\int_{\mathcal{X}} \mathrm{d} y_n r (z, y_n) r (y_n, y_{n - 1})
      \cdots r (y_1,
x) .\)
    </center>
    <p>
      Recalling that \(q_{\Delta t} (z|x) = \delta (z - x) + r (z, x) \Delta t
      + \omicron (\Delta t)\), we have the Taylor expansion of \(q_{\Delta
      t}\), as
      <div class="footnote">
        <font style="font-size: 77.1%"><div align="justify">
          <div style="margin-left: 0px">
            <div style="margin-right: 0px">
              <class style="font-style: normal"><p>
                5. Another derivation uses exponential mapping. By regarding
                \(p\) a time-dependent element in functional space, and \(r\)
                as a linear operator, it becomes (we add a hat for indicating
                operator, using dot \(\cdot\) for its operation)
              </p><center>
                \(\displaystyle \frac{\mathrm{d} p}{\mathrm{d} t} (t) =
                \hat{r} \cdot p (t) .\)
              </center><p>
                This operator differential equation has a famous solution,
                called exponential mapping, \(p (t) = \exp (\hat{r} t) p
                (0)\), where the exponential operator is defined by Taylor
                expansion \(\exp (\hat{L}) := \hat{1} + \hat{L} + (1 / 2!) 
                \hat{L}^2 + \cdots\) for any linear operator \(\hat{L}\).
                Indeed, by taking derivative on \(t\) on both sides, we find
                \((\mathrm{d} p / \mathrm{d} t) (t) = \hat{r} \cdot \exp
                (\hat{r} t) p (0) =
\hat{r} \cdot p (t)\). Recall the discrete
                time master equation, \(p (\Delta t) = \hat{q}_{\Delta t}
                \cdot p (0)\), where the transition density \(\hat{q}_{\Delta
                t}\) is regarded as a linear operator too (so we put a hat on
                it). We find \(\exp (\hat{r} \Delta t) \cdot p (0) =
                \hat{q}_{\Delta t} \cdot p (0)\), which holds for arbitrary
                \(p (0)\), implying \(\hat{q}_{\Delta t} = \exp (\hat{r}
                \Delta t) = 1 + \hat{r} \Delta t + (1 / 2!)
(\hat{r} \cdot
                \hat{r})  (\Delta t)^2 + \cdots\). Going back to functional
                representation, we have the correspondences \(\hat{q}_{\Delta
                t} \rightarrow q_{\Delta t} (z|x)\), \(\hat{r} \rightarrow r
                (z, x)\), \(\hat{r} \cdot \hat{r} \rightarrow \int \mathrm{d}
                y r (z, y) r (y, x)\), \(\hat{r} \cdot \hat{r} \cdot \hat{r}
                \rightarrow \int \mathrm{d} y_1 \mathrm{d}
y_2 r (z, y_2) r
                (y_2, y_1) r (y_1, x)\), and so on, thus recover the relation
                between \(q_{\Delta t}\) and \(r\).
              </p></class>
            </div>
          </div>
        </div></font>
      </div>
      <span style="margin-left: 0em"></span>
      <a id="footnr-5"></a>
      <sup><class style="font-style: normal"><a href="#footnote-5">5</a></class></sup>
    </p>
    <table width="100%">
      <tr>
        <td width="100%" align="center">\(\displaystyle \begin{array}{rl}
  q_{\Delta t}
        (z|x) = & \delta (z - x)\\
  + & (\Delta t) r (z, x)\\
  + &
        \frac{(\Delta t)^2}{2!}  \int_{\mathcal{X}} \mathrm{d} y r (z, y) r
        (y,
  x)\\
  + & \cdots\\
  + & \frac{(\Delta t)^{n + 1}}{(n + 1) !}
        \int_{\mathcal{X}} \mathrm{d} y_1
  \cdots \int_{\mathcal{X}}
        \mathrm{d} y_n r (z, y_n) r (y_n, y_{n - 1})
  \cdots r (y_1, x)\\
  +
        & \cdots .\\
  & 
\end{array} \)</td>
        <td align="right">(6)</td>
      </tr>
    </table>
    <p>
      Well, this is a complicated formula, but its implication is straight
      forward and very impressive: <em>the transition density is equivalent to
      transition rate, even though transition rate is derived from
      infinitesimal time-interval transition density.</em>
    </p>
    <p>
      This may be a little weird at the first sight. For example, consider
      \(q'_{\Delta t} (y|x) := q_{\Delta t} (y|x) + f (y, x) \Delta t^2\),
      where \(f\) is any function ensuring that \(q'_{\Delta t}\) is
      non-negative and normalized (thus \(\int_{\mathcal{X}} \mathrm{d} y f
      (y, x) = 0\)). Following the previous derivation, we find that the
      discrete time master equation
    </p>
    <center>
      \(\displaystyle p (z, t + \Delta t) = \int_{\mathcal{X}} \mathrm{d} x
      q'_{\Delta t} (z|x) p
(x, t)\)
    </center>
    <p>
      also leads to the (continuous time) master equation <a href="#equation:master equation">4</a> with
      the same \(r\) as that of \(q_{\Delta t}\). So, we should have
      \(q'_{\Delta t} = q_{\Delta t}\), which means \(f\) is not free, but
      should vanish.
    </p>
    <p>
      The answer to this question is that, a transition density is not free to
      choose, but sharing the same degree of freedom as that of its transition
      rate. <em>The fundamental quantity that describes the evolution of a
      continuous time Markov process is transition rate.</em> For example,
      consider \(p (z, t + \Delta t + \Delta t')\) for any \(\Delta t\) and
      \(\Delta t'\). Directly, we have
    </p>
    <center>
      \(\displaystyle p (z, t + \Delta t + \Delta t') = \int_{\mathcal{X}}
      \mathrm{d} x q_{\Delta t
+ \Delta t'} (z|x) p (x, t),\)
    </center>
    <p>
      but on the other hand, by applying discrete time master equation twice,
      we find
    </p>
    <center>
      \(\displaystyle \begin{array}{rl}
  p (z, t + \Delta t + \Delta t') = &
      \int_{\mathcal{X}} \mathrm{d} y
  q_{\Delta t} (z|y) p (y, t + \Delta
      t')\\
  = & \int_{\mathcal{X}} \mathrm{d} y q_{\Delta t'} (z|y)
      \int_{\mathcal{X}}
  \mathrm{d} x q_{\Delta t} (y|x) p (x, t)
      .
\end{array}\)
    </center>
    <p>
      By equaling the two expressions of \(p (z, t + \Delta t + \Delta t')\),
      we find
    </p>
    <center>
      \(\displaystyle \int_{\mathcal{X}} \mathrm{d} x \left[ q_{\Delta t +
      \Delta t'} (z|x) -
\int_{\mathcal{X}} \mathrm{d} y q_{\Delta t'} (z|y)
      q_{\Delta t} (y|x) \right]
p (x, t) = 0.\)
    </center>
    <p>
      Since \(p (x, t)\) can be arbitrary, we arrive at
    </p>
    <table width="100%">
      <tr>
        <td width="100%" align="center">\(\displaystyle q_{\Delta t + \Delta t'} (z|x) =
        \int_{\mathcal{X}} \mathrm{d} y q_{\Delta t'}
(z|y) q_{\Delta t} (y|x)
        . \)</td>
        <td align="right">(7)</td>
      </tr>
    </table>
    <p>
      This provides an addition restriction to the transition density.
    </p>
    <p>
      Interestingly, obeying equation <a href="#equation:transition rate determines transition density v2">7</a> is sufficient for
      \(q_{\Delta t}\) to satisfy equation <a href="#equation:transition rate determines transition density">6</a>. Precisely, let
      \(q_{\Delta t} (x|y)\) is a function that is smooth on \(\Delta t\) with
      \(q_0 (x|y) = \delta (x - y)\), we are to show that, if \(q_{\Delta t}\)
      satisfies equation <a href="#equation:transition rate determines transition density v2">7</a>, then it will obey equation <a href="#equation:transition rate determines transition density">6</a>.
      To do so, we take derivative on equation <a href="#equation:transition rate determines transition density v2">7</a> by \(\Delta t'\)
      at \(\Delta t' = 0\), resulting in
    </p>
    <center>
      \(\displaystyle q^{(1)}_{\Delta t} (z|x) = \int_{\mathcal{X}} \mathrm{d}
      y r (z, y) q_{\Delta
t} (y|x),\)
    </center>
    <p>
      where \(r (z, y) := q_0^{(1)} (z|y)\). Then, we are to Taylor expand
      both sides by \(\Delta t\). On the right hand side, we have
    </p>
    <center>
      \(\displaystyle q_{\Delta t} (y|x) = \delta (y - x) + \sum_{n = 1}^{+
      \infty} \frac{(\Delta
t)^n}{n!} q^{(n)}_0 (y|x),\)
    </center>
    <p>
      and on the left hand side,
    </p>
    <center>
      \(\displaystyle q^{(1)}_{\Delta t} (z|x) = \sum_{n = 0}^{+ \infty}
      \frac{(\Delta t)^n}{n!}
q^{(n + 1)}_0 (z|x) .\)
    </center>
    <p>
      So, we get the Taylor expansion on both sides. At \((\Delta t)^0\)
      order,
    </p>
    <center>
      \(\displaystyle q^{(1)}_0 (y|x) = r (y, x),\)
    </center>
    <p>
      which is just the definition of \(r\). At \((\Delta t)^1\) order,
    </p>
    <center>
      \(\displaystyle q^{(2)}_0 (y|x) = \int_{\mathcal{X}} \mathrm{d} y r (z,
      y) q^{(1)}_0 (y|x) =
\int_{\mathcal{X}} \mathrm{d} y r (z, y) r (y, x)
      .\)
    </center>
    <p>
      Iteratively at \((\Delta t)^{n + 1}\) order, we will find
    </p>
    <center>
      \(\displaystyle q^{(n + 1)}_0 (y|x) = \int_{\mathcal{X}} \mathrm{d} y_1
      \cdots
\int_{\mathcal{X}} \mathrm{d} y_n r (z, y_n) r (y_n, y_{n - 1})
      \cdots r (y_1,
x)\)
    </center>
    <p>
      again. And this implies equation <a href="#equation:transition rate determines transition density">6</a>. So, we conclude this
      paragraph as follow: <em>obeying equation <a href="#equation:transition rate determines transition density v2">7</a> is the
      sufficient and essential condition for a function \(q_{\Delta t}
      (x|y)\), which is smooth on \(\Delta t\) with \(q_0 (x|y) = \delta (x -
      y)\), to satisfy equation <a href="#equation:transition rate determines transition density">6</a>; additionally, if \(q_{\Delta
      t} (x|y)\) is non-negative and normalized on \(x\) (namely,
      \(\int_{\mathcal{X}} \mathrm{d} x q_{\Delta t} (x|y) = 1\)), then
      \(q_{\Delta t}\) is a transition density</em>.
    </p>
    <h3 id="auto-10"><a id="section: Detailed Balance Provides Stationary Distribution"></a>2.4<span style="margin-left: 1em"></span>Detailed Balance Provides
    Stationary Distribution<span style="margin-left: 1em"></span></h3>
    <p>
      Let \(\Pi\) a stationary solution of master equation <a href="#equation:master equation">4</a>.
      Then, its density function \(\pi\) satisfies \(\int_{\mathcal{X}}
      \mathrm{d} y r (x, y) \pi (y) = 0\). Since we have demanded that
      \(\int_{\mathcal{X}} \mathrm{d} y r (y, x) = 0\), the stationary master
      equation can be re-written as
    </p>
    <center>
      \(\displaystyle \int_{\mathcal{X}} \mathrm{d} y [r (x, y) \pi (y) - r
      (y, x) \pi (x)] = 0.\)
    </center>
    <p>
      But, this condition is too weak to be used. A more useful condition,
      which is stronger than this, is that the integrand vanishes everywhere:
    </p>
    <table width="100%">
      <tr>
        <td width="100%" align="center">\(\displaystyle r (x, y) \pi (y) = r (y, x) \pi (x),
        \)</td>
        <td align="right">(8)</td>
      </tr>
    </table>
    <p>
      which is called the <b>detailed balance condition</b>.
    </p>
    <p>
      Interestingly, for a transition rate \(r\) that satisfies detailed
      balance condition <a href="#equation:Detailed Balance">8</a>, the transition density \(q_{\Delta
      t}\) generated by \(r\) using equation <a href="#equation:transition rate determines transition density">6</a> satisfies a
      similar relation
    </p>
    <table width="100%">
      <tr>
        <td width="100%" align="center">\(\displaystyle q_{\Delta t} (x|y) \pi (y) =
        q_{\Delta t} (y|x) \pi (x) . \)</td>
        <td align="right">(9)</td>
      </tr>
    </table>
    <p>
      To see this, consider the third line in equation (<a href="#equation:transition rate determines transition density">6</a>), where
      the main factor is
    </p>
    <center>
      \(\displaystyle \begin{array}{rl}
  q_{\Delta t} (z|x) \pi (x) \supset &
      \int \mathrm{d} y r (z, y) r (y, x) \pi
  (x)\\
  \{ r (y, x) \pi (x) =
      \pi (y) r (x, y) \} = & \int \mathrm{d} y r (z, y) \pi
  (y) r (x, y)\\

      \{ r (z, y) \pi (y) = \pi (z) r (x, y) \} = & \int \mathrm{d} y \pi (z)
      r
  (x, y) r (y, z)\\
  = & \pi (z)  \int \mathrm{d} y r (x, y) r (y,
      z)\\
  \subset & q_{\Delta t} (x|z) \pi (z)
\end{array}\)
    </center>
    <p>
      Following the same steps, we can show that all terms in equation <a
      href="#equation:transition rate determines transition density">6</a> share the same relation, indicating \(q_{\Delta t} (z|x) \pi
      (x) = q_{\Delta t} (x|z) \pi (z)\).
    </p>
    <h3 id="auto-11"><a id="section: Detailed Balance Condition and Connectivity Monotonically Reduce Relative Entropy"></a>2.5<span style="margin-left: 1em"></span>Detailed Balance with
    Connectivity Monotonically Reduces Relative Entropy<span style="margin-left: 1em"></span></h3>
    <p>
      Given the time \(t\), if the time-dependent distribution \(P (t)\) and
      the stationary distribution \(\Pi\) share the same alphabet
      \(\mathcal{X}\), which means \(p (x, t) > 0\) and \(\pi (x) > 0\) for
      each \(x \in \mathcal{X}\), we have defined the relative entropy between
      them, as
    </p>
    <table width="100%">
      <tr>
        <td width="100%" align="center">\(\displaystyle H (P (t), \Pi) = \int_{\mathcal{X}}
        \mathrm{d} x p (x, t) \ln \frac{p (x,
t)}{\pi (x)} .\)</td>
        <td align="right">(10)</td>
      </tr>
    </table>
    <p>
      It describes the uncertainty (surprise) caused by \(P (t)\) when prior
      knowledge is given by \(\Pi\). It is a plausible generalization of
      Shannon entropy to continuous random variables.
    </p>
    <p>
      We can calculate the time-derivative of relative entropy by master
      equation
      <a href="#equation:master equation">4</a>
      . Generally, the time-derivative of relative entropy has no interesting
      property. But, if the \(\pi\) is more than stationary but satisfying a
      stronger condition: detailed balance, then \(\mathrm{d} H (P (t), \Pi) /
      \mathrm{d} t\) will have a regular form
      <div class="footnote">
        <font style="font-size: 77.1%"><div align="justify">
          <div style="margin-left: 0px">
            <div style="margin-right: 0px">
              <class style="font-style: normal"><p>
                6. The proof is given as follow. Directly, we have
              </p><center>
                \(\displaystyle \begin{array}{rl}
 
                \frac{\mathrm{d}}{\mathrm{d} t} H (P (t), \Pi) = &
 
                \frac{\mathrm{d}}{\mathrm{d} t} \int_{\mathcal{X}} \mathrm{d}
                x [p (x, t)
  \ln p (x, t) - p (x, t) \ln \pi (x)]\\
  = &
                \int_{\mathcal{X}} \mathrm{d} x \left( \frac{\partial
                p}{\partial t} (x,
  t) \ln p (x, t) + \frac{\partial
                p}{\partial t} (x, t) - \frac{\partial
  p}{\partial t} (x, t)
                \ln \pi (x) \right) .
\end{array}\)
              </center><p>
                Since \(\int_{\mathcal{X}} \mathrm{d} x (\partial p / \partial
                t) (x, t) = (\partial /
\partial t) \int_{\mathcal{X}}
                \mathrm{d} x p (x, t) = 0\), the second term vanishes. Then,
                we get
              </p><center>
                \(\displaystyle \frac{\mathrm{d}}{\mathrm{d} t} H (P (t), \Pi)
                = \int_{\mathcal{X}} \mathrm{d}
x \frac{\partial p}{\partial
                t} (x, t) \ln \frac{p (x, t)}{\pi (x)} .\)
              </center><p>
                Now, we replace \(\partial p / \partial t\) by master equation
                <a href="#equation:master equation">4</a>, as
              </p><center>
                \(\displaystyle \frac{\mathrm{d}}{\mathrm{d} t} H (P (t), \Pi)
                = \int_{\mathcal{X}} \mathrm{d}
x \int_{\mathcal{X}}
                \mathrm{d} y [r (x, y) p (y, t) - r (y, x) p (x, t)]
                \ln
\frac{p (x, t)}{\pi (x)},\)
              </center><p>
                Then, insert detailed balance condition \(r (y, x) = r (x, y)
                \pi (y) / \pi (x)\), as
              </p><center>
                \(\displaystyle \begin{array}{rl}
 
                \frac{\mathrm{d}}{\mathrm{d} t} H (P (t), \Pi) = &
                \int_{\mathcal{X}}
  \mathrm{d} x \int_{\mathcal{X}}
                \mathrm{d} y \left( r (x, y) p (y, t) - r
  (x, y) \pi (y)
                \frac{p (x, t)}{\pi (x)} \right) \ln \frac{p (x, t)}{\pi
 
                (x)}\\
  = & \int_{\mathcal{X}} \mathrm{d} x
                \int_{\mathcal{X}} \mathrm{d} y r (x, y)
  \pi (y) \left(
                \frac{p (y, t)}{\pi (y)} - \frac{p (x, t)}{\pi (x)} \right)
 
                \ln \frac{p (x, t)}{\pi (x)} .
\end{array}\)
              </center><p>
                Since \(x\) and \(y\) are dummy, we interchange them in the
                integrand, and then insert detailed balance condition again,
                as
              </p><center>
                \(\displaystyle \begin{array}{rl}
 
                \frac{\mathrm{d}}{\mathrm{d} t} H (P (t), \Pi) = &
                \int_{\mathcal{X}}
  \mathrm{d} x \int_{\mathcal{X}}
                \mathrm{d} y r (y, x) \pi (x) \left( \frac{p
  (x, t)}{\pi
                (x)} - \frac{p (y, t)}{\pi (y)} \right) \ln \frac{p (y,
                t)}{\pi
  (y)}\\
  \{
                \operatorname{detailed}\operatorname{balance} \} = &
                \int_{\mathcal{X}}
  \mathrm{d} x \int_{\mathcal{X}}
                \mathrm{d} y r (x, y) \pi (y) \left( \frac{p
  (x, t)}{\pi
                (x)} - \frac{p (y, t)}{\pi (y)} \right) \ln \frac{p (y,
                t)}{\pi
  (y)} .
\end{array}\)
              </center><p>
                By adding the two previous results together, we find
              </p><center>
                \(\displaystyle \begin{array}{rl}
  & 2
                \frac{\mathrm{d}}{\mathrm{d} t} H (P (t), \Pi)\\
 
                {}[1\operatorname{st}\operatorname{result}] = &
                \int_{\mathcal{X}}
  \mathrm{d} x \int_{\mathcal{X}}
                \mathrm{d} y r (x, y) \pi (y) \left( \frac{p
  (y, t)}{\pi
                (y)} - \frac{p (x, t)}{\pi (x)} \right) \ln \frac{p (x,
                t)}{\pi
  (x)}\\
  {}[2\operatorname{nd}\operatorname{result}]
                + & \int_{\mathcal{X}}
  \mathrm{d} x \int_{\mathcal{X}}
                \mathrm{d} y r (x, t) \pi (y) \left( \frac{p
  (x, t)}{\pi
                (x)} - \frac{p (y, t)}{\pi (y)} \right) \ln \frac{p (y,
                t)}{\pi
  (y)}\\
  = & - \int_{\mathcal{X}} \mathrm{d} x
                \int_{\mathcal{X}} \mathrm{d} y r (x,
  y) \pi (y) \left(
                \frac{p (x, t)}{\pi (x)} - \frac{p (y, t)}{\pi (y)}
  \right) 
                \left( \ln \frac{p (x, t)}{\pi (x)} - \ln \frac{p (y, t)}{\pi
                (y)}
  \right),
\end{array}\)
              </center><p>
                from which we directly get the result. Notice that this proof
                is very tricky: it uses detailed balance condition twice,
                between which the expression is symmetrized. It is an
                ingenious mathematical engineering.
              </p></class>
            </div>
          </div>
        </div></font>
      </div>
      <span style="margin-left: 0em"></span>
      <a id="footnr-6"></a>
      <sup><class style="font-style: normal"><a href="#footnote-6">6</a></class></sup>
    </p>
    <table width="100%">
      <tr>
        <td width="100%" align="center">\(\displaystyle \frac{\mathrm{d}}{\mathrm{d} t} H (P
        (t), \Pi) = - \frac{1}{2}
\int_{\mathcal{X}} \mathrm{d} x
        \int_{\mathcal{X}} \mathrm{d} y r (x, y) \pi
(x) \left( \frac{p (x,
        t)}{\pi (x)} - \frac{p (y, t)}{\pi (y)} \right)  \left(
\ln \frac{p
        (x, t)}{\pi (x)} - \ln \frac{p (y, t)}{\pi (y)} \right) . \)</td>
        <td align="right">(11)</td>
      </tr>
    </table>
    <p>
      
    </p>
    <p>
      We are to check the sign of the integrand. The \(r (x, y)\) is negative
      only when \(x = y\), on which the integrand vanishes. Thus, \(r (x, y)\)
      can be treated as non-negative, so is the \(r (x, y) \pi (y)\) (since
      \(\pi (x) > 0\) for all \(x \in \mathcal{X}\)). Now, we check the sign
      of the last two terms. If \(p (x, t) / \pi (x) > p (y, t) / \pi (y)\),
      then \(\ln [p (x, t) / \pi (x)] > \ln [p (y, t) / \pi (y)]\), thus the
      sign of the last two terms is positive. The same goes for \(p (x, t) /
      \pi (x) < p (y, t) / \pi (y)\). Only when \(p (x, t) / \pi (x) = p (y,
      t) / \pi (y)\) can it be zero. Altogether, the integrand is
      non-positive, thus \(\mathrm{d} H / \mathrm{d} t \leqslant 0\).
    </p>
    <p>
      The integrand vanishes when either \(r (x, y) = 0\) or \(p (x, t) / \pi
      (x) = p (y, t) / \pi (y)\). If \(r (x, y) > 0\) for each \(x \neq y\),
      then \((\mathrm{d} / \mathrm{d} t) H (P (t), \Pi) = 0\) only when \(p
      (x, t) / \pi (x) = p (y, t) / \pi (y)\) for all \(x, y \in
      \mathcal{X}\), which implies that \(p (\cdot, t) = \pi\) (since
      \(\)\(\int_{\mathcal{X}} \mathrm{d} x p (x, t) = \int_{\mathcal{X}}
      \mathrm{d} x \pi
(x) = 1\)), or \(P (t) = \Pi\).
    </p>
    <p>
      Contrarily, if \(r (x, y) = 0\) on some subset \(U \subset \mathcal{X}
      \times \mathcal{X}\), it seems that \((\mathrm{d} / \mathrm{d} t) H (P
      (t), \Pi) = 0\) cannot imply \(p (x, t) / \pi (x) = p (y, t) / \pi (y)\)
      on \(U\). But, if there is a \(z \in \mathcal{X}\) such that both \((x,
      z)\) and \((y, z)\) are not in \(U\), then \((\mathrm{d} / \mathrm{d} t)
      H (P (t), \Pi) = 0\) implies \(p (x, t) / \pi (x) = p (z, t) / \pi (z)\)
      and \(p (y, t) / \pi (y) = \pi (z, t) / \pi (z)\), thus implies \(p (x,
      t) / \pi (x) = p (y, t) / \pi (y)\). It hints for connectivity.
      Precisely, for each \(x, z \in \mathcal{X}\), if there is a series
      \((y_1, \ldots, y_n)\) from \(x\) (\(y_1 := x\)) to \(z\) (\(y_n := z\))
      with both \(r (y_{i + 1}, y_i)\) and \(r (y_i, y_{i + 1})\) are positive
      for each \(i\), then we say \(x\) and \(z\) are
      <b>connected</b>
      , and the series is called a
      <b>path</b>
      . It means
      <em>there are densities transiting along the forward and backward
      directions of the path</em>
      . In this situation, \((\mathrm{d} / \mathrm{d} t) H (P (t), \Pi) = 0\)
      implies \(p (x, t) / \pi (x) = p (z, t) / \pi (z)\).
      <div class="footnote">
        <font style="font-size: 77.1%"><div align="justify">
          <div style="margin-left: 0px">
            <div style="margin-right: 0px">
              <class style="font-style: normal"><p>
                7. We have, along the path, \(p (y_1, t) / \pi (y_1) = p (y_2,
                t) / \pi (y_2) = \cdots = p (y_n, t) / \pi
(y_n)\), thus \(p
                (x, t) / \pi (x) = p (z, t) / \pi (z)\) since \(x = y_1\) and
                \(z = y_n\).
              </p></class>
            </div>
          </div>
        </div></font>
      </div>
      <span style="margin-left: 0em"></span>
      <a id="footnr-7"></a>
      <sup><class style="font-style: normal"><a href="#footnote-7">7</a></class></sup>
      So, by repeating the previous discussion on the case &ldquo;\(r (x, y)
      > 0\) for each \(x \neq y\)&rdquo;, we find \(P (t) = \Pi\) at
      \((\mathrm{d} / \mathrm{d} t) H (P (t), \Pi) = 0\) if every two elements
      in \(\mathcal{X}\) are connected.
    </p>
    <p>
      Let us examine the connectivity further. We additionally <i>define</i>
      that every element in \(\mathcal{X}\) is connected to itself, then
      connectivity forms an equivalence relation. So, it separates
      \(\mathcal{X}\) into subsets (equivalence classes) \(\mathcal{X}_1,
      \ldots, \mathcal{X}_n\) with \(\mathcal{X}_i \cap \mathcal{X}_j =
      \varnothing\) for each \(i \neq j\) and \(\mathcal{X}= \cup_{i = 1}^n
      \mathcal{X}_i\). In each subset \(\mathcal{X}_i\), every two elements
      are connected. In this way, the whole random system are separated into
      many independent subsystems. The distributions \(P_i (t)\) and \(\Pi_i\)
      defined in the subsystem \(i\) have the alphabet \(\mathcal{X}_i\) and
      densities functions \(p_i (x, t) := p (x, t) / \int_{\mathcal{X}_i}
      \mathrm{d} x p (x, t)\) and \(\pi_i (x) := \pi (x) /
      \int_{\mathcal{X}_i} \mathrm{d} x \pi (x)\) respectively (the
      denominators are used for normalization). Applying the previous
      discussion to this subsystem, we find \(P_i (t) = \Pi_i\) at
      \((\mathrm{d} / \mathrm{d} t) H (P_i (t), \Pi_i) = 0\).
    </p>
    <p>
      So, for the whole random system or each of its subsystems, the following
      theorem holds.
    </p>
    <p style="margin-top: 1em; margin-bottom: 1em">
      <strong>Theorem <class style="font-style: normal">1</class>. </strong><i><a id="theorem: relaxation"></a>Let
      \(\Pi\) a distribution with alphabet \(\mathcal{X}\). If there is a
      transition rate r such that 1) every two elements in \(\mathcal{X}\) are
      connected and that 2) the detailed balance condition <a href="#equation:Detailed Balance">8</a>
      holds for \(\Pi\) and \(r\), then for any time-dependent distribution
      \(P (t)\) with the same alphabet (at one time) evolved by the master
      equation <a href="#equation:master equation">4</a>, \(P (t)\) will monotonically and constantly
      relax to \(\Pi\).</i>
    </p>
    <p>
      Many textures use Fokker-Planck equation to prove the monotonic
      reduction of relative entropy. After an integration by parts, they
      arrive at a negative definite expression, which means the monotonic
      reduction. This proof needs smooth structure on \(X\), which is
      essential for integration by parts. In this section, we provides a more
      generic alternative to the proof, for which smooth structure on \(X\) is
      unnecessary.
    </p>
    <h3 id="auto-12"><a id="section: Monte-Carlo Simulation and Guarantee of Relaxation"></a>2.6<span style="margin-left: 1em"></span>Monte-Carlo Simulation and
    Guarantee of Relaxation<span style="margin-left: 1em"></span></h3>
    <p>
      How to numerically simulate the evolution of master equation
      <a href="#equation:master equation">4</a>
      that tends to equilibrium (without which the simulation will not
      terminate)? Using the metaphor of sands (see section
      <a href="#section: Master Equation Describes the Evolution of Markov Process">2.2</a>
      ), we simulate each sand, but replace its free will by a transition
      probability. Explicitly, we initialize the sands (that is, their
      positions) randomly. Then iteratively update the position of each sand.
      In each iteration, a sand jumps from position \(x\) to position \(y\)
      with the probability \(q_{\Delta t} (y|x) \approx \delta (y - x) + r (y,
      x) \Delta t\) where \(\Delta t\) is sufficiently small. Not every jump
      is valid. On one hand, we have to ensure that computer has a sampler
      that makes random sampling for \(q_{\Delta t} (y|x)\). On the other
      hand, to ensure the termination, the transition rate \(r\), together
      with the density function \(\pi\), shall satisfy the detailed balance
      condition
      <a href="#equation:Detailed Balance">8</a>
      . (Section
      <a href="#section: Example: Metropolis-Hastings Algorithm">2.7</a>
      will provide a method that constructs such a transition rate from the
      density function.) Then, we
      <em>expect</em>
      that the simulation will iteratively decrease the difference between
      the distribution of the sands and the \(\Pi\). We terminate the
      iteration when they have been close enough. In this way, we simulate a
      collection of sands evolves with the master equation to equilibrium, and
      finally distributes as \(\Pi\). This process is called
      <strong>Monte-Carlo simulation</strong>
      , first developed by Stanislaw Ulam in 1940s while he was working on the
      project of nuclear weapons at Los Alamos National Laboratory. The name
      is in memory of Ulam's uncle who lost all his personal assets in Monte
      Carlo Casino, Monaco.
      <div class="footnote">
        <font style="font-size: 77.1%"><div align="justify">
          <div style="margin-left: 0px">
            <div style="margin-right: 0px">
              <class style="font-style: normal"><p>
                8. There are multiple motivations for Monte-Carlo simulation.
                An important one comes from numerical integration. The problem
                is calculating the integral \(\int_{\mathcal{X}} \mathrm{d} x
                \pi (x) f (x)\) for a density function \(\pi\) and an
                arbitrary function \(f : \mathcal{X} \rightarrow \mathbb{R}\).
                When \(\mathcal{X}\) has finite elements, this integral is
                easy to compute, which is \(\sum_{x \in \mathcal{X}} \pi (x) f
                (x)\). Otherwise, this integral will be intractable.
                Numerically, this integral becomes the expectation \((1 / |
                \mathcal{S} |) \sum_{x \in \mathcal{S}} f (x)\) where
                \(\mathcal{S}\) is a collection of elements randomly sampled
                from distribution \(\Pi\), whose density function is the
                \(\pi\). By central limit theorem (briefly, the mean of i.i.d.
                random variables \(X_1, \ldots, X_N\) with mean \(\mathbb{E}
                [X_i] = 0\) and variance \(\operatorname{Var} [X_i] =
                \sigma^2\) for some \(\sigma\), has standard derivation
                \(\sigma / \sqrt{N}\) when \(N\) is large enough), the
                numerical error \(\left| \int_{\mathcal{X}} \mathrm{d} x \pi
                (x) f (x) - (1 / | \mathcal{S} |)
\sum_{x \in \mathcal{S}} f
                (x) \right|\) is proportional to \(1 / \sqrt{| \mathcal{S}
                |}\), which can be properly bounded as long as \(| \mathcal{S}
                |\) is large enough. But, how to sample from a distribution if
                you only know its density function (recall in section <a href="#section: A Brief Review of Probability">1.1</a>,
                a distribution is the combination of its density function and
                its sampler)? The answer is using Monte-Carlo simulation.
              </p></class>
            </div>
          </div>
        </div></font>
      </div>
      <span style="margin-left: 0em"></span>
      <a id="footnr-8"></a>
      <sup><class style="font-style: normal"><a href="#footnote-8">8</a></class></sup>
    </p>
    <p>
      Like the Euler method in solving dynamical system, however, a finite
      time step results in a residual error. This residual error must be
      analyzed an controlled, so that the distribution will evolve toward
      \(\Pi\), as we have expected. To examine this, we calculate the \(H (P
      (t + \Delta t), \Pi) - H (P (t), \Pi)\) where \(\Delta t\) is small but
      still finite, and check when it is negative (such that \(H (P (t))\)
      monotonically decreases to \(P (t) \rightarrow \Pi\)).
    </p>
    <p>
      By definition, we have
    </p>
    <center>
      \(\displaystyle \Delta H := H (P (t + \Delta t), \Pi) - H (P (t), \Pi) =
      \int_{\mathcal{X}}
\mathrm{d} x p (x, t + \Delta t) \ln \frac{p (x, t +
      \Delta t)}{\pi (x)} -
\int_{\mathcal{X}} \mathrm{d} x p (x, t) \ln
      \frac{p (x, t)}{\pi (x)} .\)
    </center>
    <p>
      Inserting \({\int_{\mathcal{X}} \mathrm{d} x p (x, t + \Delta t) \ln (p
      (x, t) / \pi (x,
t))}\) gives
    </p>
    <center>
      \(\displaystyle \begin{array}{rl}
  \Delta H = & \int_{\mathcal{X}}
      \mathrm{d} x p (x, t + \Delta t) \ln \frac{p
  (x, t + \Delta t)}{\pi
      (x)} - {\int_{\mathcal{X}} \mathrm{d} x p (x, t +
  \Delta t) \ln
      \frac{p (x, t)}{\pi (x)}}\\
  + & {\int_{\mathcal{X}} \mathrm{d} x p (x,
      t + \Delta t) \ln \frac{p (x,
  t)}{\pi (x)}} - \int_{\mathcal{X}}
      \mathrm{d} x p (x, t) \ln \frac{p (x,
  t)}{\pi (x)}\\
  = &
      \int_{\mathcal{X}} \mathrm{d} x p (x, t + \Delta t) \ln \frac{p (x, t +

      \Delta t)}{p (x, t)}\\
  + & \int_{\mathcal{X}} \mathrm{d} x [p (x, t +
      \Delta t) - p (x, t)] \ln
  \frac{p (x, t)}{\pi (x)}
\end{array}\)
    </center>
    <p>
      The first line is recognized as \(H (P (t + \Delta t), P (t))\), which
      is non-negative. Following the same steps in section <a href="#section: Detailed Balance Condition and Connectivity Monotonically Reduce Relative Entropy">2.5</a>
      (but using discrete time master equation <a href="#equation:discrete time master equation">5</a> instead, and
      detailed balance condition <a href="#equation:Detailed Balance for transition density">9</a> for transition density), the
      second line reduces to
    </p>
    <center>
      \(\displaystyle - \frac{1}{2} \int_{\mathcal{X}} \mathrm{d} x
      \int_{\mathcal{X}} \mathrm{d} y
q_{\Delta t} (x|y) \pi (y) \left(
      \frac{p (x, t)}{\pi (x)} - \frac{p (y,
t)}{\pi (y)} \right) \left( \ln
      \frac{p (x, t)}{\pi (x)} - \ln \frac{p (y,
t)}{\pi (y)} \right),\)
    </center>
    <p>
      which is non-positive (suppose that \(r\) connects every two elements in
      \(\mathcal{X}\)). So, the sign of \(\Delta H\) is determined by that
      which line has greater absolute value. The first line depends only on
      the difference between \(P (t)\) and \(P (t + \Delta t)\), thus \(\Delta
      t\), while the second line additionally depends on the difference
      between \(P (t)\) and \(\Pi\) (the factor \(q_{\Delta t} (x|y)\) also
      depends on \(\Delta t\)). When \(\Delta t \rightarrow 0\), the first
      line vanishes, while the second does not until \(P (t) \rightarrow
      \Pi\). This suggests us to investigate how fast each term converges as
      \(\Delta t \rightarrow 0\).
    </p>
    <p>
      To examine the speed of convergence, we calculate the leading order of
      \(\Delta t\) in each line. To make it clear, we denote the first line by
      \(\Delta H_1\) and the second line \(\Delta H_2\). Taylor expanding
      \(\Delta H_1\) by \(\Delta t\) gives
      <div class="footnote">
        <font style="font-size: 77.1%"><div align="justify">
          <div style="margin-left: 0px">
            <div style="margin-right: 0px">
              <class style="font-style: normal"><p>
                9. The first line
              </p><center>
                \(\displaystyle \Delta H_1 := \int_{\mathcal{X}} \mathrm{d} x
                p (x, t + \Delta t) \ln \frac{p
(x, t + \Delta t)}{p (x, t)}\)
              </center><p>
                To Taylor expand the right hand side by \(\Delta t\), we
                expand \(p (x, t + \Delta t)\) to \(\omicron (\Delta t^2)\),
                as
              </p><p>
                <font color="#000080"><center>
                  \(\displaystyle p (x, t + \Delta t) = p (x, t) + \Delta t
                  \frac{\partial p}{\partial t} (x, t)
+ \frac{\Delta t^2}{2!}
                  \frac{\partial^2 p}{\partial t^2} (x, t) + \omicron
(\Delta
                  t^2),\)
                </center></font>
              </p><p>
                and the same for \(\ln p (x, t + \Delta t)\), as
              </p><center>
                \(\displaystyle \ln p (x, t + \Delta t) = \ln p (x, t) +
                \Delta t \frac{\partial}{\partial t}
\ln p (x, t) +
                \frac{\Delta t^2}{2!} \frac{\partial^2}{\partial t^2} \ln p
                (x,
t) + \omicron (\Delta t^2) .\)
              </center><p>
                Plugging in \((\mathrm{d} / \mathrm{d} x) \ln f (x) = f' (x) /
                f (x)\) and then \((\mathrm{d}^2 / \mathrm{d} x^2) \ln f (x) =
                f'' (x) / f (x) - (f' (x) / f
(x))^2\), we find
              </p><center>
                \(\displaystyle {\ln p (x, t + \Delta t) - \ln p (x, t) =
                \Delta t \left[ \frac{\partial
p}{\partial t} p (x, t) p^{- 1}
                (x, t) \right] + \frac{\Delta t^2}{2}  \left[
\frac{\partial^2
                p}{\partial t^2} (x, t) p^{- 1} (x, t) - \left(
\frac{\partial
                p}{\partial t} (x, t) p^{- 1} \right)^2 \right] +
                \omicron
(\Delta t^2) .}\)
              </center><p>
                So, the \(\Delta t\) order term in \(\Delta H_1\) is
              </p><center>
                \(\displaystyle \int_{\mathcal{X}} \mathrm{d} x
                {{\color{blue}{p (x, t)}}}  {\left[
\frac{\partial p}{\partial
                t} p (x, t) p^{- 1} (x, t) \right]} =
\int_{\mathcal{X}}
                \mathrm{d} x \frac{\partial p}{\partial t} p (x, t)
                =
\frac{\partial}{\partial t} \int_{\mathcal{X}} \mathrm{d} x
                p (x, t) = 0,\)
              </center><p>
                where we used the normalization of \(p\). The \(\Delta t^2\)
                term in \(\Delta H_1\) is
              </p><center>
                \(\displaystyle \int_{\mathcal{X}} \mathrm{d} x {p (x, t)} 
                {\frac{1}{2} \left[
\frac{\partial^2 p}{\partial t^2} (x, t)
                p^{- 1} (x, t) - \left(
\frac{\partial p}{\partial t} p (x, t)
                p^{- 1} (x, t) \right)^2 \right]} +
{\frac{\partial
                p}{\partial t} (x, t)}  {p^{- 1} (x, t) 
                \frac{\partial
p}{\partial t} (x, t)} .\)
              </center><p>
                Using the normalization of \(p\) as before, it is reduced to
              </p><center>
                \(\displaystyle \frac{1}{2} \int_{\mathcal{X}} \mathrm{d} x p
                (x, t)  \left( \frac{\partial
p}{\partial t} p (x, t) p^{- 1}
                (x, t) \right)^2 = \frac{1}{2}
\int_{\mathcal{X}} \mathrm{d} x
                p (x, t)  \left( \frac{\partial}{\partial t}
\ln p (x, t)
                \right)^2 .\)
              </center><p>
                Altogether, we arrive at
              </p><center>
                \(\displaystyle \Delta H_1 = \frac{\Delta t^2}{2}
                \int_{\mathcal{X}} \mathrm{d} x p (x, t) 
\left(
                \frac{\partial}{\partial t} \ln p (x, t) \right)^2 + \omicron
                (\Delta
t^2) .\)
              </center></class>
            </div>
          </div>
        </div></font>
      </div>
      <span style="margin-left: 0em"></span>
      <a id="footnr-9"></a>
      <sup><class style="font-style: normal"><a href="#footnote-9">9</a></class></sup>
    </p>
    <center>
      \(\displaystyle \Delta H_1 = \frac{\Delta t^2}{2} \int_{\mathcal{X}}
      \mathrm{d} x p (x, t) 
\left( \frac{\partial}{\partial t} \ln p (x, t)
      \right)^2 + \omicron (\Delta
t^2),\)
    </center>
    <p>
      where, by master equation <a href="#equation:master equation">4</a>, \((\partial / \partial t) \ln
      p (x, t) = \int_{\mathcal{X}} \mathrm{d} x r (x,
y) p (y, t) / p (x,
      t)\). For \(\Delta H_2\), we insert equation <a href="#equation:relative entropy derivative">11</a> after
      Taylor expanding \(q_{\Delta t}\) by \(\Delta t\), and obtain
    </p>
    <center>
      \(\displaystyle \Delta H_2 = \Delta t \frac{\mathrm{d}}{\mathrm{d} t} H
      (P (t), \Pi) +
\omicron (\Delta t) .\)
    </center>
    <p>
      We find \(\Delta H_1\) converges with speed \(\Delta t^2\) while
      \(\Delta H_2\) has speed \(\Delta t\).
    </p>
    <p>
      Thus, given \(P (t) \neq \Pi\) (so that \(\Delta H_2 \neq 0\), recall
      section <a href="#section: Detailed Balance Condition and Connectivity Monotonically Reduce Relative Entropy">2.5</a>), there must be a \(\delta > 0\) such that for
      any \(\Delta t < \delta\), we have \(| \Delta H_1 | < | \Delta H_2 |\),
      in which case the \(\Delta H = \Delta H_1 + \Delta H_2 < 0\) (recall
      that \(\Delta H_1 \geqslant 0\) and \(\Delta H_2 \leqslant 0\)). The
      \(\delta\) is bounded by
    </p>
    <center>
      \(\displaystyle \delta \leqslant \left[ - \frac{\mathrm{d}}{\mathrm{d}
      t} H (P (t), \Pi)
\right] / \left[ \frac{1}{2} \int_{\mathcal{X}}
      \mathrm{d} x p (x, t)  \left(
\frac{\partial}{\partial t} \ln p (x, t)
      \right)^2 \right] .\)
    </center>
    <p>
      This bound is proportional to the difference between \(P (t)\) and
      \(\Pi\) (represented by the first factor). When \(P (t)\) has approached
      \(\Pi\) (that is, \(P (t) \approx \Pi\) but not exactly equal),
      \(\delta\) has to be extremely small. (This is a little like supervised
      machine learning where \(\Delta t\) acts as learning rate and \(H (P
      (t), \Pi)\) as loss. In the early stage of training, the loss function
      has a greater slope and we can safely employ a relatively larger
      learning rate to speed up the decreasing of loss. But, we have to tune
      the learning rate to be smaller and smaller during the training, in
      which the slope of loss function is gradually decreasing. Otherwise, the
      loss will not decrease but keep fluctuating when it has been
      sufficiently small, since the learning rate now becomes relatively too
      big.)
    </p>
    <h3 id="auto-13"><a id="section: Example: Metropolis-Hastings Algorithm"></a>2.7<span style="margin-left: 1em"></span>Example: Metropolis-Hastings
    Algorithm<span style="margin-left: 1em"></span></h3>
    <p>
      Metropolis-Hastings algorithm is a simple method that constructs
      transition rate for any given stationary distribution such that detailed
      balance condition holds. Explicitly, given a stationary distribution
      \(\Pi\), and an auxiliary transition rate \(\gamma\), ensuring that
      \(\gamma (x, y) > 0\) for each \(x\) and \(y\) in alphabet
      \(\mathcal{X}\) such that \(x \neq y\), the transition rate \(r\) is
      given by
    </p>
    <table width="100%">
      <tr>
        <td width="100%" align="center">\(\displaystyle r (x, y) = \min \left( 1,
        \frac{\gamma (y, x) \pi (x)}{\gamma (x, y) \pi (y)}
\right) \gamma (x,
        y) . \)</td>
        <td align="right">(12)</td>
      </tr>
    </table>
    <p>
      This transition rate connects every two elements in \(\mathcal{X}\)
      (since \(\gamma (y, x) > 0\) for each \(x \neq y\)). In addition,
      together with \(\pi\), it satisfies the detailed balance condition <a
      href="#equation:Detailed Balance">8</a>. Directly,
    </p>
    <center>
      \(\displaystyle \begin{array}{rl}
  & r (x, y) \pi (y)\\
  \{
      \operatorname{definition}\operatorname{of}r \} = & \min \left( 1,
 
      \frac{\gamma (y, x) \pi (x)}{\gamma (x, y) \pi (y)} \right) \gamma (x,
      y)
  \pi (y)\\
  \{ \operatorname{property}\operatorname{of} \min \} = &
      \min (\gamma (x, y)
  \pi (y), \gamma (y, x) \pi (x))\\
  \{
      \operatorname{property}\operatorname{of} \min \} = & \min \left(
 
      \frac{\gamma (x, y) \pi (y)}{\gamma (y, x) \pi (x)}, 1 \right) \gamma
      (y, x)
  \pi (x)\\
  \{ \operatorname{definition}\operatorname{of}r \} =
      & r (y, x) \pi (x) .
\end{array}\)
    </center>
    <p>
      Thus detailed balance condition holds. So, theorem <a href="#theorem: relaxation">1</a> states
      that, <em>evolved by the master equation <a href="#equation:master equation">4</a>, any initial
      distribution will finally relax to the stationary distribution
      \(\Pi\)</em>.
    </p>
    <p>
      Metropolis-Hastings algorithm was first proposed by Nicholas Metropolis
      and others in 1953 in Los Alamos, and then improved by Canadian
      statistician Wilfred Hastings in 1970. This algorithm was first defined
      for transition density. Together with a positive auxiliary transition
      density \(g\), the transition density is defined as
    </p>
    <table width="100%">
      <tr>
        <td width="100%" align="center">\(\displaystyle q (x|y) := \min \left( 1, \frac{g
        (y|x) \pi (x)}{g (x|y) \pi (y)} \right) g
(x|y), \)</td>
        <td align="right">(13)</td>
      </tr>
    </table>
    <p>
      where \(g\) is positive-definite on \(\mathcal{X}\). Notice that, in
      equation <a href="#equation:metropolis-hastings origin">13</a> there is no extra time parameter like the
      \(q_{\Delta t} (x|y)\) in section <a href="#section: Master Equation Describes the Evolution of Markov Process">2.2</a>. It can be seen as a
      fixed time interval, which can only be used for discrete time master
      equation.
    </p>
    <p>
      This definition has an intuitive and practical explanation. The two
      factors can be seen as two conditional probability. The factor \(g
      (x|y)\) first proposes a transition from \(y\) to \(x\). (In numerical
      simulation, we have to ensure that computer has a sampler for sampling
      an \(x\) from the conditional probability \(g (x|y)\).) Then, this
      proposal will be accepted by Bernoulli probability with the ratio given
      by the first factor in the right hand side. If accepted, then transit to
      \(x\), otherwise stay on \(y\). Altogether, we get a conditional
      probability jumping from \(y\) to \(x\), the \(q (x|y)\).
    </p>
    <p>
      It is straight forward to check that, if, in addition, \(g\) smoothly
      depends on a parameter \(\Delta t\) as \(g_{\Delta t}\), so is \(q\) as
      \(q_{\Delta t}\), and if we expand \(g_{\Delta t}\) at \(\Delta t
      \rightarrow 0\) as \(g_{\Delta t} (x|y) = \delta (x - y) + \gamma (x, y)
      \Delta t + \omicron
(\Delta t)\), then we will find \(q_{\Delta t} (x|y)
      = \delta (x - y) + r (x, y) \Delta t + \omicron (\Delta t)\). Indeed,
      when \(x = y\), we have \(q_{\Delta t} (x|x) = g_{\Delta t} (x, x)\).
      And when \(x \neq y\), \(\delta (x - y) = 0\), we find
    </p>
    <center>
      \(\displaystyle q_{\Delta t} (x|y) = \left[ \min \left( 1, \frac{\gamma
      (y, x) \pi (x) +
\omicron (1)}{\gamma (x, y) \pi (y) + \omicron (1)}
      \right)  (\gamma (x, y) +
\omicron (1)) \right] \Delta t.\)
    </center>
    <p>
      Altogether, for each \(x, y \in \mathcal{X}\), we find \(q_{\Delta t}
      (x|y) = \delta (x - y) + r (x, y) \Delta t + \omicron (\Delta t)\).
      <em>In practice, we use the Metropolis-Hastings algorithm <a href="#equation:metropolis-hastings origin">13</a>
      to numerically simulate master equation <a href="#equation:master equation">4</a>.</em> But, based
      on the discussion in section <a href="#section: Monte-Carlo Simulation and Guarantee of Relaxation">2.6</a>, the \(\Delta t\) in
      \(g_{\Delta t}\) shall be properly bounded to be small (or equivalently
      speaking, \(g\) shall be &ldquo;principal diagonal&rdquo;)  so as to
      ensure the relaxation \(P (t) \rightarrow \Pi\).
    </p>
    <h3 id="auto-14">2.8<span style="margin-left: 1em"></span>* Existence of Stationary Density
    Function<span style="margin-left: 1em"></span></h3>
    <p>
      Given a transition rate, we wonder if there exists a density function
      such that detailed balance condition <a href="#equation:Detailed Balance">8</a> holds. Actually,
      equation <a href="#equation:Detailed Balance">8</a> <em>defines</em> a density function. For
      example, if both \(r (x, y)\) and \(r (y, x)\) are not zero, we can
      construct \(\pi (y)\) by given \(\pi (x)\) as \(\pi (y) = \pi (x) r (y,
      x) / r (x, y)\). Generally, if \(x\) and \(y\) are connected, then there
      is a path \(P := (p_0, \ldots, p_n)\) from \(x\) to \(y\) with \(p_0 =
      x\) and \(p_n = y\) (path and connectivity are defined in section <a
      href="#section: Detailed Balance Condition and Connectivity Monotonically Reduce Relative Entropy">2.5</a>), and define
    </p>
    <center>
      \(\displaystyle \begin{array}{rl}
  \pi (p_1) := & \pi (p_0) r (p_1,
      p_0) / r (p_0, p_1)\\
  \pi (p_2) := & \pi (p_1) r (p_2, p_1) / r (p_1,
      p_2)\\
  \ldots & \\
  \pi (p_n) := & \pi (p_{n - 1}) r (p_n, p_{n - 1})
      / r (p_{n - 1}, p_n) .
\end{array}\)
    </center>
    <p>
      Thus, \(\pi (y)\) (the \(\pi (p_n)\)) is constructed out of \(\pi (x)\)
      (the \(\pi (p_0)\)). Let \(\rho (x, y) := \ln r (x, y) - \ln r (y, x)\),
      it becomes
    </p>
    <center>
      \(\displaystyle \ln \pi (y) = \ln \pi (x) + \sum_{i = 0}^{n - 1} \rho
      (p_{i + 1}, p_i),\)
    </center>
    <p>
      or in continuous format,
    </p>
    <table width="100%">
      <tr>
        <td width="100%" align="center">\(\displaystyle \ln \pi (y) = \ln \pi (x) + \int_P
        \mathrm{d} s \rho (s), \)</td>
        <td align="right">(14)</td>
      </tr>
    </table>
    <p>
      where \(\rho (s)\) is short for \(\rho (p_{s + 1}, p_s)\) along the path
      \(P\). In this way, given \(x_0 \in \mathcal{X}\), we define any \(x \in
      \mathcal{X}\) that is connected to \(x_0\) by \(\ln \pi (x) := \ln \pi
      (x_0) + \int_P \mathrm{d} s \rho (s)\). And \(\pi (x_0)\) is determined
      by the normalization of \(\pi\).
    </p>
    <p>
      But, there can be multiple paths from \(x\) to \(y\) which are connected
      in \(\mathcal{X}\). For example, consider two paths \(P\) and \(P'\),
      then we have \(\int_P \mathrm{d} s \rho (s) = \int_{P'} \mathrm{d} s
      \rho (s)\). Generally, if \(C\) is a <strong>circle</strong> which is a
      path starting at an element \(x \in \mathcal{X}\) and finally end at
      \(x\) (but not simply standing at \(x\)), then
    </p>
    <table width="100%">
      <tr>
        <td width="100%" align="center">\(\displaystyle \oint_C \mathrm{d} s \rho (s) = 0.
        \)</td>
        <td align="right">(15)</td>
      </tr>
    </table>
    <p>
      It means every path along two connected elements in \(\mathcal{X}\) is
      equivalent. If the condition <a href="#equation:circle">15</a> holds, we can simplify the
      notation in equation <a href="#equation:define stationary density function">14</a> by
    </p>
    <center>
      \(\displaystyle \ln \pi (y) = \ln \pi (x) + \int_x^y \mathrm{d} s \rho
      (s),\)
    </center>
    <p>
      where \(\int_x^y\) indicates any path from \(x\) to \(y\) (if \(x\) and
      \(y\) are connected).
    </p>
    <p>
      Condition <a href="#equation:circle">15</a> implies that the previous construction does
      define a \(\pi\) that holds the detailed balance condition. Given \(x, y
      \in \mathcal{X}\), we have \(\ln \pi (x) = \ln \pi (x_0) + \int_{x_0}^x
      \mathrm{d} s \rho (s)\) and \(\ln \pi (y) = \ln \pi (x_0) + \int_{x_0}^y
      \mathrm{d} s \rho (s)\). If \(x\) and \(y\) are connected, then, by
      condition <a href="#equation:circle">15</a>,\(\) \(\rho (y, x) = \int_x^{x_0} \mathrm{d} s
      \rho (s) + \int_{x_0}^y \mathrm{d} s
\rho (s)\) (the \(\rho (y, x)\)
      indicates the path \((x, y)\), &ldquo;jumping&rdquo; directly from \(x\)
      to \(y\)), thus \(\ln \pi (y) = \ln \pi (x) + \rho (y, x)\), which is
      just the detailed balance condition <a href="#equation:Detailed Balance">8</a>. And if \(x\) and
      \(y\) are not connected, then both \(r (x, y)\) and \(r (y, x)\) shall
      vanish (recall the requirements of transition rate in section <a href="#section: Master Equation Describes the Evolution of Markov Process">2.2</a>:
      if \(r (x, y) = 0\), then \(r (y, x) = 0\)), and detailed balance
      condition holds naturally.
    </p>
    <p>
      So, condition <a href="#equation:circle">15</a> is <em>essential and sufficient for the
      existence of \(\pi\) that holds the detailed balance condition <a href="#equation:Detailed Balance">8</a></em>.
      If \(\mathcal{X}\) is a simply connected smooth manifold, then using
      Stokes's theorem, we have \(\nabla \times \rho = 0\) on \(\mathcal{X}\).
      But, generally \(\mathcal{X}\) is neither simply connected nor smooth,
      but involving independent subsystems and discrete. In these cases,
      condition <a href="#equation:circle">15</a> becomes very complicated.
    </p>
    <p>
      In many applications, we consider the inverse question: given a density
      function, if there exists a transition rate such that detailed balance
      condition holds. This inverse problem is much easier, and a proper
      transition rate can be constructed out of the density function (such as
      in Metropolis-Hastings algorithm).
    </p>
    <h2 id="auto-15"><a id="section: Kramers-Moyal Expansion and Langevin Process"></a>3<span style="margin-left: 1em"></span>Kramers-Moyal Expansion and
    Langevin Process<span style="margin-left: 1em"></span></h2>
    <p>
      We follow the discussion in section <a href="#section: Master Equation, Detailed Balance, and Relative Entropy">2</a>, but focusing on the
      specific situation where there is extra smooth structure on \(X\). This
      smoothness reflects on the connectivity of the alphabet \(\mathcal{X}\),
      and on the smooth &ldquo;spatial&rdquo; dependence of the density
      function and transition rate. This indicates that the conclusions in
      section <a href="#section: Master Equation, Detailed Balance, and Relative Entropy">2</a> hold in this section, but the inverse is not
      guaranteed.
    </p>
    <h3 id="auto-16">3.1<span style="margin-left: 1em"></span>Conventions in This Section<span style="margin-left: 1em"></span></h3>
    <p>
      Follow the conventions in section <a href="#section: Master Equation, Detailed Balance, and Relative Entropy">2</a>. In addition, we employ
      the <strong>Einstein convention</strong>. That is, we omit the sum
      notation for the duplicated indices as long as they are
      &ldquo;balanced&rdquo;. For example, \(x_{\alpha} y^{\alpha}\)
      represents \(\sum_{\alpha} x_{\alpha} y^{\alpha}\). The \(\alpha\)
      appears twice in the expression, once in subscript (the \(x_{\alpha}\))
      and once in superscript (the \(y^{\alpha}\)), for which we say indices
      are balanced. Expression like \(x_{\alpha} y_{\alpha}\), however, does
      not represent a summation over \(\alpha\), because indices are not
      balanced (both are subscript). A more complicated example is
      \(\partial_{\alpha} A^{\alpha}_{\beta} x^{\beta}\), which means
      \(\sum_{\alpha} \sum_{\beta} \partial_{\alpha} A^{\alpha}_{\beta}
      x^{\beta}\).
    </p>
    <h3 id="auto-17"><a id="section: Spatial Expansion of Master Equation Gives Kramers-Moyal Expansion"></a>3.2<span style="margin-left: 1em"></span>Spatial Expansion of Master
    Equation Gives Kramers-Moyal Expansion<span style="margin-left: 1em"></span></h3>
    <p>
      Let the alphabet \(\mathcal{X}=\mathbb{R}^n\) for some integer \(n
      \geqslant 1\), which has sufficient connectivity. In addition, suppose
      that the density function \(p (x, t)\) of a time-dependent distribution
      \(P (t)\) and the transition rate \(r (x, y)\) are smooth on \(x\) and
      \(y\). In this section, we investigate the direct results of spatial
      smoothness.
    </p>
    <p>
      Now, the master equation <a href="#equation:master equation">4</a> becomes
    </p>
    <center>
      \(\displaystyle \frac{\partial p}{\partial t} (x, t) =
      \int_{\mathbb{R}^n} \mathrm{d} y r (x,
y) p (y, t) .\)
    </center>
    <p>
      The spatial smoothness indicates that we can Taylor expand the right
      hand side to arbitrary order. The quantity that is used to perform the
      Taylor expansion neither \(x\) nor \(y\) since they are equally
      weighted, but their difference, \(\epsilon := x - y\). If we replace the
      \(y\) in the right hand side with \(x - \epsilon\), that is,
      \(\int_{\mathbb{R}^n} \mathrm{d} y r (x, y) p (y, t) =
      \int_{\mathbb{R}^n}
\mathrm{d} \epsilon r (x, x - \epsilon) p (x -
      \epsilon, t)\), and directly Taylor expand by \(\epsilon\), then we will
      get the leading term \(\int_{\mathbb{R}^n} \mathrm{d} \epsilon r (x, x)
      p (x, t)\), the result of which is unknown. What we have known is
      \(\int_{\mathbb{R}^n} \mathrm{d} \epsilon r (x + \epsilon, x) p (x, t)\)
      which is zero because of the &ldquo;normalization&rdquo; of transition
      density. So, we expect to Taylor expand by \(\epsilon\) that which
      results in a leading term \(\int_{\mathbb{R}^n} \mathrm{d} \epsilon r (x
      + \epsilon, x) p (x, t) .\) To do this, we need a little magic.
    </p>
    <p>
      First of all, we have the identity
    </p>
    <center>
      \(\displaystyle \int_{\mathbb{R}^n} \mathrm{d} \epsilon r (x, x -
      \epsilon) p (x - \epsilon,
t) = \int_{\mathbb{R}^n} \mathrm{d} \epsilon
      r ((x - \epsilon) + \epsilon, x -
\epsilon) p (x - \epsilon, t) .\)
    </center>
    <p>
      Next, we perform the magic. We first define \(\omega (x, \epsilon) := r
      (x + \epsilon, x)\), which the factor we want to obtain in the leading
      term. Then, the integral turns to be \(\int_{\mathbb{R}^n} \mathrm{d}
      \epsilon \omega (x - \epsilon, \epsilon) p (x -
\epsilon, t)\). The key
      is Taylor expanding by the \(\epsilon\) <em>in the first argument</em>
      of \(\omega (x - \epsilon, \epsilon)\) in addition to that in \(p (x -
      \epsilon, t)\). So, it becomes
    </p>
    <center>
      \(\displaystyle \int_{\mathbb{R}^n} \mathrm{d} \epsilon \omega (x,
      \epsilon) p (x, t) +
\int_{\mathbb{R}^n} \mathrm{d} \epsilon
      (\epsilon^{\alpha_1} \cdots
\epsilon^{\alpha_k}) \sum_{k = 1}^{+ \infty}
      \frac{(- 1)^k}{k!}  \left(
\frac{\partial}{\partial x^{\alpha_1}} \cdots
      \frac{\partial}{\partial
x^{\alpha_k}} \right)  [\omega (x, \epsilon) p
      (x, t)] .\)
    </center>
    <p>
      The leading term (the first one) vanishes, as expected. With some
      re-arrangement to the second term, and plugging it back to the right
      hand side of master equation, we find
    </p>
    <center>
      \(\displaystyle \frac{\partial p}{\partial t} (x, t) = \sum_{k = 1}^{+
      \infty} \frac{(-
1)^k}{k!}  \left( \frac{\partial}{\partial
      x^{\alpha_1}} \cdots
\frac{\partial}{\partial x^{\alpha_k}} \right) 
      \left[ p (x, t) 
\int_{\mathbb{R}^n} \mathrm{d} \epsilon
      (\epsilon^{\alpha_1} \cdots
\epsilon^{\alpha_k}) \omega (x, \epsilon)
      \right] .\)
    </center>
    <p>
      
    </p>
    <p>
      The integral \(\int_{\mathbb{R}^n} \mathrm{d} \epsilon
      (\epsilon^{\alpha_1} \cdots
\epsilon^{\alpha_k}) \omega (x, \epsilon)\)
      in the \([\cdots]\) factor has an intuitive meaning. Remind of \(\omega
      (x, \epsilon) = r (x + \epsilon, x)\) and \(q_{\Delta t} (x + \epsilon
      |x) = \delta (\epsilon) + r (x + \epsilon, x)
\Delta t + \omicron
      (\Delta t)\), we have
    </p>
    <center>
      \(\displaystyle \int_{\mathbb{R}^n} \mathrm{d} \epsilon
      (\epsilon^{\alpha_1} \cdots
\epsilon^{\alpha_k}) q_{\Delta t} (x +
      \epsilon |x) = \Delta t
\int_{\mathbb{R}^n} \mathrm{d} \epsilon
      (\epsilon^{\alpha_1} \cdots
\epsilon^{\alpha_k}) \omega (x, \epsilon) +
      \omicron (\Delta t) .\)
    </center>
    <p>
      So, \(\Delta t \int_{\mathbb{R}^n} \mathrm{d} \epsilon
      (\epsilon^{\alpha_1} \cdots
\epsilon^{\alpha_k}) \omega (x, \epsilon)\)
      is recognized as an approximation of the \(k\)-order correlation of
      \(\epsilon\) sampled from transition density \(q_{\Delta t} (x +
      \epsilon |x)\) (regarding \(q_{\Delta t} (x + \epsilon |x)\) as an
      \(x\)-dependent distribution \(Q_{\Delta t} (x)\) that samples
      \(\epsilon\)). We denote it by (\(K\) for the leading consonant of
      &ldquo;correlation&rdquo;)
    </p>
    <table width="100%">
      <tr>
        <td width="100%" align="center">\(\displaystyle K^{\alpha^1 \cdots \alpha^k} (x) :=
        \int_{\mathbb{R}^n} \mathrm{d} \epsilon
(\epsilon^{\alpha_1} \cdots
        \epsilon^{\alpha_k}) \omega (x, \epsilon) . \)</td>
        <td align="right">(16)</td>
      </tr>
    </table>
    <p>
      Finally, we arrive at
    </p>
    <table width="100%">
      <tr>
        <td width="100%" align="center">\(\displaystyle \frac{\partial p}{\partial t} (x, t)
        = \sum_{k = 1}^{+ \infty} \frac{(-
1)^k}{k!}  \left(
        \frac{\partial}{\partial x^{\alpha_1}} \cdots
\frac{\partial}{\partial
        x^{\alpha_k}} \right)  [K^{\alpha^1 \cdots \alpha^k}
(x) p (x, t)] .
        \)</td>
        <td align="right">(17)</td>
      </tr>
    </table>
    <p>
      This Taylor expansion of master equation is called the
      <b>Kramers&ndash;Moyal expansion</b>.
    </p>
    <h3 id="auto-18"><a id="section: From Brownian Motion to Central Limit Theorem"></a>3.3<span style="margin-left: 1em"></span>From Brownian Motion to Central
    Limit Theorem<span style="margin-left: 1em"></span></h3>
    <p>
      One important application of Kramers&ndash;Moyal expansion is Brownian
      motion. In 1827, botanist Robert Brown noticed that pollen particles
      automatically shakes in water. This phenomenon was first explained by
      Albert Einstein in 1905. He argued that the pollen particles are
      constantly stricken by water molecules.
    </p>
    <p>
      We are to quantitatively determine how a pollen particle moves in water.
      The random movement of a pollen particle can be characterized by a
      transition density \(q_{\Delta t} (x + \epsilon |x)\), where the pollen
      particle transits from \(x\) to \(x + \epsilon\) during time interval
      \(\Delta t\). For this transition density, we make two assumptions. The
      first comes from the observation that the pool under the microscope of
      Brown is much broader than the diameter of water molecule, and the
      temperature of water is uniform, so that a water molecule cannot
      distinguish where it locates, just like a boat floating on the ocean,
      because every place is the same. It indicates that the transition is
      homogeneous, namely, \(q_{\Delta t} (x + \epsilon |x)\) does not depend
      on \(x\). It, then, implies that the transition rate \(r (x + \epsilon,
      x)\) is independent of \(x\). This landscape also gives the other
      assumption that every direction is the same too: the transition is also
      isotropic. It indicates that \(\int_{\mathbb{R}^n} \mathrm{d} x
      q_{\Delta t} (x + \epsilon |x)
\epsilon^{\alpha} = 0\) for each
      \(\alpha\), since the water molecule cannot distinguish the direction
      \(- \epsilon^{\alpha}\) from \(\epsilon^{\alpha}\). With these two
      assumptions, the Kramers&ndash;Moyal expansion <a href="#equation:km expansion">17</a> becomes
    </p>
    <center>
      \(\displaystyle \frac{\partial p}{\partial t} (x, t) = \sum_{k = 2}^{+
      \infty} \frac{(-
1)^k}{k!} K^{\alpha^1 \cdots \alpha^k}  \left(
      \frac{\partial}{\partial
x^{\alpha_1}} \cdots \frac{\partial}{\partial
      x^{\alpha_k}} \right) p (x, t),\)
    </center>
    <p>
      where the \(k\) starts at \(2\) (since the assumption
      \(\int_{\mathbb{R}^n} \mathrm{d} x q_{\Delta t} (x + \epsilon
      |x)
\epsilon^{\alpha} = 0\) implies \(K^{\alpha} (x) = 0\)) and the
      \(K^{\alpha^1 \cdots \alpha^k} (x) := \int_{\mathbb{R}^n} \mathrm{d}
      \epsilon
(\epsilon^{\alpha_1} \cdots \epsilon^{\alpha_k}) r (x +
      \epsilon |x)\) is constant now (because the \(r (x + \epsilon, x)\) is
      independent of \(x\)).
    </p>
    <p>
      Now, we are to examine the \(K\) carefully. It is determined by
      transition rate, that is, by the transition where \(\Delta t\) is
      infinitesimal (at least sufficiently small). In this situation, there
      will be at most one water molecule that strikes the pollen particle, so
      that the typical scale of \(\epsilon\) is extremely tiny (much smaller
      than the capacity of Brown's microscope). So, we have \(K^{\alpha_1
      \cdots \alpha_k} \gg K^{\alpha_1 \cdots \alpha_k \alpha_{k + 1}}\) for
      any \(k \geqslant 2\) since the later contains more \(\epsilon\) (\(k =
      1\) is not so because \(K^{\alpha} = 0\)). This leads to a valid
      approximation
    </p>
    <center>
      \(\displaystyle \frac{\partial p}{\partial t} (x, t) = \frac{1}{2}
      K^{\alpha \beta}  \left(
\frac{\partial}{\partial x^{\alpha}}
      \frac{\partial}{\partial x^{\beta}}
\right) p (x, t),\)
    </center>
    <p>
      where only the leading term \(k = 2\) remains. This equation is the
      famous heat equation, first developed by French mathematician Joseph
      Fourier in 1822. For initial value \(p (x, 0)\), it has the solution
    </p>
    <center>
      \(\displaystyle p (x, t) = \frac{1}{\sqrt{(2 \pi t)^n \det (K)}}
      \int_{\mathbb{R}^n}
\mathrm{d} y \exp \left( - \frac{1}{2 t} (K^{-
      1})_{\alpha \beta}  (x^{\alpha}
- y^{\alpha})  (x^{\beta} - y^{\beta})
      \right) p (y, 0),\)
    </center>
    <p>
      where the factor \(1 / \sqrt{\cdots}\) comes from normalization
      \(\int_{\mathbb{R}^n} \mathrm{d} x p (x, t) = 1\). Recall the (discrete
      time) master equation <a href="#equation:discrete time master equation">5</a>, \(p (x, \Delta t) =
      \int_{\mathbb{R}^n} \mathrm{d} y q_{\Delta t} (x|y) p (y, 0)\). The
      transition rate of pollen particle can be readily read out as
    </p>
    <table width="100%">
      <tr>
        <td width="100%" align="center">\(\displaystyle q_{\Delta t} (x + \epsilon |x) =
        \frac{1}{\sqrt{(2 \pi \Delta t)^n \det (K)}}
\exp \left( - \frac{1}{2
        \Delta t} (K^{- 1})_{\alpha \beta} \epsilon^{\alpha}
\epsilon^{\beta}
        \right) . \)</td>
        <td align="right">(18)</td>
      </tr>
    </table>
    <p>
      The phenomenon that this transition density describes is called
      <strong>Brownian motion</strong>. Even though the techniques used for
      deriving this transition density had been mature when Brown first
      observed this phenomenon, but almost one hundred years after Brown's
      discover, in 1918, Norbert Wiener first constructed a complete
      mathematical theory for this stochastic process. So, it is also called
      <strong>Wiener process</strong>.
    </p>
    <p>
      The transition rate \(q_{\Delta t} (x + \epsilon |x)\) can be seen as an
      accumulation of a series tiny transitions, each is caused by one strike
      from a water molecule. The strike obeys a distribution which is
      identical (each water molecule behaves in the same way, as a result of
      homogeneity) and independent (since each strike is individual) with zero
      mean (as a result of isotropy). This distribution, however, is unknown.
      Although, we find that the accumulative effect always obeys a normal
      distribution. We can abstract this and conclude a corollary as follow.
    </p>
    <p style="margin-top: 1em; margin-bottom: 1em">
      <strong>Corollary <class style="font-style: normal">2</class>. </strong><i>For any
      independently identically distributed \(n\)-dimensional random variables
      \((X_1, \ldots, X_N)\) with zero mean (thus each \(X_i\) is one strike),
      the accumulation \(Y := X_1 + \cdots + X_N\) tends to obey a normal
      distribution as \(N\) is large enough.</i>
    </p>
    <p>
      Each \(X_i\) can be seen as a strike by water molecule. Further, the
      mean of \(Y\) can be calculated by the linearity of expectation, as
      \(\mathbb{E} [Y] =\mathbb{E} [X_1] + \cdots +\mathbb{E} [X_N] = 0\). And
      because of independency, we have \(\mathbb{E} [Y^{\alpha} Y^{\beta}]
      =\mathbb{E} [X_1^{\alpha} X_1^{\beta}] +
\cdots +\mathbb{E}
      [X_N^{\alpha} X_N^{\beta}]\). Let \(\Sigma^{\alpha \beta} := \mathbb{E}
      [X_i^{\alpha} X^{\beta}_i]\), which is the same for all \(i\) because
      \(X_i\)s are identical, we find \(\mathbb{E} [Y^{\alpha} Y^{\beta}] = N
      \Sigma^{\alpha \beta}\). This is the <strong>central limit
      theorem</strong>, the most famous theorem in probability theory. Now, we
      have found for central limit theorem a physical description, the
      Brownian motion, and found it as a corollary of Kramers&ndash;Moyal
      expansion.
    </p>
    <h3 id="auto-19"><a id="section: Langevin Process Arises in the Difference of Scales"></a>3.4<span style="margin-left: 1em"></span>Langevin Process Arises in the
    Difference of Scales<span style="margin-left: 1em"></span></h3>
    <p>
      There are many levels of scale in Nature. From the lifetime of universe
      to the lifetime of human. From the movement of a bird to the movement of
      molecule. We are to formulate the general mathematical description for
      the system in which multiple scales are involved.
    </p>
    <p>
      A typical example is the Brownian motion described in section <a href="#section: From Brownian Motion to Central Limit Theorem">3.3</a>.
      Of course, each water molecule moves the pollen particle in such a tiny
      distance that cannot be observed by a microscope made in the 19th
      century. What Brown noticed was not a pollen particle shaken by a single
      water molecule, but an accumulation of strikes by a large group of water
      molecules. So, this phenomenon involves two different scales: the scale
      of pollen particles, and the scale of movement of water molecules, which
      is much smaller than the frontier.
    </p>
    <p>
      If we replace the pollen particles by paramecia, then the scales remain.
      In the perspective of water molecule, homogeneity and isotropy still
      hold. So, the contribution from the constant striking of water molecules
      obeys the transition density of Wiener process <a href="#equation:wiener process">18</a>. But in
      the perspective of paramecium, both homogeneity and isotropy break.
      Unlike pollen particle, a paramecium can swim along a direction (maybe,
      there is food on this direction), thus isotropy breaks. In the
      perspective of the paramecium, which is much larger than a water
      molecule, the pool is not like an ocean anymore, but a pond. So, after
      arriving at another place in the pool, it can feel the change of
      environment (such as the temperature of water), thus homogeneity breaks.
    </p>
    <p>
      This pattern arises in many areas of Nature in which two scales coexist
      simultaneously: one scale is smaller, being homogeneous and isotropic,
      while the other is greater, breaking homogeneity and isotropy. The
      greater scale obeys a deterministic behavior, characterized by a
      dynamical system \(\mathrm{d} x^{\alpha} / \mathrm{d} t = f^{\alpha}
      (x)\), or difference equation \(x^{\alpha}_{i + 1} = x^{\alpha}_i +
      f^{\alpha} (x_i) \Delta t\) for some small but still finite time
      interval \(\Delta t\) (the subscripts denote the iterative steps). While
      the smaller scale contributes to the movement of the greater one by the
      accumulative random effect \(\Delta W_i^{\alpha}\), which is proven to
      obey a normal distribution with zero mean and covariance \(K^{\alpha
      \beta} (x_i) \Delta t\) (proved in section <a href="#section: From Brownian Motion to Central Limit Theorem">3.3</a>). Notice
      that, since the homogeneity has broken at the greater scale, \(K^{\alpha
      \beta}\) will explicitly depends on position \(x\). So, the total effect
      is
    </p>
    <table width="100%">
      <tr>
        <td width="100%" align="center">\(\displaystyle x^{\alpha}_{i + 1} = x^{\alpha}_i +
        f^{\alpha} (x_i) \Delta t + \Delta
w_i^{\alpha}, \)</td>
        <td align="right">(19)</td>
      </tr>
    </table>
    <p>
      where \(\Delta w_i\) is sampled from the distribution of \(\Delta W_i\).
    </p>
    <p>
      We are to determine the conditional probability of \(x_{i + 1}\) given
      \(x_i\), where the randomness of \(x_{i + 1}\) comes from that of
      \(\Delta W_i\). We know that a linear combination of random variables
      that obey normal distribution also obeys a normal distribution. Then,
      since \(x_{i + 1}\) is linear with \(\Delta w_i\), we have \(X_{i + 1}\)
      (the random version of \(x_{i + 1}\)) will also obey a normal
      distribution when \(x_i\) is fixed, with the conditional density
      function on \(\mathbb{R}^n\)
    </p>
    <font style="font-size: 84.1%"><table width="100%">
      <tr>
        <td width="100%" align="center">\(\displaystyle q_{\Delta t} (x_{i + 1} |x_i) :=
        \frac{1}{\sqrt{(2 \pi \Delta t)^n \det K
(x_i)}} \exp \left( -
        \frac{1}{2 \Delta t}  [K^{- 1} (x_i)]_{\alpha \beta} 
[x^{\alpha}_{i +
        1} - x^{\alpha}_i - f^{\alpha} (x_i) \Delta t]  [x^{\beta}_{i
+ 1} -
        x^{\beta}_i - f^{\beta} (x_i) \Delta t] \right) . \)</td>
        <td align="right">(20)</td>
      </tr>
    </table></font>
    <p>
      When \(\Delta t\) is sufficiently small, \(q_{\Delta t}\) can be
      approximately regarded as a transition density (the essential and
      sufficient condition for \(q_{\Delta t}\) to be a transition density was
      discussed in section
      <a href="#section: Transition Rate Determines Transition Density">2.3</a>
      ).
      <div class="footnote">
        <font style="font-size: 77.1%"><div align="justify">
          <div style="margin-left: 0px">
            <div style="margin-right: 0px">
              <class style="font-style: normal"><p>
                10. Is \(q_{\Delta t}\) a transition density? In section <a
                href="#Transition Rate Determines Transition Density">?</a>, we have shown that \(q_{\Delta t}\) is a
                transition density if and only if \(q_{\Delta t + \Delta t'}
                (x|z) = \int_{\mathbb{R}^n} \mathrm{d} y q_{\Delta
t'} (x|y)
                q_{\Delta t} (y|z)\). By inserting the \(q_{\Delta t}\) of
                Langevin process, we find the integrand in the right hand side
                proportional to
              </p><center>
                \(\displaystyle q_{\Delta t'} (x|y) = \frac{1}{\sqrt{(2 \pi
                \Delta t')^n \det K (y)}} \exp
\left( - \frac{1}{2 \Delta t'}
                K^{- 1} (y)  (x - y - f (y) \Delta t')  (x - y
- f (y) \Delta
                t') \right),\)
              </center><p>
                in which \(y\) appears in many places, including \(\det K
                (y)\), \(K^{- 1} (y)\), and \(f (y)\). Thus, that in the
                exponential is not quadratic on \(y\). It is hard to expect
                that integrating over \(y\) will give a result that is
                proportional to
              </p><center>
                \(\displaystyle \exp \left( - \frac{1}{2 (\Delta t + \Delta
                t')} K^{- 1} (z)  [x - z - f (z) 
(\Delta t + \Delta t')]  [x
                - z - f (z)  (\Delta t + \Delta t')] \right) .\)
              </center><p>
                So, an educated guess is that \(q_{\Delta t}\) is not a
                transition density, but just an approximation of some
                transition density when \(\Delta t\) is sufficiently small.
                Remark that, when \(f = 0\) and \(K\) is constant, it is
                straight-forward to show that \(q_{\Delta t}\) is indeed a
                transition density.
              </p></class>
            </div>
          </div>
        </div></font>
      </div>
      <span style="margin-left: 0em"></span>
      <a id="footnr-10"></a>
      <sup><class style="font-style: normal"><a href="#footnote-10">10</a></class></sup>
      The corresponding Markov process is called
      <strong>Langevin dynamics</strong>
      or
      <b>Langevin process</b>
      . In many textures, it is written in
    </p>
    <center>
      \(\displaystyle \mathrm{d} X^{\alpha} = f^{\alpha} (X) \mathrm{d} t +
      \mathrm{d} W^{\alpha},\)
    </center>
    <p>
      which is a formal re-formulation of equation <a href="#equation:langevin process v0">19</a>.
    </p>
    <h3 id="auto-20"><a id="section: Transition Rate of Langevin Process Is a Generalized Function"></a>3.5<span style="margin-left: 1em"></span>Transition Rate of Langevin
    Process Is a Generalized Function<span style="margin-left: 1em"></span></h3>
    <p>
      In this section, we calculate the the transition rate of Langevin
      process from transition density. The \(\Delta t\) appears in many places
      in transition density, and directly Taylor expanding \(q_{\Delta t}\) by
      \(\Delta t\) is very hard. Instead, we employ an arbitrary test function
      \(\varphi : \mathbb{R}^n \rightarrow \mathbb{R}\) in <strong>Schwarts
      space</strong>, which is a functional space in which function is smooth
      and rapidly falls to zero in the region far from origin. For example,
      Gaussian function (the density function of normal distribution) is in
      Schwarts space \(S (\mathbb{R}, \mathbb{R})\) (the first \(\mathbb{R}\)
      represents for domain and the second for codomain). Then, we Taylor
      expand \(f\) by its variable
    </p>
    <center>
      \(\displaystyle \int_{\mathbb{R}^n} \mathrm{d} \epsilon q_{\Delta t} (x
      + \epsilon |x) \varphi
(\epsilon) = \int_{\mathbb{R}^n} \mathrm{d}
      \epsilon q_{\Delta t} (x +
\epsilon |x) \left[ \varphi (0) +
      \epsilon^{\alpha} \partial_{\alpha} \varphi
(0) + \frac{1}{2}
      \epsilon^{\alpha} \epsilon^{\beta} \partial_{\alpha}
\partial_{\beta}
      \varphi (0) + \cdots \right]\)
    </center>
    <p>
      These Gaussian integrals result in
    </p>
    <center>
      \(\displaystyle \int_{\mathbb{R}^n} \mathrm{d} \epsilon q_{\Delta t} (x
      + \epsilon |x)
\epsilon^{\alpha} = f^{\alpha} (x) \Delta t\)
    </center>
    <p>
      and (recall the relation between covariance and mean,
      \(\operatorname{Cov} (X, Y) =\mathbb{E} [X Y] -\mathbb{E} [X] \mathbb{E}
      [Y]\))
    </p>
    <center>
      \(\displaystyle \int_{\mathbb{R}^n} \mathrm{d} \epsilon q_{\Delta t} (x
      + \epsilon |x)
\epsilon^{\alpha} \epsilon^{\beta} = K^{\alpha \beta} (x)
      \Delta t +
f^{\alpha} (x) f^{\beta} (x) \Delta t^2 = K^{\alpha \beta}
      (x) \Delta t +
\omicron (\Delta t) .\)
    </center>
    <p>
      Altogether,
    </p>
    <center>
      \(\displaystyle \int_{\mathbb{R}^n} \mathrm{d} \epsilon q_{\Delta t} (x
      + \epsilon |x) \varphi
(\epsilon) = \varphi (0) + \Delta t \left[
      f^{\alpha} (x) \partial_{\alpha}
\varphi (0) + \frac{1}{2} K^{\alpha
      \beta} (x) \partial_{\alpha}
\partial_{\beta} \varphi (0) \right] +
      \omicron (\Delta t),\)
    </center>
    <p>
      as \(\Delta t \rightarrow 0\) (for example, \(\)\(\int_{\mathbb{R}^n}
      \mathrm{d} \epsilon q_{\Delta t} (x + \epsilon |x)
[\epsilon^{\alpha}
      \epsilon^{\beta} \epsilon^{\gamma} \epsilon^{\delta}
\partial_{\alpha}
      \partial_{\beta} \partial_{\gamma} \partial_{\delta} \varphi
(0)] =
      \mathcal{O} (\Delta t^2) = \omicron (\Delta t)\)). On the other hand, if
      we Taylor expand \(q_{\Delta t}\) by \(\Delta t\) as \(q_{\Delta t} (x +
      \epsilon |x) = \delta (\epsilon) + r (x + \epsilon, x)
\Delta t +
      \omicron (\Delta t)\), where \(r\) is the transition rate, then we will
      get
    </p>
    <center>
      \(\displaystyle \int_{\mathbb{R}^n} \mathrm{d} \epsilon q_{\Delta t} (x
      + \epsilon |x) \varphi
(\epsilon) = \varphi (0) + \Delta t
      \int_{\mathbb{R}^n} \mathrm{d} \epsilon r
(x + \epsilon, x) \varphi
      (\epsilon) + \omicron (\Delta t) .\)
    </center>
    <p>
      From the terms proportional to \(\Delta t\), we recognize
    </p>
    <center>
      \(\displaystyle \int_{\mathbb{R}^n} \mathrm{d} \epsilon r (x + \epsilon,
      x) \varphi (\epsilon)
= f^{\alpha} (x) \partial_{\alpha} \varphi (0) +
      \frac{1}{2} K^{\alpha \beta}
(x) \partial_{\alpha} \partial_{\beta}
      \varphi (0) .\)
    </center>
    <p>
      Noticing the integration by parts
      <div class="footnote">
        <font style="font-size: 77.1%"><div align="justify">
          <div style="margin-left: 0px">
            <div style="margin-right: 0px">
              <class style="font-style: normal"><p>
                11. High-dimensional integration by parts employs Stokes
                theorem. Consider the integral \(\int_{\mathbb{R}^n}
                \mathrm{d} x \partial_{\alpha} \varphi (x) v^{\alpha} (x)\)
                with smooth scalar function \(\varphi : \mathbb{R}^n
                \rightarrow \mathbb{R}\) and vector field \(v : \mathbb{R}^n
                \rightarrow \mathbb{R}^n\). We have identity
              </p><center>
                \(\displaystyle \int_{\mathbb{R}^n} \mathrm{d} x
                \partial_{\alpha} \varphi (x) v^{\alpha} (x)
=
                \int_{\mathbb{R}^n} \mathrm{d} x \partial_{\alpha} [\varphi
                (x) v^{\alpha}
(x)] - \int_{\mathbb{R}^n} \mathrm{d} x \varphi
                (x) \partial_{\alpha}
v^{\alpha} (x) .\)
              </center><p>
                The first integrand in the right hand side is a divergence.
                Using Stokes theorem, it becomes
              </p><center>
                \(\displaystyle \int_{\partial \mathbb{R}^n} \mathrm{d}
                S_{\alpha}  [\varphi (x) v^{\alpha}
(x)],\)
              </center><p>
                where \(\partial \mathbb{R}^n\) is the &ldquo;boundary&rdquo;
                of \(\mathbb{R}^n\). If \(\varphi\) or \(v\) is in Schwarts
                space, then this term vanishes, and the integral results in
              </p><center>
                \(\displaystyle \int_{\mathbb{R}^n} \mathrm{d} x
                \partial_{\alpha} \varphi (x) v^{\alpha} (x)
= -
                \int_{\mathbb{R}^n} \mathrm{d} x \varphi (x) \partial_{\alpha}
                v^{\alpha}
(x) .\)
              </center></class>
            </div>
          </div>
        </div></font>
      </div>
      <span style="margin-left: 0em"></span>
      <a id="footnr-11"></a>
      <sup><class style="font-style: normal"><a href="#footnote-11">11</a></class></sup>
    </p>
    <center>
      \(\displaystyle \int_{\mathbb{R}^n} \mathrm{d} \epsilon f^{\alpha} (x)
      \partial_{\alpha}
\delta (\epsilon) \varphi (\epsilon) = -
      \int_{\mathbb{R}^n} \mathrm{d}
\epsilon f^{\alpha} (x) \delta (\epsilon)
      \partial_{\alpha} \varphi (\epsilon)
= - f^{\alpha} (x)
      \partial_{\alpha} \varphi (0),\)
    </center>
    <p>
      and
    </p>
    <center>
      \(\displaystyle \int_{\mathbb{R}^n} \mathrm{d} \epsilon K^{\alpha \beta}
      (x) \partial_{\alpha}
\partial_{\beta} \delta (\epsilon) \varphi
      (\epsilon) = \int_{\mathbb{R}^n}
\mathrm{d} \epsilon K^{\alpha \beta}
      (x) \delta (\epsilon) \partial_{\alpha}
\partial_{\beta} \varphi
      (\epsilon) = K^{\alpha \beta} (x) \partial_{\alpha}
\partial_{\beta}
      \varphi (0),\)
    </center>
    <p>
      we get
    </p>
    <table width="100%">
      <tr>
        <td width="100%" align="center">\(\displaystyle r (x + \epsilon, x) = - f^{\alpha}
        (x) \partial_{\alpha} \delta (\epsilon) +
\frac{1}{2} K^{\alpha \beta}
        (x) \partial_{\alpha} \partial_{\beta} \delta
(\epsilon) . \)</td>
        <td align="right">(21)</td>
      </tr>
    </table>
    <p>
      Because of the Dirac's \(\delta\)-functions, this transition rate is a
      generalized function. That is, only when applied to a test function can
      they be evaluated.
    </p>
    <p>
      For example, to evaluate \(\partial_{\alpha} \delta (- x)\), we have to
      employ an arbitrary test function \(\varphi \in S (\mathbb{R}^n,
      \mathbb{R}^n)\), and calculate \(\int_{\mathbb{R}^n} \mathrm{d} x
      \partial_{\alpha} \delta (- x)
\varphi^{\alpha} (x)\). First, notice
      that \(\partial_{\alpha} \delta (- x)\) is in fact \((\partial_{\alpha}
      \delta) (- x)\) and that \((\partial \delta / \partial x^{\alpha}) (- x)
      = - (\partial / \partial
x^{\alpha}) \delta (- x)\), thus
    </p>
    <center>
      \(\displaystyle \int_{\mathbb{R}^n} \mathrm{d} x \partial_{\alpha}
      \delta (- x)
\varphi^{\alpha} (x) = \int_{\mathbb{R}^n} \mathrm{d} x
      (\partial_{\alpha}
\delta) (- x) \varphi^{\alpha} (x) = -
      \int_{\mathbb{R}^n} \mathrm{d} x
\partial_{\alpha} [\delta (- x)]
      \varphi^{\alpha} (x) .\)
    </center>
    <p>
      Then, integration by parts gives \(- \int_{\mathbb{R}^n} \mathrm{d} x
      \partial_{\alpha} [\delta (- x)]
\varphi^{\alpha} (x) =
      \int_{\mathbb{R}^n} \mathrm{d} x \delta (- x)
\partial_{\alpha}
      \varphi^{\alpha} (x)\). After inserting the relation \(\delta (x) =
      \delta (- x)\), we arrive at \(\int_{\mathbb{R}^n} \mathrm{d} x
      \partial_{\alpha} \delta (- x)
\varphi^{\alpha} (x) = \partial_{\alpha}
      \varphi^{\alpha} (0)\). On the other hand, we have, by integration by
      parts, \(- \int_{\mathbb{R}^n} \mathrm{d} x \partial_{\alpha} \delta
      (x)
\varphi^{\alpha} (x) = \int_{\mathbb{R}^n} \mathrm{d} x \delta
      (x)
\partial_{\alpha} \varphi^{\alpha} (x) = \partial_{\alpha}
      \varphi^{\alpha}
(0)\). Altogether, we find \(\int_{\mathbb{R}^n}
      \mathrm{d} x \partial_{\alpha} \delta (- x)
\varphi^{\alpha} (x) = -
      \int_{\mathbb{R}^n} \mathrm{d} x \partial_{\alpha}
\delta (x)
      \varphi^{\alpha} (x)\), for any \(\varphi \in S (\mathbb{R}^n,
      \mathbb{R}^n)\). Thus, \(\partial_{\alpha} \delta (- x)\) is evaluated
      to be \(- \partial_{\alpha} \delta (x)\). That is,
      <em>\(\partial_{\alpha} \delta\) is odd</em>
      . Following the same process, we can show that
      <em>\(\partial_{\alpha} \partial_{\beta} \delta\) is even</em>
      .
      <div class="footnote">
        <font style="font-size: 77.1%"><div align="justify">
          <div style="margin-left: 0px">
            <div style="margin-right: 0px">
              <class style="font-style: normal"><p>
                12. We are to calculate \(\int_{\mathbb{R}^n} \mathrm{d} x
                \partial_{\alpha} \partial_{\beta} \delta (-
x) f^{\alpha
                \beta} (x)\), where \(f \in S (\mathbb{R}^n, \mathbb{R}^{n
                \times n})\). Again, noticing that \((\partial_{\alpha}
                \partial_{\beta} \delta) (- x) =
                \partial_{\alpha}
\partial_{\beta} [\delta (- x)]\), we have
              </p><center>
                \(\displaystyle \int_{\mathbb{R}^n} \mathrm{d} x
                \partial_{\alpha} \partial_{\beta} \delta (-
x) f^{\alpha
                \beta} (x) = \int_{\mathbb{R}^n} \mathrm{d} x
                (\partial_{\alpha}
\partial_{\beta} \delta) (- x) f^{\alpha
                \beta} (x) = \int_{\mathbb{R}^n}
\mathrm{d} x
                \partial_{\alpha} \partial_{\beta} [\delta (- x)]
                f^{\alpha
\beta} (x) .\)
              </center><p>
                Then integration by parts gives
              </p><center>
                \(\displaystyle \int_{\mathbb{R}^n} \mathrm{d} x
                \partial_{\alpha} \partial_{\beta} [\delta (-
x)] f^{\alpha
                \beta} (x) = \int_{\mathbb{R}^n} \mathrm{d} x \delta (-
                x)
\partial_{\alpha} \partial_{\beta} f^{\alpha \beta} (x) =
                \partial_{\alpha}
\partial_{\beta} f^{\alpha \beta} (0) .\)
              </center><p>
                That is, \(\int_{\mathbb{R}^n} \mathrm{d} x \partial_{\alpha}
                \partial_{\beta} \delta (-
x) f^{\alpha \beta} (x) =
                \partial_{\alpha} \partial_{\beta} f^{\alpha \beta}
(0)\). On
                the other hand, we have
              </p><center>
                \(\displaystyle \int_{\mathbb{R}^n} \mathrm{d} x
                \partial_{\alpha} \partial_{\beta} \delta (x)
f^{\alpha \beta}
                (x) = \int_{\mathbb{R}^n} \mathrm{d} x \delta
                (x)
\partial_{\alpha} \partial_{\beta} f^{\alpha \beta} (x) =
                \partial_{\alpha}
\partial_{\beta} f^{\alpha \beta} (0) .\)
              </center><p>
                So,
              </p><center>
                \(\displaystyle \int_{\mathbb{R}^n} \mathrm{d} x
                \partial_{\alpha} \partial_{\beta} \delta (-
x) f^{\alpha
                \beta} (x) = \int_{\mathbb{R}^n} \mathrm{d} x
                \partial_{\alpha}
\partial_{\beta} \delta (x) f^{\alpha \beta}
                (x)\)
              </center><p>
                holds for any \(f \in S (\mathbb{R}^n, \mathbb{R}^{n \times
                n})\), thus \(\)\(\partial_{\alpha} \partial_{\beta} \delta (-
                x) = \partial_{\alpha}
\partial_{\beta} \delta (x)\).
              </p></class>
            </div>
          </div>
        </div></font>
      </div>
      <span style="margin-left: 0em"></span>
      <a id="footnr-12"></a>
      <sup><class style="font-style: normal"><a href="#footnote-12">12</a></class></sup>
      These conclusions are to be used in section
      <a href="#section: Detailed Balance Condition of Langevin Process Lacks Source-Free Degree of Freedom">3.8</a>
      .
    </p>
    <h3 id="auto-21">3.6<span style="margin-left: 1em"></span>Master Equation of Langevin Process Is
    Fokker-Planck Equation<span style="margin-left: 1em"></span></h3>
    <p>
      After discussing transition rate, we turn to the master equation of
      Langevin process. Since Langevin process applies to continuous random
      variable, we can use Kramers-Moyal expansion to evaluate its master
      equation. Directly, we have \(K^{\alpha} (x) = f^{\alpha} (x)\), and
      those with order (the number of superscripts) higher than \(K^{\alpha
      \beta} (x)\) are all vanishing (\(K\) is defined in section <a href="#section: Spatial Expansion of Master Equation Gives Kramers-Moyal Expansion">3.2</a>).
      For example, the integral \(\int_{\mathbb{R}^n} \mathrm{d} \epsilon
      (\epsilon^{\alpha} \epsilon^{\beta}
\epsilon^{\gamma}) q_{\Delta t} (x +
      \epsilon |x) = \mathcal{O} (\Delta t^{3 /
2})\), which can be easily
      realized by the estimation \(\epsilon = \mathcal{O} \left( \sqrt{\Delta
      t} \right)\). By relation \(\int_{\mathbb{R}^n} \mathrm{d} \epsilon
      (\epsilon^{\alpha} \epsilon^{\beta}
\epsilon^{\gamma}) q_{\Delta t} (x +
      \epsilon |x) = \Delta t K^{\alpha \beta
\gamma} (x) + \omicron (\Delta
      t)\) (derived in section <a href="#section: Spatial Expansion of Master Equation Gives Kramers-Moyal Expansion">3.2</a>), we find \(K^{\alpha \beta
      \gamma} (x) = 0\). Thus, Kramers-Moyal expansion <a href="#equation:km expansion">17</a> reads
    </p>
    <table width="100%">
      <tr>
        <td width="100%" align="center">\(\displaystyle \frac{\partial p}{\partial t} (x, t)
        = - \partial_{\alpha} (f^{\alpha} (x) p
(x, t)) + \frac{1}{2}
        \partial_{\alpha} \partial_{\beta} (K^{\alpha \beta} (x)
p (x, t)) .
        \)</td>
        <td align="right">(22)</td>
      </tr>
    </table>
    <p>
      This equation is called <b>Fokker-Planck equation</b>, found by Adriaan
      Fokker and Max Planck in 1914 and 1917 respectively, or
      <strong>Kolmogorov forward equation</strong>, independently discovered
      in 1931.
    </p>
    <h3 id="auto-22">3.7<span style="margin-left: 1em"></span>Stationary Solution of Langevin Process Has
    Source-Free Degree of Freedom<span style="margin-left: 1em"></span></h3>
    <p>
      The master equation of Langevin process (equation <a href="#equation:Fokker-Planck equation">22</a>) has
      stationary solution \(\Pi\) which satisfies (since there is only one
      variable \(x\), we use \(\partial\) instead of \(\nabla\))
    </p>
    <center>
      \(\displaystyle - \partial_{\alpha} (f^{\alpha} (x) \pi (x)) +
      \frac{1}{2} \partial_{\alpha}
\partial_{\beta} (K^{\alpha \beta} (x) \pi
      (x)) = 0,\)
    </center>
    <p>
      which means
    </p>
    <table width="100%">
      <tr>
        <td width="100%" align="center">\(\displaystyle f^{\alpha} (x) \pi (x) = \frac{1}{2}
        \partial_{\beta} (K^{\alpha \beta} (x)
\pi (x)) + \nu^{\alpha} (x),
        \)</td>
        <td align="right">(23)</td>
      </tr>
    </table>
    <p>
      where \(\nu : \mathbb{R}^n \rightarrow \mathbb{R}^n\) is an arbitrary
      vector field such that \(\partial_{\alpha} \nu^{\alpha} (x) = 0\).
    </p>
    <p>
      The vector field \(\nu\) has an intuitive explanation. Regarding \(\nu\)
      as a flux on \(\mathbb{R}^n\), we find that there is not net flux
      flowing out of anywhere in \(\mathbb{R}^n\). Otherwise, suppose there is
      \(x \in \mathbb{R}^n\) and a closed surface \(S\) around \(x\) such that
      the net flux \(\int \mathrm{d} S \cdot \nu (x)\) does not vanish. Then,
      by Stokes theorem, the surface integral \(\int \mathrm{d} S \cdot \nu
      (x) = \int \mathrm{d} x \nabla \cdot v (x) = 0\), thus conflicts. Such a
      vector field \(\nu\) is called <strong>free of source</strong> or
      <strong>source-free</strong>.
    </p>
    <h3 id="auto-23"><a id="section: Detailed Balance Condition of Langevin Process Lacks Source-Free Degree of Freedom"></a>3.8<span style="margin-left: 1em"></span>Detailed Balance of Langevin
    Process Lacks Source-Free Degree of Freedom<span style="margin-left: 1em"></span></h3>
    <p>
      After discussing stationary distribution of Fokker-Planck equation (as a
      master equation), we continue investigate when will Langevin process
      relax an initial distribution to the stationary. By theorem <a href="#theorem: relaxation">1</a>,
      this is equivalent to ask: when will the transition rate of Langevin
      process satisfy detailed balance condition? Detailed balance condition
      reads \(r (x + \epsilon, x) \pi (x) = r (x, x + \epsilon) \pi (x +
      \epsilon)\). Directly inserting equation <a href="#equation:Langevin transition rate">21</a>, we get, for
      the left hand side,
    </p>
    <center>
      \(\displaystyle r (x + \epsilon, x) \pi (x) = - f^{\alpha} (x) \pi (x)
      \partial_{\alpha}
\delta (\epsilon) + \frac{1}{2} K^{\alpha \beta} (x)
      \pi (x) \partial_{\alpha}
\partial_{\beta} \delta (\epsilon),\)
    </center>
    <p>
      and, for the right hand side,
    </p>
    <center>
      \(\displaystyle \begin{array}{rl}
  & r (x, x + \epsilon) \pi (x +
      \epsilon)\\
  = & r ((x + \epsilon) - \epsilon, x + \epsilon) \pi (x +
      \epsilon)\\
  = & - f^{\alpha} (x + \epsilon) \pi (x + \epsilon)
      \partial_{\alpha} \delta
  (- \epsilon) + \frac{1}{2} K^{\alpha \beta}
      (x + \epsilon) \pi (x +
  \epsilon) \partial_{\alpha} \partial_{\beta}
      \delta (- \epsilon)\\
  = & f^{\alpha} (x + \epsilon) \pi (x + \epsilon)
      \partial_{\alpha} \delta
  (\epsilon) + \frac{1}{2} K^{\alpha \beta} (x
      + \epsilon) \pi (x + \epsilon)
  \partial_{\alpha} \partial_{\beta}
      \delta (\epsilon),
\end{array}\)
    </center>
    <p>
      where in the last line, we have used \(\partial_{\alpha} \delta (- x) =
      - \partial_{\alpha} \delta (x)\) and \(\partial_{\alpha}
      \partial_{\beta} \delta (- x) = \partial_{\alpha}
\partial_{\beta}
      \delta (x)\) (derived in the end of section <a href="#section: Transition Rate of Langevin Process Is a Generalized Function">3.5</a>).
    </p>
    <p>
      As generalized functions, we are to examine these two expressions by
      using an arbitrary test function \(\varphi\). Thus, for the left hand
      side,
    </p>
    <center>
      \(\displaystyle \int_{\mathbb{R}^n} \mathrm{d} \epsilon r (x + \epsilon,
      x) \pi (x) \varphi
(\epsilon) = - \int_{\mathbb{R}^n} \mathrm{d}
      \epsilon f^{\alpha} (x) \pi (x)
\partial_{\alpha} \delta (\epsilon)
      \varphi (\epsilon) + \frac{1}{2}
\int_{\mathbb{R}^n} \mathrm{d} \epsilon
      K^{\alpha \beta} (x) \pi (x)
\partial_{\alpha} \partial_{\beta} \delta
      (\epsilon) \varphi (\epsilon) .\)
    </center>
    <p>
      Integration by parts gives (note that the \(\partial\) is applied on
      \(\epsilon\))
    </p>
    <center>
      \(\displaystyle \int_{\mathbb{R}^n} \mathrm{d} \epsilon r (x + \epsilon,
      x) \pi (x) \varphi
(\epsilon) = {f^{\alpha} (x) \pi (x)
      \partial_{\alpha} \varphi (0) +
\frac{1}{2} K^{\alpha \beta} (x) \pi (x)
      \partial_{\alpha} \partial_{\beta}
\varphi (0)} .\)
    </center>
    <p>
      The right hand side is a little complicated,
    </p>
    <font style="font-size: 84.1%"><center>
      \(\displaystyle \int_{\mathbb{R}^n} \mathrm{d} \epsilon r (x, x +
      \epsilon) \pi (x + \epsilon)
\varphi (\epsilon) = \int_{\mathbb{R}^n}
      \mathrm{d} \epsilon f^{\alpha} (x +
\epsilon) \pi (x + \epsilon)
      \partial_{\alpha} \delta (\epsilon) \varphi
(\epsilon) + \frac{1}{2}
      \int_{\mathbb{R}^n} \mathrm{d} \epsilon K^{\alpha
\beta} (x + \epsilon)
      \pi (x + \epsilon) \partial_{\alpha} \partial_{\beta}
\delta (\epsilon)
      \varphi (\epsilon) .\)
    </center></font>
    <p>
      Again, integration by parts results in (again, the \(\partial\) operator
      is applied on \(\epsilon\))
    </p>
    <center>
      \(\displaystyle \begin{array}{rl}
  & \int_{\mathbb{R}^n} \mathrm{d}
      \epsilon r (x, x + \epsilon) \pi (x +
  \epsilon) \varphi (\epsilon)\\
 
      = & - \int_{\mathbb{R}^n} \mathrm{d} \epsilon \delta (\epsilon)
 
      \frac{\partial}{\partial \epsilon^{\alpha}} [f^{\alpha} (x + \epsilon)
      \pi
  (x + \epsilon) \varphi (\epsilon)]\\
  + & \frac{1}{2}
      \int_{\mathbb{R}^n} \mathrm{d} \epsilon \delta (\epsilon)
 
      \frac{\partial^2}{\partial \epsilon^{\alpha} \partial \epsilon^{\beta}}

      [K^{\alpha \beta} (x + \epsilon) \pi (x + \epsilon) \varphi
      (\epsilon)]\\
  = & - \partial_{\alpha} [f^{\alpha} (x) \pi (x)] \varphi
      (0) - {f^{\alpha}
  (x) \pi (x) \partial_{\alpha} \varphi (0)}\\
  + &
      \frac{1}{2} \partial_{\alpha} \partial_{\beta} [K^{\alpha \beta} (x)
      \pi
  (x)] \varphi (0) + \partial_{\beta} [K^{\alpha \beta} (x) \pi
      (x)]
  \partial_{\alpha} \varphi (0) + {\frac{1}{2} K^{\alpha \beta} (x)
      \pi (x)
  \partial_{\alpha} \partial_{\beta} \varphi (0)}
      .
\end{array}\)
    </center>
    <p>
      By equaling \(\int_{\mathbb{R}^n} \mathrm{d} \epsilon r (x + \epsilon,
      x) \pi (x) \varphi
(\epsilon)\) and \(\int_{\mathbb{R}^n} \mathrm{d}
      \epsilon r (x, x + \epsilon) \pi (x + \epsilon)
\varphi (\epsilon)\),
      since \(\varphi\) is arbitrary, we find, for the \(\varphi (0)\) terms,
    </p>
    <center>
      \(\displaystyle - \partial_{\alpha} (f^{\alpha} (x) \pi (x)) +
      \frac{1}{2} \partial_{\alpha}
\partial_{\beta} (K^{\alpha \beta} (x) \pi
      (x)) = 0,\)
    </center>
    <p>
      and for \(\partial \varphi (0)\) terms,
    </p>
    <center>
      \(\displaystyle - f^{\alpha} (x) \pi (x) + \frac{1}{2} \partial_{\beta}
      (K^{\alpha \beta} (x)
\pi (x)) = 0.\)
    </center>
    <p>
      The \(\partial \partial \varphi (0)\) terms vanishes automatically.
      Altogether, we find the detailed balance condition for Langevin process
      to be
    </p>
    <table width="100%">
      <tr>
        <td width="100%" align="center">\(\displaystyle f^{\alpha} (x) \pi (x) = \frac{1}{2}
        \partial_{\beta} (K^{\alpha \beta} (x)
\pi (x)) . \)</td>
        <td align="right">(24)</td>
      </tr>
    </table>
    <p>
      Comparing with the stationary solution of Langevin process (equation <a
      href="#equation:stationary Fokker-Planck equation">23</a>), the source-free vector field \(\nu\) is absent here.
      Recall in section <a href="#section: Detailed Balance Provides Stationary Distribution">2.4</a> where detailed balance condition was
      first encountered, we said that detailed balance condition is stronger
      than just being stationary. Now, in Langevin process, this becomes
      concrete: <em>detailed balance condition is stronger than stationary
      condition in the sense that it lacks the source-free degree of freedom
      that appears in the stationary condition</em>. The lost degree of
      freedom is the cost of ensuring that any initial distribution will
      finally relax to the stationary.
    </p>
    <h2 id="auto-24">4<span style="margin-left: 1em"></span>Least-Action Principle<span style="margin-left: 1em"></span></h2>
    <h3 id="auto-25">4.1<span style="margin-left: 1em"></span>Conventions in This Section<span style="margin-left: 1em"></span></h3>
    <p>
      Follow the conventions in section <a href="#section: Kramers-Moyal Expansion and Langevin Process">3</a>. In addition, we use
      \(P (\theta)\) for a parameterized distribution, where \(\theta\) is the
      collection of parameters. Its density function is \(p (x, \theta)\),
      where random variable \(X\) takes the value \(x\).
    </p>
    <h3 id="auto-26"><a id="section: A Brief Review of Least-Action Principle in Classical Mechanics"></a>4.2<span style="margin-left: 1em"></span>A Brief Review of Least-Action
    Principle in Classical Mechanics<span style="margin-left: 1em"></span></h3>
    <p>
      In physics, least-action principle gives the dynamics of the state of an
      evolutionary system, determining how it evolves with time. The state of
      an evolutionary system is called a <strong>configuration</strong>. As
      the state changes with time, the evolution of configuration can be seen
      as a path in a space, like a contrail in the sky, indicating the
      movement of an airplane. This space is called <strong>configuration
      space</strong>, which is generally Euclidean, \(\mathbb{R}^n\) for some
      \(n\). A <strong>path</strong> is a function with single parameter \(x :
      [t_i, t_f] \rightarrow \mathbb{R}^n\), where \(t_i\) and \(t_f\) denote
      the initial and final time respectively. Without losing generality, we
      standardize the time interval from \([t_i, t_f]\) to \([0, 1]\). To
      introduce the least-action principle, consider the collection of paths
      with fixed boundaries, that is, \(\mathcal{P} (x_0, x_1) := \{ x : [0,
      1] \rightarrow \mathbb{R}^n |x (0) = x_0,
x (1) = x_1 \}\) given the
      boundaries \((x_0, x_1)\). An <strong>action</strong> is a scalar
      functional of path with fixed boundaries, thus an action \(S (\cdot
      |x_0, x_1) : \mathcal{P} (x_0, x_1) \rightarrow \mathbb{R}\), where we
      use a vertical line to separate variables and those that are given as
      constants (the boundaries \((x_0, x_1)\)), which should not be confused
      with the vertical line in conditional probability, like \(p (x|y)\). For
      example, the configuration space of an (one-dimensional) harmonic
      oscillator is \(\mathbb{R}\), and the evolution is characterized by a
      path \(x : [0, 1] \rightarrow \mathbb{R}\). The action of harmonic
      oscillator is given by the functional
    </p>
    <table width="100%">
      <tr>
        <td width="100%" align="center">\(\displaystyle S_{\operatorname{HO}} (x|x_0, x_1) =
        \frac{1}{2} \int_0^1 \mathrm{d} t
[\dot{x}^2 (t) - \omega^2 x^2 (t)],
        \)</td>
        <td align="right">(25)</td>
      </tr>
    </table>
    <p>
      where \(\dot{x} := \mathrm{d} x / \mathrm{d} t\), \(\omega \in
      \mathbb{R}\), and \(x (0) = x_0\), \(x (1) = x_1\).
    </p>
    <p>
      Roughly, least-action principle states that, in the real world, the
      paths with the fixed boundaries are those that minimize the action. To
      quantitatively declare the least-action principle, we have to describe
      the minimum of an action mathematically. Recall that a local minimum, or
      generally an extremum, \(x_{\star}\) of a function \(f\) is
      characterized by \((\partial f / \partial x^{\alpha}) (x_{\star}) = 0\)
      for each component \(\alpha\). How can we generalize this from function
      to functional (action is a functional)? The trick is discretizing the
      time. Precisely, we uniformly separate the time interval \([0, 1]\) into
      \(T\) fragments. Thus, the path \(x\) is discretized as a vector \((x
      (0), x (1 / T), \ldots, x ((T - 1) / T), x (1))\), each component is an
      endpoint of a fragment. Since the boundaries are fixed in least-action
      principle, \(x (0)\) and \(x (1)\) are constant rather than variables.
      Hence, the true degree of freedom is \((x (1 / T), \ldots, x ((T - 1) /
      T))\). <strong>Least-action principle in classical mechanics</strong>
      then states that, given the (discretized) action \(S\) and the
      boundaries \((x_0, x_1)\), there is at most one path \(x_{\star} \in
      \mathcal{P} (x_0, x_1)\) such that
    </p>
    <table width="100%">
      <tr>
        <td width="100%" align="center">\(\displaystyle \frac{\partial S}{\partial x (i /
        T)} (x_{\star} |x_0, x_1) = 0, \)</td>
        <td align="right">(26)</td>
      </tr>
    </table>
    <p>
      for each \(i = 1, \ldots, T - 1\) and any \(T > 1\), and that
      \(x_{\star}\) is the path in real world.
    </p>
    <p>
      Take harmonic oscillator as example. To discretize its action (equation
      <a href="#equation:harmonic oscillator action">25</a>), we replace the integral \(\int_0^1 \mathrm{d} t\) by
      mean \((1 / T)  \sum_{i = 0}^T\) and \(x (t)\) by \(x (i / T)\). Thus
      the second term becomes \((\omega^2 / 2 T)  \sum_{i = 0}^T x^2 (i /
      T)\). For the first term, the derivative \(\dot{x} (t)\) is replaced by
      its difference \(T [x ((i + 1) / T) - x (i / T)]\), hence the summation
      shall terminated at \(T - 1\) instead of \(T\). Altogether, the action
      <a href="#equation:harmonic oscillator action">25</a> is discretized as
    </p>
    <center>
      \(\displaystyle S_{\operatorname{HO}} (x|x_0, x_1) = \frac{T}{2} \sum_{i
      = 0}^{T - 1} [x ((i +
1) / T) - x (i / T)]^2 - \frac{\omega^2}{2 T}
      \sum_{i = 0}^T x^2 (i / T),\)
    </center>
    <p>
      Given \(i\), \(x (i / T)\) appears in two terms in
      \(S_{\operatorname{HO}}\), the \(i\) and \(i + 1\) terms in the
      summation. They have derivatives \(T [- x ((i + 1) / T) + x (i / T)] -
      (\omega^2 / T) x (i / T)\) and \(T [x (i / T) - x ((i - 1) / T)]\)
      respectively. So, we find
    </p>
    <center>
      \(\displaystyle T \frac{\partial S_{\operatorname{HO}}}{\partial x (i /
      T)} (x_{\star} |x_0,
x_1) = T^2  [x_{\star} ((i + 1) / T) - 2 x_{\star}
      (i / T) + x_{\star} ((i -
1) / T)] + \omega^2 x_{\star} (i / T),\)
    </center>
    <p>
      for \(i = 1, \ldots, T - 1\). The right hand side is the discretized
      \(\ddot{x}_{\star} (t) + \omega^2 x_{\star} (t)\), for \(t \in (0, 1)\)
      (notice we have excluded the \(t = 0, 1\), corresponding to \(i = 0, T\)
      respectively). So, least-action principle, \(\partial
      S_{\operatorname{HO}} / \partial x (i / T) (x_{\star} |x_0, x_1) = 0\),
      implies the correct dynamics of harmonic oscillator in textbooks, which
      is \(\ddot{x}_{\star} (t) + \omega^2 x_{\star} (t) = 0\).
      <div class="footnote">
        <font style="font-size: 77.1%"><div align="justify">
          <div style="margin-left: 0px">
            <div style="margin-right: 0px">
              <class style="font-style: normal"><p>
                13. The dynamics with fixed boundaries is called
                <strong>boundary value problem</strong>. But in physics, the
                dynamics we obtained from the least-action principle is
                applied to <strong>initial value problem</strong>, where the
                initial &ldquo;phase&rdquo; (for physical system, it involves
                initial position and velocity), instead of boundaries, is
                fixed. This mysterious application leads to some interesting
                results. For an \(m\)th-order dynamics (for example, harmonic
                oscillator is a second order dynamics since it involves at
                most the second derivative of path), an initial value problem
                has \((T + 1 - m)\) variables (there are \(T + 1\) endpoints
                on the path), since the \(m\) degree of freedom has been
                assigned to the initial values. On the other hand, the
                boundary value problem has \((T + 1 - 2)\) degree of freedom,
                since there are always two boundaries (\(t = 0\) and \(t =
                1\)). So, for the success of this mysterious application, we
                must have \(m = 2\). That is, the initial value problem has to
                be second order.
              </p></class>
            </div>
          </div>
        </div></font>
      </div>
      <span style="margin-left: 0em"></span>
      <a id="footnr-13"></a>
      <sup><class style="font-style: normal"><a href="#footnote-13">13</a></class></sup>
    </p>
    <p>
      We can generalize the least-action principle to any system, evolutionary
      or not, where variables locate in a high-dimensional Euclidean space
      and, given some conditions, action is a scalar function on it. It states
      that the real world datum locates in the minimum of the action.
      Precisely, given the conditioned action \(S\) (we may hide the condition
      \(y\) into \(S\) instead of explicitly writing it out), there is a at
      most one \(x_{\star}\) such that
    </p>
    <table width="100%">
      <tr>
        <td width="100%" align="center">\(\displaystyle \frac{\partial S}{\partial
        x^{\alpha}} (x_{\star}) = 0, \)</td>
        <td align="right">(27)</td>
      </tr>
    </table>
    <p>
      and that \(x_{\star}\) is the real world datum.
    </p>
    <p>
      There are, however, redundant degrees of freedom in action \(S\). We may
      construct multiple actions all satisfying equation <a href="#equation:least-action principle v1">27</a>.
      Knowing the extremum of a function cannot imply the shape of the
      function. The action has much more degrees of freedom than that is
      needed for revealing the real world datum in classical mechanics. But
      combined with uncertainty, as we will see in section <a href="#section: Least-Action Principle of Distribution Has No Redundancy">4.3</a>,
      action is completely determined by the real world distribution (the
      correspondence of real world datum), with nothing redundant.
    </p>
    <h3 id="auto-27"><a id="section: Least-Action Principle of Distribution Has No Redundancy"></a>4.3<span style="margin-left: 1em"></span>Least-Action Principle of
    Distribution Has No Redundancy<span style="margin-left: 1em"></span></h3>
    <p>
      Dynamics in classical mechanics are always deterministic. That is, once
      the initial conditions (for initial value problem) or the boundaries
      (for boundary value problem) are fixed, then the path is fully
      determined, in which randomness is forbidden. There are, however, many
      phenomena in nature that have <em>intrinsic</em> randomness. For
      example, Langevin process \(\mathrm{d} X = \mu (x) \mathrm{d} t +
      \mathrm{d} W\), which was originally used to describe molecular
      movement, has a stochastic term \(\mathrm{d} W\) obeying a normal
      distribution with variance proportional to \(\mathrm{d} t\). The
      dynamics of starling flocks also has intrinsic randomness, which is the
      &ldquo;free will&rdquo; of each bird, so is ant colony, human society,
      and any interactive system in which each element has some level of
      intrinsic uncertainty. For these cases, the real world datum is not
      simply a path, but a distribution of path. Precisely, we use a
      distribution \(Q\) to describe real world phenomenon that has intrinsic
      randomness.
    </p>
    <p>
      For any density function \(q (x)\) and any \(\beta > 0\), we can always
      define
    </p>
    <table width="100%">
      <tr>
        <td width="100%" align="center">\(\displaystyle S (x) := - (1 / \beta) \ln q (x)
        +\operatorname{const}, \)</td>
        <td align="right">(28)</td>
      </tr>
    </table>
    <p>
      up to an arbitrary constant. Thus, \(q (x) = \exp (- \beta S (x)) / Z\)
      where \(Z := \int_{\mathcal{X}} \mathrm{d} x \exp (- \beta S (x))\).
      This \(S\) has some properties that can be analog to the action in
      classical mechanics. First, if \(\mathcal{X}=\mathbb{R}^n\), then we
      find, by plugging in the definition of \(S\),
    </p>
    <center>
      \(\displaystyle \int_{\mathbb{R}^n} \mathrm{d} x q (x)  \frac{\partial
      S}{\partial x^{\alpha}}
(x) = - \beta^{- 1}  \int_{\mathbb{R}^n}
      \mathrm{d} x q (x) 
\frac{\partial}{\partial x^{\alpha}} \ln q (x) = -
      \beta^{- 1} 
\int_{\mathbb{R}^n} \mathrm{d} x \frac{\partial}{\partial
      x^{\alpha}} q (x) .\)
    </center>
    <p>
      The integrand of the right most expression is a divergence, so it
      results in a boundary integral. But since \(q\), as a density function,
      is normalized, the boundary integral shall vanish. So, we conclude that
    </p>
    <center>
      \(\displaystyle \mathbb{E}_Q \left[ \frac{\partial S}{\partial
      x^{\alpha}} \right] = 0.\)
    </center>
    <p>
      This is analog to equation <a href="#equation:least-action principle v1">27</a>, where the minimum
      \(x_{\star}\) is replaced by the expectation \(\mathbb{E}_Q\). Secondly,
      in the limit \(\beta \rightarrow + \infty\) while fixing \(S\), the
      distribution \(Q\) becomes so sharp that it only samples the
      \(x_{\star}\) (recall section <a href="#section: A Brief Review of Probability">1.1</a> that distribution has a
      sampler) that maximizes \(q\), thus minimizes \(S\). For these reasons,
      we illustrate the \(S\) defined by \(q\) as the action of \(Q\).
      Contrary to the action in classical mechanics, the \(S\) here is
      completely determined by the real world distribution \(Q\) (because it
      is defined by the density function \(q\)), without any redundancy. This
      is the direct implication that distribution involves more information
      than its most likely datum.
    </p>
    <h3 id="auto-28"><a id="section: Data Fitting Is Equivalent to Least-Action Principle of Distribution"></a>4.4<span style="margin-left: 1em"></span>Data Fitting Is Equivalent to
    Least-Action Principle of Distribution<span style="margin-left: 1em"></span></h3>
    <p>
      Given a collection of real world data, we are to find a distribution
      that fits the data. These data can be seen as samples from an unknown
      distribution which characterizes the real world. We are to figure out a
      method to fit the real world distribution by given some samples of it.
    </p>
    <p>
      Let \(P (\theta)\) represent a parametrized distribution with parameters
      \(\theta\). From its density function, \(p (\cdot, \theta)\), we get a
      parameterized action \(S (\cdot, \theta)\) such that
    </p>
    <table width="100%">
      <tr>
        <td width="100%" align="center">\(\displaystyle p (x, \theta) = \exp (- S (x,
        \theta)) / Z (\theta), \)</td>
        <td align="right">(29)</td>
      </tr>
    </table>
    <p>
      where \(Z (\theta) = \int_{\mathcal{X}} \mathrm{d} x \exp (- S (x,
      \theta))\) for ensuring the normalization \(\int_{\mathcal{X}}
      \mathrm{d} x p (x, \theta) = 1\). This is consistent with the action
      defined by equation <a href="#equation:action of distribution">28</a>, except that the action here is
      parameterized, and that we omit the constant \(\beta\) since it is
      irrelevant throughout this section.
    </p>
    <p>
      What we have is a collection of data, sampled from an unknown
      distribution \(Q\). And we are to adjust the parameters \(\theta\) so
      that \(P (\theta)\) approximates \(Q\). To do so, we minimize the
      relative entropy between \(Q\) and \(P (\theta)\), which is defined as
      \(H (Q, P (\theta)) := \int_{\mathcal{X}} \mathrm{d} x q (x) \ln (q (x)
      / p (x,
\theta))\). This expression is formal. Since we do not know the
      density function of \(Q\), all that we can do with \(Q\) is computing
      the expectation \(\mathbb{E}_Q [f] = (1 / | Q |) \sum_{x \in Q} f (x)\)
      for any function \(f\), where we use \(Q\) as a set of data. With this
      realization, we have, after plugging equation <a href="#equation:generic density">29</a> into \(H
      (Q, P (\theta))\),
    </p>
    <center>
      \(\displaystyle H (Q, P (\theta)) = \int_{\mathcal{X}} \mathrm{d} x q
      (x) \ln q (x) +
\int_{\mathcal{X}} \mathrm{d} x q (x) S (x, \theta) +
      \int_{\mathcal{X}}
\mathrm{d} x q (x) \ln Z (\theta) .\)
    </center>
    <p>
      By omitting the \(\theta\)-independent terms, we get the loss function
    </p>
    <center>
      \(\displaystyle L (\theta) := \int_{\mathcal{X}} \mathrm{d} x q (x) S
      (x, \theta) + \ln Z
(\theta) .\)
    </center>
    <p>
      The parameters that minimize \(L (\theta)\) also minimize \(H (Q, P
      (\theta))\), and vice versa. We can find the \(\theta_{\star} :=
      \operatorname{argmin}L\) by iteratively updating \(\theta\) along the
      direction \(- \partial L / \partial \theta\). To calculate \(- \partial
      L / \partial \theta\), we start at
    </p>
    <center>
      \(\displaystyle - \frac{\partial L}{\partial \theta^{\alpha}} (\theta) =
      - \int_{\mathcal{X}}
\mathrm{d} x q (x)  \frac{\partial S}{\partial
      \theta^{\alpha}} (x, \theta) -
\frac{1}{Z (\theta)}  \frac{\partial
      Z}{\partial \theta^{\alpha}} (\theta) .\)
    </center>
    <p>
      The first term is recognized as \(-\mathbb{E}_Q [\partial S / \partial
      \theta^{\alpha}]\). For the second term, since \(Z (\theta) =
      \int_{\mathcal{X}} \mathrm{d} x \exp (- S (x, \theta))\), we have
    </p>
    <center>
      \(\displaystyle - \frac{1}{Z (\theta)}  \frac{\partial Z}{\partial
      \theta^{\alpha}} (\theta) =
\int_{\mathcal{X}} \mathrm{d} x {\frac{\exp
      (- S (x, \theta))}{Z (\theta)}} 
\frac{\partial S}{\partial
      \theta^{\alpha}} (x, \theta) = \int_{\mathcal{X}}
\mathrm{d} x p (x,
      \theta)  \frac{\partial S}{\partial \theta^{\alpha}} (x,
\theta),\)
    </center>
    <p>
      where in the last equality, we used the definition of \(p (x, \theta)\)
      (the green factor). This final expression is just the \(\mathbb{E}_{P
      (\theta)} [\partial S / \partial \theta^{\alpha}]\). Altogether, we
      arrive at
    </p>
    <table width="100%">
      <tr>
        <td width="100%" align="center">\(\displaystyle - \frac{\partial L}{\partial
        \theta^{\alpha}} (\theta) =\mathbb{E}_{P
(\theta)} \left[
        \frac{\partial S}{\partial \theta^{\alpha}} (\cdot, \theta)
\right]
        -\mathbb{E}_Q \left[ \frac{\partial S}{\partial
        \theta^{\alpha}}
(\cdot, \theta) \right] . \)</td>
        <td align="right">(30)</td>
      </tr>
    </table>
    <p>
      At the minimum, we shall have \(\partial L / \partial \theta = 0\).
      Then, we find that \(\theta_{\star}\) obeys
    </p>
    <table width="100%">
      <tr>
        <td width="100%" align="center">\(\displaystyle \mathbb{E}_{P (\theta_{\star})}
        \left[ \frac{\partial S}{\partial
\theta^{\alpha}} (\cdot,
        \theta_{\star}) \right] =\mathbb{E}_Q \left[
\frac{\partial
        S}{\partial \theta^{\alpha}} (\cdot, \theta_{\star}) \right] . \)</td>
        <td align="right">(31)</td>
      </tr>
    </table>
    <p>
      
    </p>
    <p>
      It can be read from equation <a href="#equation:data-fitting iteration">30</a> that minimizing \(L\) is to
      increase \(S (\cdot, \theta)\) on the sampled points (the first term)
      while decrease it on data points (the second term). As figure <a href="#figure: Least-Action">1</a>
      illustrates, this way of optimization will site real world data onto
      local minima of \(S (\cdot, \theta)\), <em>in statistical sense</em>.
    </p>
    <div style="margin-top: 1em; margin-bottom: 1em">
      <table style="width: 100%">
        <tbody><tr>
          <td style="text-align: center; padding-left: 0em; padding-right: 0em"><img src="index-1.png" style="margin-left: -0.0134736842105263em; margin-bottom: 0em; margin-right: -0.0134736842105241em; margin-top: 0em; vertical-align: -14.3223684210526em; height: 28.6447368421053em"></img></td>
        </tr><tr>
          <td style="text-align: center; padding-left: 0em; padding-right: 0em; height: 0.5em"></td>
        </tr><tr>
          <td style="text-align: center; padding-left: 0em; padding-right: 0em; padding-left: 1.5em; padding-right: 1.5em"><div class="caption">
            <font style="font-size: 84.1%"><p>
              <b>Figure 1. </b><a id="auto-29"></a><a id="figure: Least-Action"></a> This figure illustrate
              how \(\min_{\theta} L (\theta)\) will site a real world datum
              onto a local minimum of \(S (\cdot, \theta)\). The green curve
              represents the current not-yet-optimized \(S (\cdot, \theta)\).
              The \(x_1\) (red point) is a real world datum while \(x_2\)
              (blue point), which is currently a local minimum of \(S (\cdot,
              \theta)\), is not. Minimizing \(L\) by tuning \(\theta\) pushes
              the \(\mathbb{E}_Q [S (\cdot, \theta)]\) down to lower value,
              corresponding to the red downward double-arrow on \(x_1\). Also,
              since \(x_2\) is a local minimum, the data points sampled from
              \(p (x, \theta) \propto \exp (- S (x, \theta))\) will accumulate
              around \(x_2\). So, minimizing \(L\) also pulls the
              \(\mathbb{E}_{P (\theta)} [S (\cdot, \theta)]\) up to greater
              value, corresponding to the blue upward double-arrow on \(x_2\).
              Altogether, it makes \(x_1\) a local minimum of \(S (\cdot,
              \theta)\), and \(S (\cdot, \theta)\) is optimized to be the
              dashed green curve.
            </p></font>
          </div></td>
        </tr></tbody>
      </table>
    </div>
    <p>
      In this way, we find an analytical distribution \(P (\theta)\) that
      approximates the empirical distribution \(Q\). The \(S (\cdot, \theta)\)
      that defines \(P (\theta)\) describes the interaction between the
      different components of an entity. This entity may be of physics, like a
      collection of particles. But it can also be words, genes, flock of
      birds, and so on.
    </p>
    <p>
      As an example, if we want to get the action that characterizes the
      stochastic dynamics of starling flocks, we take movies for many flocks.
      Each movie is a series of frames that log the positions of each bird at
      each time instant. These movies provide the real world data. The
      parameterized action \(S\) can be expressed by a neural network. Then,
      iterating by equation <a href="#equation:data-fitting iteration">30</a> until \(\| \partial L / \partial
      \theta \|\) has been small enough gives an \(S (\cdot, \theta_{\star})\)
      that mimics the stochastic dynamics of starling flocks. To compute the
      expectation \(\mathbb{E}_{P (\theta)} [\ldots]\) in equation <a href="#equation:data-fitting iteration">30</a>,
      we can employ Monte-Carlo simulation with the transition rate satisfying
      detailed balance condition with \(P (\theta)\) as the stationary
      distribution. For continuous random variables, Monte-Carlo simulation
      with Langevin dynamics (section <a href="#section: Detailed Balance Condition for Langevin Process Lacks Source-Free Degree of Freedom">?</a>) is efficient; and for
      discrete random variables, Metropolis-Hastings (section <a href="#section: Example: Metropolis-Hastings Algorithm">2.7</a>)
      is available.
    </p>
    <h3 id="auto-30"><a id="section: The Action of Langevin Process Is Gaussian"></a>4.5<span style="margin-left: 1em"></span>The Action of Langevin Process
    Is Gaussian<span style="margin-left: 1em"></span></h3>
    <p>
      We are to find the action of Langevin process. Its transition density is
      approximated by the conditional density function (we have employed
      Einstein convention for summing over \(\alpha\) and \(\beta\) indices)
    </p>
    <font style="font-size: 84.1%"><center>
      \(\displaystyle q (x_{i + 1} |x_i) := \frac{1}{\sqrt{(2 \pi \Delta t)^n
      \det K (x_i)}} \exp
\left( - \frac{1}{2 \Delta t}  [K^{- 1}
      (x_i)]_{\alpha \beta}  [x^{\alpha}_{i
+ 1} - x^{\alpha}_i - f^{\alpha}
      (x_i) \Delta t]  [x^{\beta}_{i + 1} -
x^{\beta}_i - f^{\beta} (x_i)
      \Delta t] \right),\)
    </center></font>
    <p>
      where \(f : \mathbb{R}^n \rightarrow \mathbb{R}^n\) is a smooth vector
      field and \(K : \mathbb{R}^n \rightarrow \mathbb{R}^{n \times n}\), as a
      smooth matrix-valued field, is positive definite and symmetric. The
      iterative step \(i \in \{ 0, 1, 2, \ldots \}\). And for simplicity, we
      have neglected the subscript \(\Delta t\) in \(q\), regarding it as an
      arbitrarily given parameter.
    </p>
    <p>
      To obtain the whole density function, we first notice that, since \(q
      (x_2 |x_1)\) is not explicitly dependent on \(x_0\), \(q (x_2 |x_1) = q
      (x_2 |x_0, x_1)\) holds for any \(x_0\). Then, \(q (x_2 |x_1) q (x_1
      |x_0) q (x_0) = q (x_2 |x_0, x_1) q (x_0, x_1) = q (x_0,
x_1, x_2)\).
      Dividing \(q (x_0)\) on both sides, we get \(q (x_1, x_2 |x_0) = q (x_2
      |x_1) q (x_1 |x_0)\). Repeating this step, we will find
    </p>
    <center>
      \(\displaystyle q (x_1, \ldots, x_N |x_0) = q (x_N |x_{N - 1}) \cdots q
      (x_1 |x_0) .\)
    </center>
    <p>
      Plugging in the definition of \(q (x_{i + 1} |x_i)\), we arrive at
      (after some algebraic manipulation)
    </p>
    <center>
      \(\displaystyle - \ln q (x_1, \ldots, x_N |x_0) = \frac{\Delta t}{2}
      \sum_{i = 0}^{N - 1}
[K^{- 1} (x_i)]_{\alpha \beta}  \left[
      \frac{x^{\alpha}_{i + 1} -
x^{\alpha}_i}{\Delta t} - f^{\alpha} (x_i)
      \right]  \left[ \frac{x^{\beta}_{i
+ 1} - x^{\beta}_i}{\Delta t} -
      f^{\beta} (x_i) \right] +\operatorname{const}.\)
    </center>
    <p>
      If regard \(x_0\) as the condition, then equation <a href="#equation:action of distribution">28</a>
      (setting \(\beta = 1\)) defines the action
    </p>
    <table width="100%">
      <tr>
        <td width="100%" align="center">\(\displaystyle S (x|x_0) = \frac{\Delta t}{2}
        \sum_{i = 0}^{N - 1} [K^{- 1} (x_i)]_{\alpha
\beta}  \left[
        \frac{x^{\alpha}_{i + 1} - x^{\alpha}_i}{\Delta t} - f^{\alpha}
(x_i)
        \right]  \left[ \frac{x^{\beta}_{i + 1} - x^{\beta}_i}{\Delta t}
        -
f^{\beta} (x_i) \right] . \)</td>
        <td align="right">(32)</td>
      </tr>
    </table>
    <p>
      
    </p>
    <p>
      In the rest of this section, we consider the effect of coordinate
      transformation. Consider a coordinate transformation \(x' = x' (x)\) (we
      use \(x'\) for both new coordinates and the coordinate transformation
      that produces the new coordinates). Remark that, as a density function
      on continuous alphabet, \(q (x|x_0)\) is not invariant under coordinate
      transformation, but for any scalar function \(\varphi\),
    </p>
    <center>
      \(\displaystyle \int_{\mathbb{R}^{n \times N}} \mathrm{d} x q (x|x_0)
      \varphi (x) =
\int_{\mathbb{R}^{n \times N}} \mathrm{d} x' q' (x' |x'_0)
      \varphi (x'),\)
    </center>
    <p>
      we find
    </p>
    <center>
      \(\displaystyle q' (x' |x_0') = \left| \frac{\partial x'}{\partial x}
      \right| (x) q (x|x_0),\)
    </center>
    <p>
      where \(| \partial x' / \partial x |\) represents the absolute value of
      determinant of Jacobian \(\partial x' / \partial x\).
    </p>
    <h3 id="auto-31">4.6<span style="margin-left: 1em"></span>* The Action of Langevin Process: Another
    Derivation<span style="margin-left: 1em"></span></h3>
    <p>
      Another derivation comes from physicists Parisi and Sourlas.
      <div class="footnote">
        <font style="font-size: 77.1%"><div align="justify">
          <div style="margin-left: 0px">
            <div style="margin-right: 0px">
              <class style="font-style: normal"><p>
                14. <i>Random Magnetic Fields, Supersymmetry, and Negative
                Dimensions</i> by Parisi and Sourlas, 1979. And
                <i>Supersymmetric Field Theories and Stochastic Differential
                Equations</i>, also by Parisi and Sourlas, 1982.
              </p></class>
            </div>
          </div>
        </div></font>
      </div>
      <span style="margin-left: 0em"></span>
      <a id="footnr-14"></a>
      <sup><class style="font-style: normal"><a href="#footnote-14">14</a></class></sup>
      They cleverly introduced a test function \(\varphi : \mathbb{R}^{N
      \times n} \rightarrow \mathbb{R}\) and examine the expectation on it.
      Explicitly, given \(x_0\), they consider the random variables \(X :=
      (X_1, \ldots, X_N)\) as a whole. The randomness comes from the sequence
      of Wiener process \(\Delta W := (\Delta W_0, \ldots, \Delta W_{N -
      1})\), with \(\mathbb{E}_{\Delta W} [\Delta W_i^{\alpha}] = 0\) and
      \(\mathbb{E}_{\Delta W} [\Delta W_i^{\alpha} \Delta W_j^{\beta}] =
      \delta_{i j}
\delta^{\alpha \beta} \Delta t\) (they assume \(K (x)\) to
      be identity matrix for any \(x\)). Thus, to compute the expectation on
      \(X\), we first sample lots of \(\Delta w\) values from Wiener process,
      and for each \(\Delta w\) value, we compute the \(x\) value via the
      iteration with \(x_0\) fixed
    </p>
    <center>
      \(\displaystyle x_{i + 1}^{\alpha} = x^{\alpha}_i + f^{\alpha} (x_i)
      \Delta t + \Delta
w_i^{\alpha} .\)
    </center>
    <p>
      The expectation then becomes the mean value of \(\varphi\) on these
      \(x\) values. Namely,
    </p>
    <center>
      \(\displaystyle \mathbb{E}_{x \sim X} [\varphi (x)] =\mathbb{E}_{\Delta
      w \sim \Delta W}
[\varphi (x (\Delta w))],\)
    </center>
    <p>
      where the function \(x (\Delta w)\) denotes the previous iteration.
    </p>
    <p>
      This equality can be explicitly written as (seen as a definition of \(q
      (x|x_0)\)?)
    </p>
    <center>
      \(\displaystyle \int D [x] q (x|x_0) \varphi (x) = \int D [\Delta w]
      \exp \left( -
\frac{\Delta w^2}{2 \Delta t} \right) \varphi (x (\Delta
      w)),\)
    </center>
    <p>
      where we have simplified the notations by denoting \(\int D [x] :=
      \prod_{i = 1}^N \int_{\mathbb{R}^n} \mathrm{d} x_i\), \(\int D [\Delta
      w] := \prod_{i = 0}^{N - 1} \int_{\mathbb{R}^n} \mathrm{d}
(\Delta w_i) 
      [(2 \pi \Delta t)^n]^{- 1 / 2}\), and \(\Delta w^2 := \sum_{i = 0}^{N -
      1} \sum_{\alpha = 1}^n (\Delta w^{\alpha}_i)^2\). Now, we calculate the
      \(q (x|x_0)\). The right hand side can be re-written as
    </p>
    <center>
      \(\displaystyle \int D [\Delta w] \left[ \int D [y] \delta (y - \Delta
      w) \exp \left( -
\frac{y^2}{2 \Delta t} \right) \varphi (x (y))
      \right],\)
    </center>
    <p>
      where \(\int D [y] := \prod_{i = 0}^{N - 1} \int_{\mathbb{R}^n}
      \mathrm{d} y_i\). Now, recall the property of Dirac's delta function on
      \(\mathbb{R}^m\), for any function \(g : \mathbb{R}^m \rightarrow
      \mathbb{R}^m\) and test function \(\psi : \mathbb{R}^m \rightarrow
      \mathbb{R}\),
    </p>
    <center>
      \(\displaystyle \int_{\mathbb{R}^m} \mathrm{d} x \delta (g (x) - z) 
      \left| \frac{\partial
g}{\partial x} \right| (x) \psi (g (x)) = \int_{g
      (\mathbb{R}^m)} \mathrm{d} y
\delta (y - z) \psi (y) .\)
    </center>
    <p>
      If we replace \(g (x)\) by \(\Delta w (x)\), \(z\) by \(\Delta w\), and
      \(\psi (y)\) by \(\exp (- y^2 / (2 \Delta t)) \varphi (x (y))\), and
      notice that \(x_{i + 1} \in \mathbb{R}^n\) makes \(\Delta w_i \in
      \mathbb{R}^n\) (which corresponds to the \(g (\mathbb{R}^m)\)), then the
      property reduces to
    </p>
    <center>
      \(\displaystyle \int D [x] \delta (\Delta w (x) - \Delta w)  \left|
      \frac{\partial \Delta
w}{\partial x} \right| (x) \exp \left( -
      \frac{\Delta w (x)^2}{2 \Delta t}
\right) \varphi (x) = \int D [y]
      \delta (y - \Delta w) \exp \left( -
\frac{y^2}{2 \Delta t} \right)
      \varphi (x (y)) .\)
    </center>
    <p>
      The right hand side is the integrand in the expectation to be
      calculated. So, the expectation becomes
    </p>
    <center>
      \(\displaystyle \mathbb{E}_{\Delta W} [\varphi \circ x] = \int D [\Delta
      w] \int D [x] \delta
(\Delta w (x) - \Delta w)  \left| \frac{\partial
      \Delta w}{\partial x} \right|
(x) \exp \left( - \frac{\Delta w (x)^2}{2
      \Delta t} \right) \varphi (x),\)
    </center>
    <p>
      where we used the relation \(\varphi (x (\Delta w (x))) = \varphi (x)\).
      Integrating over \(\Delta w\) gives
    </p>
    <center>
      \(\displaystyle \mathbb{E}_{\Delta W} [\varphi \circ x] = \int D [x] 
      \left| \frac{\partial
\Delta w}{\partial x} \right| (x) \exp \left( -
      \frac{\Delta w (x)^2}{2 \Delta
t} \right) \varphi (x) .\)
    </center>
    <p>
      From the equality of expectations, \(q (x|x_0)\) can be read out as
    </p>
    <center>
      \(\displaystyle q (x|x_0) = \left| \frac{\partial \Delta w}{\partial x}
      \right| (x) \exp
\left( - \frac{\Delta w (x)^2}{2 \Delta t} \right) .\)
    </center>
    <p>
      Plugging in the definition of \(\Delta w (x)\), we finally arrive at
    </p>
    <center>
      \(\displaystyle q (x|x_0) = \left| \frac{\partial \Delta w}{\partial x}
      \right| (x) \times
\exp \left( - \sum_{i = 0}^{N - 1} \sum_{\alpha =
      1}^n \frac{\Delta t}{2}
\left[ \frac{x^{\alpha}_{i + 1} -
      x^{\alpha}_i}{\Delta t} - f^{\alpha} (x_i)
\right]^2 \right) .\)
    </center>
    <p>
      We get an extra factor \(| \partial \Delta w / \partial x |\). Since
      \(\Delta w_i^{\alpha} = x_{i + 1}^{\alpha} - x^{\alpha}_i - f^{\alpha}
      (x_i)
\Delta t\), we have (recall that \(i \in \{ 1, \ldots, N \}\), \(j
      \in \{ 0, \ldots, N - 1 \}\), and \(\alpha, \beta \in \{ 1, \ldots, n
      \}\), thus the Jacobian \(\partial \Delta W / \partial x\) is an \(N n
      \times N n\)-matrix)
    </p>
    <center>
      \(\displaystyle \frac{\partial \Delta w^{\alpha}_i}{\partial
      x^{\beta}_j} =
\delta^{\alpha}_{\beta} \delta_{i + 1}^j -
      \delta^{\alpha}_{\beta} \delta^j_i
- \delta^j_i \partial_{\beta}
      f^{\alpha} (x_i) \Delta t.\)
    </center>
    <p>
      Thus, using the identity \(\det A = \exp (\operatorname{tr} \ln (A))\)
      for any matrix \(A\), we get an extra term in \(S (x|x_0)\) as TODO.
      What is the problem??
    </p>
    <h3 id="auto-32"><a id="section: Langevin Process Has Dissipation"></a>4.7<span style="margin-left: 1em"></span>* Langevin Process Has
    Dissipation<span style="margin-left: 1em"></span></h3>
    <p>
      We are to compare action <a href="#equation:action of langevin process">32</a> with that appearing in
      classical mechanics. To make the compute simple, we directly employ
      Euler-Lagrange equation. Readers who are not familiar with it may skip
      this section.
    </p>
    <p>
      For simplicity, we suppose \(K (x)\) to be identity matrix for any
      \(x\). In this situation, the action <a href="#equation:action of langevin process">32</a> becomes
    </p>
    <table width="100%">
      <tr>
        <td width="100%" align="center">\(\displaystyle S (x|x_0) = \sum_{i = 0}^{N - 1}
        \sum_{\alpha = 1}^n \frac{\Delta t}{2} \left[
\frac{x^{\alpha}_{i + 1}
        - x^{\alpha}_i}{\Delta t} - f^{\alpha} (x_i)
\right]^2 . \)</td>
        <td align="right">(33)</td>
      </tr>
    </table>
    <p>
      Comparing with classical mechanics, we can interpret \(\Delta t\) as a
      tiny time interval and \((x_{i + 1} - x_i) / \Delta t\) as
      &ldquo;velocity&rdquo;. It motives us to consider its continuous
      version. To do so, we assume that the \(\Delta t\) is very small and
      \(N\) is sufficiently large, so that \(N \Delta t = \mathcal{O} (1)\).
      Then, we simply replace \(\Delta t\) by \(\mathrm{d} t\), and the series
      \((x_0, \ldots, x_N)\) becomes \(x (t)\) with \(t \in [0, t_f]\), where
      \(t_f := N \Delta t\), and \(x_0\) becomes \(x (0)\). Accordingly, \(f
      (x_i)\) becomes \(f (x (t))\). So, we get the continuous version of
      equation <a href="#equation:action of langevin process v2">33</a>, as
    </p>
    <center>
      \(\displaystyle S (x|x (0)) = \frac{1}{2} \int_0^{t_f} \mathrm{d} t
      \sum_{\alpha = 1}^n
[\dot{x}^{\alpha} (t) - f^{\alpha} (x (t))]^2 .\)
    </center>
    <p>
      To get the Lagrange \(L\), which is defined by \(S (x|x (0)) = \int
      \mathrm{d} t L (x (t), \dot{x} (t), t)\), we expand the integrand and
      find
    </p>
    <table width="100%">
      <tr>
        <td width="100%" align="center">\(\displaystyle L (x, \dot{x}, t) = \sum_{\alpha =
        1}^n \left[ \frac{1}{2}
(\dot{x}^{\alpha})^2 - \dot{x}^{\alpha}
        f^{\alpha} (x) + \frac{1}{2}
(f^{\alpha} (x))^2 \right] . \)</td>
        <td align="right">(34)</td>
      </tr>
    </table>
    <p>
      
    </p>
    <p>
      For evaluating Euler-Lagrange equation, we have to fix the boundary \(x
      (t_f)\) (recall \(x (0)\) has been fixed), since Euler-Lagrange equation
      is derived by fixing boundaries on both \(t = 0\) and \(t = t_f\). It
      suggests us to consider the expectation \(\int_{\mathbb{R}^n} \mathrm{d}
      x (t_f) q (x (t) |x_0) \delta (x_f - x (t_f))\) for any \(x_f \in
      \mathbb{R}^n\). Given the boundary values at \(t = 0\) and \(t = t_f\),
      variation on \(x (t)\) gives the Euler-Lagrange equation \((\mathrm{d} /
      \mathrm{d} t) \partial L / \partial \dot{x}^{\alpha} = \partial
L /
      \partial x^{\alpha}\). We have \(\partial L / \partial \dot{x}^{\alpha}
      = \dot{x}^{\alpha} - f^{\alpha} (x)\) and \(\partial L / \partial
      x^{\alpha} = \sum_{\beta = 1}^n [- \dot{x}^{\beta} +
f^{\beta} (x)]
      \partial_{\alpha} f^{\beta} (x)\), where we have denoted
      \(\partial_{\alpha} f^{\beta} := \partial f^{\beta} / \partial
      x^{\alpha}\). Thus, Euler-Lagrange equation becomes
    </p>
    <center>
      \(\displaystyle \ddot{x}^{\alpha} = \sum_{\beta = 1}^n [\partial_{\beta}
      f^{\alpha} (x) -
\partial_{\alpha} f^{\beta} (x)]  \dot{x}^{\beta} +
      \sum_{\beta = 1}^n
f^{\beta} (x) \partial_{\alpha} f^{\beta} (x) .\)
    </center>
    <p>
      The first term in the right hand side is recognized as <em>friction,
      proportional to the curl of \(f\)</em>. The second term represents a
      driving force.
    </p>
    <h3 id="auto-33"><a id="section: How Far Will Information Propagate in Langevin Process?"></a>4.8<span style="margin-left: 1em"></span>How Far Will Information
    Propagate in Langevin Process?<span style="margin-left: 1em"></span></h3>
    <p>
      We are to determine how far information will propagate during the
      iteration of Langevin process (see section TODO). For this kind of
      problem, physicists have invented a technique called renormalization
      group. This technique was first proposed by Murray Gell-Mann and Francis
      Low in 1954, applied to quantum field theory of fundamental particles.
      Following this research, Kenneth Wilson, who was a PhD student of
      Gell-Mann, started his malathion in 1961. He published his first paper
      on renormalization group eight years later, in 1969. This technique was
      then further developed and applied to many areas in and even out of
      physics, such as neural science.
    </p>
    <p>
      To show how it works, we start with an action that is generalized from
      action <a href="#equation:action of langevin process v2">33</a>, which is
    </p>
    <table width="100%">
      <tr>
        <td width="100%" align="center">\(\displaystyle S (x) = \sum_{i = - \infty}^{+
        \infty} \sum_{\alpha = 1}^n \left[
\frac{(x^{\alpha}_{i + 1} -
        x^{\alpha}_i)^2}{2 \epsilon} - (x^{\alpha}_{i + 1}
- x^{\alpha}_i)
        \varphi^{\alpha} (x_{i + 1}, x_i) + \epsilon \xi^{\alpha}
(x_{i + 1},
        x_i) \right], \)</td>
        <td align="right">(35)</td>
      </tr>
    </table>
    <p>
      where \(\varphi, \xi : \mathbb{R}^n \times \mathbb{R}^n \rightarrow
      \mathbb{R}^n\). Comparing with action <a href="#equation:action of langevin process v2">33</a>, \(\epsilon =
      \Delta t\), \(\varphi (x_{i + 1}, x_i) = f (x_i)\), and \(\xi (x_{i +
      1}, x_i) = f^2 (x_i) / 2\). There are another two differences between
      them. Here, we do not fix boundary (namely, the condition \(x_0\) in \(S
      (x|x_0)\)), and let the index \(i\) run from \(- \infty\) to \(+
      \infty\) rather than from \(0\) to \(N\). As we will see later in this
      section, these differences are crucial for renormalization group. In the
      end of this section, we will show how to add the condition back and
      restrict the range of index \(i\).
    </p>
    <p>
      Renormalization group technique bases on the fact that there are as many
      even numbers as integers. This is a famous result that was first claimed
      by George Cantor. For our purpose, we marginalize all the variable
      \(x_i\) in \(q (x)\) where \(i\) is odd. Namely, we are to compute an
      &ldquo;effective action&rdquo; \(S'\) defined by
    </p>
    <table width="100%">
      <tr>
        <td width="100%" align="center">\(\displaystyle S' (x) := - \ln \left[ \prod_{i \in
        \mathbb{Z}} \int_{\mathbb{R}^n} \mathrm{d}
x_{2 i + 1} \exp (- S (x))
        \right], \)</td>
        <td align="right">(36)</td>
      </tr>
    </table>
    <p>
      where \(S' (\ldots, x_{- 4}, x_{- 2}, x_0, x_2, x_4, \ldots)\) contains
      only the variables with even index. Interestingly, it is to be revealed
      that, by a proper re-scaling of \(x\), \(S'\) has exactly the same
      format as \(S\).
    </p>
    <p>
      Given \(i\), we are to show how to marginalize \(x_{2 i + 1}\). This
      variables appear in two terms in action <a href="#equation:rg action">35</a>, with indices
      \(2 i + 1\) and \(2 i\). So, we are to integrate \(\int_{\mathbb{R}^n}
      \mathrm{d} x_{2 i + 1} \exp \left( \sum_{\alpha = 1}^n
J^{\alpha}
      \right)\) where
    </p>
    <center>
      \(\displaystyle \begin{array}{rl}
  J^{\alpha} := & -
      \frac{(x^{\alpha}_{2 i + 1} - x^{\alpha}_{2 i})^2}{2
  \epsilon} -
      \frac{(x^{\alpha}_{2 i + 2} - x^{\alpha}_{2 i + 1})^2}{2
  \epsilon}\\
 
      & + (x^{\alpha}_{2 i + 1} - x^{\alpha}_{2 i}) \varphi^{\alpha} (x_{2 i
      +
  1}, x_{2 i}) + (x^{\alpha}_{2 i + 2} - x^{\alpha}_{2 i + 1})
 
      \varphi^{\alpha} (x_{2 i + 2}, x_{2 i + 1})\\
  & - \epsilon
      \xi^{\alpha} (x_{2 i + 1}, x_{2 i}) - \epsilon \xi^{\alpha}
  (x_{2 i +
      2}, x_{2 i + 1}) .
\end{array}\)
    </center>
    <p>
      This integral is hard to calculate. A general strategy is using
      perturbative method. In our situation, \(\epsilon\) serves as the small
      quantity for perturbation.
    </p>
    <p>
      First, we have an algebraic identity
      <div class="footnote">
        <font style="font-size: 77.1%"><div align="justify">
          <div style="margin-left: 0px">
            <div style="margin-right: 0px">
              <class style="font-style: normal"><p>
                15. Directly, expand \((x - y)^2 + (y - z)^2 = x^2 - 2 x y +
                y^2 + y^2 - 2 y z + z^2\). Then, collect the \(y\) terms
                together, as \(2 (y^2 - (x + z) y) = 2 (y - (x + z) y + (x +
                z)^2 / 4) - (x + z)^2 / 2 = 2 (y
- (x + z) / 2)^2 - (x + z)^2
                / 2\), in which the last term can be further combined with the
                rest terms \(x^2 + z^2\), as \(- (x + z)^2 / 2 + x^2 + z^2 =
                (x - z)^2 / 2\). Altogether, we find
              </p><center>
                \(\displaystyle (x - y)^2 + (y - z)^2 = 2 \left( y - \frac{x +
                z}{2} \right)^2 + \frac{1}{2}
(x - z)^2 .\)
              </center><p>
                If replace \(x \rightarrow x^{\alpha}_{2 i}\), \(y \rightarrow
                x^{\alpha}_{2 i + 1}\), and \(z \rightarrow x^{\alpha}_{2 i +
                2}\), then we get what we need.
              </p></class>
            </div>
          </div>
        </div></font>
      </div>
      <span style="margin-left: 0em"></span>
      <a id="footnr-15"></a>
      <sup><class style="font-style: normal"><a href="#footnote-15">15</a></class></sup>
    </p>
    <center>
      \(\displaystyle \frac{(x^{\alpha}_{2 i + 1} - x^{\alpha}_{2 i})^2}{2
      \epsilon} +
\frac{(x^{\alpha}_{2 i + 2} - x^{\alpha}_{2 i + 1})^2}{2
      \epsilon} =
\frac{1}{\epsilon} \left[ x^{\alpha}_{2 i + 1} -
      \frac{x^{\alpha}_{2 i} +
x^{\alpha}_{2 i + 2}}{2} \right]^2 + \frac{1}{4
      \epsilon} (x^{\alpha}_{2 i} -
x^{\alpha}_{2 i + 2})^2 .\)
    </center>
    <p>
      Remark that the second term looks like the first term in action <a href="#equation:rg action">35</a>,
      except for an \(1 / 2\) factor. Then, \(J^{\alpha}\) becomes
    </p>
    <center>
      \(\displaystyle \begin{array}{rl}
  J^{\alpha} = & - \frac{1}{\epsilon}
      \left[ x^{\alpha}_{2 i + 1} -
  \frac{x^{\alpha}_{2 i} + x^{\alpha}_{2 i
      + 2}}{2} \right]^2 - \frac{1}{4
  \epsilon} (x^{\alpha}_{2 i} -
      x^{\alpha}_{2 i + 2})^2\\
  & + (x^{\alpha}_{2 i + 1} - x^{\alpha}_{2
      i}) \varphi^{\alpha} (x_{2 i +
  1}, x_{2 i}) + (x^{\alpha}_{2 i + 2} -
      x^{\alpha}_{2 i + 1})
  \varphi^{\alpha} (x_{2 i + 2}, x_{2 i + 1})\\
 
      & - \epsilon \xi^{\alpha} (x_{2 i + 1}, x_{2 i}) - \epsilon
      \xi^{\alpha}
  (x_{2 i + 2}, x_{2 i + 1}) .
\end{array}\)
    </center>
    <p>
      The first term is a quadratic form of \(x_{2 i + 1}\). It suggests that
      we shall treat the integral as a perturbation to the Gaussian integral,
      and use perturbative method to integrate it out. Following this
      strategy, we define \(\bar{x}_{2 i + 1} := (x_{2 i + 2} + x_{2 i}) / 2\)
      and \(y := x_{2 i + 1} - \bar{x}_{2 i + 1}\). \(\)And the integral
      becomes
    </p>
    <font style="font-size: 84.1%"><center>
      \(\displaystyle \int_{\mathbb{R}^n} \mathrm{d} x_{2 i + 1} \exp \left(
      \sum_{\alpha = 1}^n
J^{\alpha} \right) = \int_{\mathbb{R}^n} \mathrm{d}
      y \exp \left( -
\frac{1}{2} \sum_{\alpha = 1}^n \left(
      \frac{y^{\alpha}}{\sqrt{\epsilon / 2}}
\right)^2 + \cdots \right) .\)
    </center></font>
    <p>
      It means the \(y\) obeys a normal distribution with zero mean and
      diagonal covariance \(\Sigma_{\alpha \beta} = (\epsilon / 2)
      \delta_{\alpha \beta}\). We have a rough estimation \(y = \mathcal{O}
      \left( \sqrt{\epsilon} \right)\).
    </p>
    <p>
      Next, we process the other lines in \(J^{\alpha}\). Using \(x_{2 i + 1}
      = y + \bar{x}_{2 i + 1}\) and \(\bar{x}_{2 i + 1} - x_{2 i} = x_{2 i +
      2} - \bar{x}_{2 i + 1} = (x_{2 i + 2} -
x_{2 i}) / 2\), the second line
      can be expanded, up to \(\mathcal{O} (\epsilon^{3 / 2})\), as
    </p>
    <font style="font-size: 84.1%"><center>
      \(\displaystyle \begin{array}{rl}
  & (y^{\alpha} + \bar{x}_{2 i +
      1}^{\alpha} - x^{\alpha}_{2 i})
  \varphi^{\alpha} (y + \bar{x}_{2 i +
      1}, x_{2 i}) + (x^{\alpha}_{2 i + 2} -
  y^{\alpha} - \bar{x}_{2 i +
      1}^{\alpha}) \varphi^{\alpha} (x_{2 i + 2}, y +
  \bar{x}_{2 i + 1})\\
 
      = & \frac{1}{2} (x^{\alpha}_{2 i + 2} - x^{\alpha}_{2 i}) 
      [\varphi^{\alpha}
  (\bar{x}_{2 i + 1}, x_{2 i}) + \varphi^{\alpha}
      (x_{2 i + 2}, \bar{x}_{2 i +
  1})]\\
  + & y^{\alpha} 
      [\varphi^{\alpha} (\bar{x}_{2 i + 1}, x_{2 i}) -
  \varphi^{\alpha}
      (x_{2 i + 2}, \bar{x}_{2 i + 1})]\\
  + & \frac{1}{2} y^{\beta} 
      (x^{\alpha}_{2 i + 2} - x^{\alpha}_{2 i}) 
  [\partial_{\beta}
      \varphi^{\alpha} (\bar{x}_{2 i + 1}, x_{2 i}) +
  \partial_{\beta}'
      \varphi^{\alpha} (x_{2 i + 2}, \bar{x}_{2 i + 1})]\\
  + & y^{\alpha}
      y^{\beta}  [\partial_{\beta} \varphi^{\alpha} (\bar{x}_{2 i +
  1}, x_{2
      i}) - \partial_{\beta}' \varphi^{\alpha} (x_{2 i + 2}, \bar{x}_{2 i
  +
      1})]\\
  + & \frac{1}{4} y^{\beta} y^{\gamma}  (x^{\alpha}_{2 i + 2} -
      x^{\alpha}_{2
  i})  [\partial_{\beta} \partial_{\gamma}
      \varphi^{\alpha} (\bar{x}_{2 i +
  1}, x_{2 i}) + \partial_{\beta}'
      \partial'_{\gamma} \varphi^{\alpha} (x_{2 i
  + 2}, \bar{x}_{2 i +
      1})]
\end{array}\)
    </center></font>
    <p>
      where we have denoted \(\partial \varphi\) as the partial derivative
      taken on the first argument, and \(\partial' \varphi\) on the second.
      Notice that we have used Einstein convention in this expansion (see the
      conventions in section <a href="#section: Kramers-Moyal Expansion and Langevin Process">3</a>), hiding the summations of indices
      \(\beta\) and \(\gamma\). Also up to \(\mathcal{O} (\epsilon^{3 / 2})\),
      the third line simply becomes \(- \epsilon \xi^{\alpha} (\bar{x}_{2 i +
      1}, x_{2 i}) - \epsilon \xi^{\alpha}
(x_{2 i + 2}, \bar{x}_{2 i + 1})\).
      Altogether, the integral becomes
    </p>
    <font style="font-size: 84.1%"><center>
      \(\displaystyle \exp \left( \sum_{\alpha = 1}^n I^{\alpha} \right)
      \times \int_{\mathbb{R}^n}
\mathrm{d} y \exp \left( - \frac{1}{2}
      \sum_{\alpha = 1}^n \left(
\frac{y^{\alpha}}{\sqrt{\epsilon / 2}}
      \right)^2 + \sum_{\alpha = 1}^n
V^{\alpha} (y) + \mathcal{O}
      (\epsilon^{3 / 2}) \right),\)
    </center></font>
    <p>
      with the &ldquo;interactive part&rdquo;
    </p>
    <font style="font-size: 84.1%"><center>
      \(\displaystyle \begin{array}{rl}
  V^{\alpha} (y) := & y^{\alpha} 
      [\varphi^{\alpha} (\bar{x}_{2 i + 1}, x_{2
  i}) - \varphi^{\alpha}
      (x_{2 i + 2}, \bar{x}_{2 i + 1})]\\
  + & \frac{1}{2} y^{\beta} 
      (x^{\alpha}_{2 i + 2} - x^{\alpha}_{2 i}) 
  [\partial_{\beta}
      \varphi^{\alpha} (\bar{x}_{2 i + 1}, x_{2 i}) +
  \partial_{\beta}'
      \varphi^{\alpha} (x_{2 i + 2}, \bar{x}_{2 i + 1})]\\
  + & y^{\alpha}
      y^{\beta}  [\partial_{\beta} \varphi^{\alpha} (\bar{x}_{2 i +
  1}, x_{2
      i}) - \partial_{\beta}' \varphi^{\alpha} (x_{2 i + 2}, \bar{x}_{2 i
  +
      1})]\\
  + & \frac{1}{4} y^{\beta} y^{\gamma}  (x^{\alpha}_{2 i + 2} -
      x^{\alpha}_{2
  i})  [\partial_{\beta} \partial_{\gamma}
      \varphi^{\alpha} (\bar{x}_{2 i +
  1}, x_{2 i}) + \partial_{\beta}'
      \partial'_{\gamma} \varphi^{\alpha} (x_{2 i
  + 2}, \bar{x}_{2 i +
      1})],
\end{array}\)
    </center></font>
    <p>
      which depends on \(y\) and is \(\mathcal{O} \left( \sqrt{\epsilon}
      \right)\), and the &ldquo;independent part&rdquo; (the color is for
      later usage)
    </p>
    <font style="font-size: 84.1%"><center>
      \(\displaystyle I^{\alpha} := - \frac{1}{4 \epsilon} (x^{\alpha}_{2 i} -
      x^{\alpha}_{2 i +
2})^2 + \frac{1}{2} (x^{\alpha}_{2 i + 2} -
      x^{\alpha}_{2 i}) 
[\varphi^{\alpha} (\bar{x}_{2 i + 1}, x_{2 i}) +
      \varphi^{\alpha} (x_{2 i +
2}, \bar{x}_{2 i + 1})] {\color{red}{-
      \epsilon \xi^{\alpha} (\bar{x}_{2 i +
1}, x_{2 i}) - \epsilon
      \xi^{\alpha} (x_{2 i + 2}, \bar{x}_{2 i + 1})}},\)
    </center></font>
    <p>
      which is independent of \(y\). We Taylor expands the second factor as
    </p>
    <font style="font-size: 84.1%"><center>
      \(\displaystyle \int_{\mathbb{R}^n} \mathrm{d} y \exp \left( -
      \frac{1}{2} \sum_{\alpha = 1}^n
\left( \frac{y^{\alpha}}{\sqrt{\epsilon
      / 2}} \right)^2 + \sum_{\alpha = 1}^n
V^{\alpha} (y) + \mathcal{O}
      (\epsilon^{3 / 2}) \right) =\mathbb{E}_Y \left[ 1
+ \sum_{\alpha = 1}^n
      V^{\alpha} (y) + \frac{1}{2} \left( \sum_{\alpha = 1}^n
V^{\alpha} (y)
      \right)^2 + \mathcal{O} (\epsilon^{3 / 2}) \right],\)
    </center></font>
    <p>
      where \(\mathbb{E}_Y [\ldots]\) is defined by the Gaussian integral of
      \(y\). We will neglect the constant factor \((\pi \epsilon)^{- n / 2}\),
      so that \(\mathbb{E}_Y [1] = 1\). This constant factor can be absorbed
      into the action as an irrelevant constant term. Plugging in the
      definition of \(V^{\alpha} (y)\) with \(\mathbb{E}_Y [y^{\alpha}] = 0\)
      and \(\mathbb{E}_Y [y^{\alpha} y^{\beta}] = \delta_{\alpha \beta}
      \epsilon / 2\), we get (color for later usage)
    </p>
    <font style="font-size: 70.7%"><p>
      <font color="#008000"><center>
        \(\displaystyle \sum_{\alpha = 1}^n \mathbb{E} [V^{\alpha} (y)] =
        \frac{\epsilon}{2}
\sum_{\alpha = 1}^n \left[ \partial_{\alpha}
        \varphi^{\alpha} (\bar{x}_{2 i +
1}, x_{2 i}) - \partial_{\alpha}'
        \varphi^{\alpha} (x_{2 i + 2}, \bar{x}_{2 i
+ 1}) + \frac{1}{4} 
        \left( x^{\alpha}_{2 i + 2} - x^{\alpha}_{2 i} \right) 
[\Delta
        \varphi^{\alpha} (\bar{x}_{2 i + 1}, x_{2 i}) +
        \Delta'
\varphi^{\alpha} (x_{2 i + 2}, \bar{x}_{2 i + 1})] \right],\)
      </center></font>
    </p></font>
    <p>
      where the Laplacian \(\Delta' := \sum_{\alpha = 1}^n \partial_{\alpha}
      \partial_{\alpha}\), and the same \(\Delta' := \sum_{\alpha = 1}^n
      \partial'_{\alpha} \partial'_{\alpha}\). Also, we have (color for later
      usage)
      <div class="footnote">
        <font style="font-size: 77.1%"><div align="justify">
          <div style="margin-left: 0px">
            <div style="margin-right: 0px">
              <class style="font-style: normal"><p>
                16. We have \(\mathbb{E}_Y \left[ (1 / 2) \left( \sum_{\alpha
                = 1}^n V^{\alpha} (y)
\right)^2 \right] = (1 / 2)
                \sum_{\alpha, \alpha' = 1}^n \mathbb{E}_Y
[V^{\alpha} (y)
                V^{\alpha'} (y)]\), where
              </p><center>
                \(\displaystyle \begin{array}{rl}
  & \mathbb{E}_Y [V^{\alpha}
                (y) V^{\alpha'} (y)]\\
  = & \frac{\delta_{\alpha \alpha'}
                \epsilon}{2}  [\varphi^{\alpha}_{2 i}
  (\bar{x}_{2 i + 1},
                x_{2 i}) - \varphi^{\alpha}_{2 i + 1} (x_{2 i + 2},
 
                \bar{x}_{2 i + 1})]^2\\
  + & \frac{\epsilon}{4} 
                (x^{\alpha'}_{2 i + 2} - x^{\alpha'}_{2 i}) 
 
                [\varphi^{\alpha}_{2 i} (\bar{x}_{2 i + 1}, x_{2 i}) -
                \varphi^{\alpha}_{2 i
  + 1} (x_{2 i + 2}, \bar{x}_{2 i + 1})]
                [\partial_{\alpha}
  \varphi^{\alpha'}_{2 i} (\bar{x}_{2 i +
                1}, x_{2 i}) + \partial_{\alpha}'
  \varphi^{\alpha'}_{2 i +
                1} (x_{2 i + 2}, \bar{x}_{2 i + 1})]\\
  + &
                \frac{\epsilon}{4}  (x^{\alpha}_{2 i + 2} - x^{\alpha}_{2 i})
                
  [\varphi^{\alpha'}_{2 i} (\bar{x}_{2 i + 1}, x_{2 i}) -
                \varphi^{\alpha'}_{2
  i + 1} (x_{2 i + 2}, \bar{x}_{2 i +
                1})]  [\partial_{\alpha'}
  \varphi^{\alpha}_{2 i} (\bar{x}_{2
                i + 1}, x_{2 i}) + \partial_{\alpha'}'
  \varphi^{\alpha}_{2 i
                + 1} (x_{2 i + 2}, \bar{x}_{2 i + 1})]\\
  + &
                \frac{\epsilon}{8}  (x^{\alpha}_{2 i + 2} - x^{\alpha}_{2 i})
                
  (x^{\alpha'}_{2 i + 2} - x^{\alpha'}_{2 i})  \sum_{\beta =
                1}^n
  [\partial_{\beta} \varphi^{\alpha}_{2 i} (\bar{x}_{2 i
                + 1}, x_{2 i}) +
  \partial_{\beta}' \varphi^{\alpha}_{2 i +
                1} (x_{2 i + 2}, \bar{x}_{2 i +
  1})]  [\partial_{\beta}
                \varphi^{\alpha'}_{2 i} (\bar{x}_{2 i + 1}, x_{2 i})
  +
                \partial_{\beta}' \varphi^{\alpha'}_{2 i + 1} (x_{2 i + 2},
                \bar{x}_{2 i +
  1})] .
\end{array}\)
              </center><p>
                
              </p></class>
            </div>
          </div>
        </div></font>
      </div>
      <span style="margin-left: 0em"></span>
      <a id="footnr-16"></a>
      <sup><class style="font-style: normal"><a href="#footnote-16">16</a></class></sup>
    </p>
    <font color="#000080"><font style="font-size: 70.7%"><center>
      \(\displaystyle \begin{array}{rl}
  & \mathbb{E} \left[ \frac{1}{2}
      \left( \sum_{\alpha = 1}^n V^{\alpha} (y)
  \right)^2 \right]\\
  = &
      \frac{\epsilon}{4} \sum_{\alpha = 1}^n [\varphi^{\alpha} (\bar{x}_{2 i
      +
  1}, x_{2 i}) - \varphi^{\alpha} (x_{2 i + 2}, \bar{x}_{2 i +
      1})]^2\\
  + & \frac{\epsilon}{4} \sum_{\alpha, \alpha' = 1}^n
      (x^{\alpha}_{2 i + 2} -
  x^{\alpha}_{2 i})  [\partial_{\alpha'}
      \varphi^{\alpha} (\bar{x}_{2 i + 1},
  x_{2 i}) + \partial_{\alpha'}'
      \varphi^{\alpha} (x_{2 i + 2}, \bar{x}_{2 i +
  1})]  [\varphi^{\alpha'}
      (\bar{x}_{2 i + 1}, x_{2 i}) - \varphi^{\alpha'}
  (x_{2 i + 2},
      \bar{x}_{2 i + 1})]\\
  + & \frac{\epsilon}{16} \sum_{\alpha, \alpha',
      \beta = 1}^n (x^{\alpha}_{2 i
  + 2} - x^{\alpha}_{2 i}) 
      [\partial_{\beta} \varphi^{\alpha} (\bar{x}_{2 i +
  1}, x_{2 i}) +
      \partial_{\beta}' \varphi^{\alpha} (x_{2 i + 2}, \bar{x}_{2 i
  + 1})] 
      (x^{\alpha'}_{2 i + 2} - x^{\alpha'}_{2 i})  [\partial_{\beta}
 
      \varphi^{\alpha'} (\bar{x}_{2 i + 1}, x_{2 i}) + \partial_{\beta}'
 
      \varphi^{\alpha'} (x_{2 i + 2}, \bar{x}_{2 i + 1})]
\end{array}\)
    </center></font></font>
    <p>
      Plugging all these back to the integral, and defining \(x'_i = x_{2 i} /
      \sqrt{2}\) for all \(i\), we find, (up to an irrelevant constant term),
    </p>
    <font style="font-size: 84.1%"><center>
      \(\displaystyle - \ln \left[ \int_{\mathbb{R}^n} \mathrm{d} x_{2 i + 1}
      \exp \left(
\sum_{\alpha = 1}^n J^{\alpha} \right) \right] =
      \sum_{\alpha = 1}^n \left[
\frac{1}{2 \epsilon} \left( {x'}^{\alpha}_{i
      + 1} {- x'}^{\alpha}_i \right)^2
- \left( {x'}^{\alpha}_{i + 1} -
      x^{\alpha}_i \right) {\varphi'}^{\alpha}
(x'_{i + 1}, x'_i) {+ \epsilon
      \xi'}^{\alpha} (x_{i + 1}', x_i') \right],\)
    </center></font>
    <p>
      where
    </p>
    <center>
      \(\displaystyle {\varphi'}^{\alpha} (x'_{i + 1}, x'_i) :=
      \frac{1}{\sqrt{2}} [\varphi^{\alpha}
(\bar{x}_{2 i + 1}, x_{2 i}) +
      \varphi^{\alpha} (x_{2 i + 2}, \bar{x}_{2 i +
1})]\)
    </center>
    <p>
      and
    </p>
    <font style="font-size: 84.1%"><center>
      \(\displaystyle {\xi'}^{\alpha}_i (x_{i + 1}', x_i') :=
      {\color{red}{\xi^{\alpha} (\bar{x}_{2
i + 1}, x_{2 i}) + \xi^{\alpha}
      (x_{2 i + 2}, \bar{x}_{2 i + 1})}} {-
\frac{1}{2} [\partial_{\alpha}
      \varphi^{\alpha} (\bar{x}_{2 i + 1}, x_{2 i}) -
\partial_{\alpha}'
      \varphi^{\alpha} (x_{2 i + 2}, \bar{x}_{2 i + 1})]} {-
\frac{1}{4}
      [\varphi^{\alpha} (\bar{x}_{2 i + 1}, x_{2 i}) - \varphi^{\alpha}
(x_{2
      i + 2}, \bar{x}_{2 i + 1})]^2} {- \frac{1}{8} (x^{\alpha}_{2 i + 2}
      -
x^{\alpha}_{2 i})  [\Delta \varphi^{\alpha} (\bar{x}_{2 i + 1}, x_{2
      i}) +
\Delta' \varphi^{\alpha} (x_{2 i + 2}, \bar{x}_{2 i + 1})]} {-
      \frac{1}{4}
\sum_{\alpha' = 1}^n (x^{\alpha}_{2 i + 2} - x^{\alpha}_{2
      i}) 
[\partial_{\alpha'} \varphi^{\alpha} (\bar{x}_{2 i + 1}, x_{2 i})
      +
\partial_{\alpha'}' \varphi^{\alpha} (x_{2 i + 2}, \bar{x}_{2 i + 1})]
      
[\varphi^{\alpha'} (\bar{x}_{2 i + 1}, x_{2 i}) - \varphi^{\alpha'}
      (x_{2 i +
2}, \bar{x}_{2 i + 1})] - \frac{1}{16} \sum_{\alpha', \beta =
      1}^n
(x^{\alpha}_{2 i + 2} - x^{\alpha}_{2 i})  [\partial_{\beta}
      \varphi^{\alpha}
(\bar{x}_{2 i + 1}, x_{2 i}) + \partial_{\beta}'
      \varphi^{\alpha} (x_{2 i +
2}, \bar{x}_{2 i + 1})]  (x^{\alpha'}_{2 i +
      2} - x^{\alpha'}_{2 i}) 
[\partial_{\beta} \varphi^{\alpha'} (\bar{x}_{2
      i + 1}, x_{2 i}) +
\partial_{\beta}' \varphi^{\alpha'} (x_{2 i + 2},
      \bar{x}_{2 i + 1})]} +
\mathcal{O} \left( \sqrt{\epsilon} \right),\)
    </center></font>
    <p>
      where we have indicated the source of the terms by color. This is held
      for all \(i\), thus we arrive at
    </p>
    <center>
      \(\displaystyle S' (x') = \sum_{i = - \infty}^{+ \infty} \sum_{\alpha =
      1}^n \left[ \frac{1}{2
\epsilon} \left( {x'}^{\alpha}_{i + 1} {-
      x'}^{\alpha}_i \right)^2 - \left(
{x'}^{\alpha}_{i + 1} {-
      x'}^{\alpha}_i \right) {\varphi'}^{\alpha} (x'_{i +
1}, x'_i) {+
      \epsilon \xi'}^{\alpha} (x_{i + 1}', x_i') \right],\)
    </center>
    <p>
      which has exactly the same format as \(S\) (equation <a href="#equation:rg action">35</a>).
    </p>
    <h3 id="auto-34">4.9<span style="margin-left: 1em"></span>Example: Action in Deep Learning
    (TODO)<span style="margin-left: 1em"></span></h3>
    <p>
      In deep learning, a feed-forward network is a supervised model that
      computes the output \(y \in \mathbb{R}^{n_L}\) from input \(x \in
      \mathbb{R}^{n_0}\). (In some cases, such as natural language process,
      \(x\) is the embedding vector; and for classification task, \(y\) is the
      logits, the input of softmax function.) It iteratively computes a series
      of intermediate quantities called hidden variables \((h_1, \ldots, h_{L
      - 1})\) with \(h_l \in \mathbb{R}^{n_l}\) by
    </p>
    <center>
      \(\displaystyle h^{\alpha}_{l + 1} = f^{\alpha}_l (h_l),\)
    </center>
    <p>
      where \(f_l : \mathbb{R}^{n_l} \rightarrow \mathbb{R}^{n_{l + 1}}\). By
      denoting \(h_0 := x\) and \(h_L := y\), we have \(l \in \{ 0, \ldots, L
      \}\). This naive structure suffers many issues caused by increasing the
      number of layers. In 2015, Kaiming He and others proposed a residual
      structure, in which all the \(n_l\)s are equal, and \(h^{\alpha}_{l + 1}
      = h_l^{\alpha} + \epsilon g^{\alpha}_l (h_l)\). This is consistent with
      the discussion in section <a href="#section: Action of Iterative Equation Has Friction">?</a>, thus the results obtained
      there also holds for deep learning. And we get an action of feed-forward
      network as equation <a href="#equation:action of iterative equation v2">?</a>.
    </p>
    <p>
      For perceptrons, \(g^{\alpha}_l (h_l) = \sigma ((W_l)^{\alpha}_{\beta}
      h^{\beta} + b^{\alpha}_l)\) for some activation function \(\sigma :
      \mathbb{R} \rightarrow \mathbb{R}\), such as sigmoid function \(1 / (1 +
      \exp (- x))\). TODO
    </p>
    <p>
      If \(W \cdot h\) is small enough, then we can safely Taylor expand
      \(\sigma\) at zero, as
    </p>
    <center>
      \(\displaystyle \sigma (x) = \frac{1}{2} + \frac{x}{4} - \frac{x^3}{48}
      + \cdots .\)
    </center>
    <h3 id="auto-35">4.10<span style="margin-left: 1em"></span>* History: Structures in Nature Arise from
    Least-Action Principle<span style="margin-left: 1em"></span></h3>
    <p>
      There are many structures in nature. The structure of vascular system is
      a simple instance. A more complicated structure appears in the bases
      along chromosome. Why do these structures arise in nature?
    </p>
    <h4 id="auto-36">4.10.1<span style="margin-left: 1em"></span>WBE Theory and Universality<span style="margin-left: 1em"></span></h4>
    <p>
      Early in 1997, physicist Geoffrey West, ecologist James Brown, and
      biologist Brian Enquist proposed a theory (now it is called WBE theory)
      that explains how the fractal structures arise in vascular system of
      mammals.
      <div class="footnote">
        <font style="font-size: 77.1%"><div align="justify">
          <div style="margin-left: 0px">
            <div style="margin-right: 0px">
              <class style="font-style: normal"><p>
                17. <i>A General Model for the Origin of Allometric Scaling
                Laws in Biology</i>. DOI: 10.1126/SCIENCE.276.5309.122
              </p></class>
            </div>
          </div>
        </div></font>
      </div>
      <span style="margin-left: 0em"></span>
      <a id="footnr-17"></a>
      <sup><class style="font-style: normal"><a href="#footnote-17">17</a></class></sup>
      To do so, they
      <em>derived</em>
      an objective that quantifies the cost of transporting blood. They found
      that the fractal structure of vascular appears naturally by minimizing
      this cost. Also arises the power-law relationship between the basal
      metabolic rate and the body size of mammal, which was first observed by
      Max Kleiber in 1930 and now named by
      <a href="https://en.wikipedia.org/wiki/Kleiber%27s_law">Kleiber's law</a>
      . Later, they applied their theory to many areas that have no
      superficial relationship with biology, such as gross domestic product of
      city. They successfully predicted some observed quantities in these
      areas.
    </p>
    <p>
      Inspired by WBE theory, we regard the cost as an action. Instead of
      deriving a cost/action as WBE does, we can use the technique declared in
      section <a href="#section: Data Fitting Is Equivalent to Least-Action Principle of Distribution">4.4</a> to reveal one if we have obtained sufficiently
      many observed data. In machine learning perspective, data fitting is
      also seen as pattern mining. It reveals the statistically significant
      patterns hidden in the data. These patterns are the structures
      frequently appear in nature, and they locate in the minima of an
      objective, as WBE theory claimed, an action.
    </p>
    <p>
      An interesting aspect of WBE theory is that the quantitative results
      obtained by minimizing the cost in one system are also held by a large
      variety of systems in nature. For example, different systems may share
      the same power-law index. This property is called
      <strong>universality</strong>. Where does universality come from?
    </p>
    <h4 id="auto-37">4.10.2<span style="margin-left: 1em"></span>Renormalization Group and
    Criticality<span style="margin-left: 1em"></span></h4>
    <p>
      In 1975, physicist Mitchell Feigenbaum computed two constants, now named
      as Feigenbaum constants, when he was studying the logistic map. Then in
      the late of 1970s, physicists found that Feigenbaum constants also
      appear in many other areas such as turbulence and Mandelbrot set:
      Feigenbaum constants are universal. Feigenbaum himself gave a
      &ldquo;proof&rdquo; of how this universality appears. The technique he
      used was invented by his collage in Cornell University, Kenneth Wilson,
      called renormalization group. With this technique, Feigenbaum
      constructed a functional iterative equation, and found his constants as
      the Taylor coefficients of the non-trivial fixed point of the functional
      iterative equation. But, Feigenbaum said little about where this
      functional iterative equation comes from. He neither gave a rigorous
      derivation of the equation, nor argued why this equation holds also for
      other systems.
    </p>
    <p>
      Generally, universality comes from a &ldquo;complex&rdquo; system, a
      system whose configuration (defined in section <a href="#section: A Brief Review of Least-Action Principle in Classical Mechanics">4.2</a>) has a
      large number of components, such as starling flocks or ant colony. In
      such systems, each component can only interact with several
      &ldquo;neighbors&rdquo;. But, when a local perturbation (for example,
      caused by a predator) appears, its information soon propagates
      throughout the whole system, and the system reacts to the perturbation
      as a large complex organism, which is where the name
      &ldquo;complex&rdquo; emerges. Phenomenon that information propagates
      throughout the whole system without decay is called
      <strong>criticality</strong>. This is important for starling flocks or
      ant colony to survive, and the cost will be strongly related to the
      appearance of criticality.
    </p>
    <p>
      TODO
    </p>
  </body>
</html>